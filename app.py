# === app.py: import block (ë§¨ ìœ„ë¡œ êµì²´) ===
from __future__ import annotations
import os, sys, re
import streamlit as st

ROOT = os.path.dirname(os.path.abspath(__file__))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

_NEED_TOOLS = re.compile(r'(ë²•ë ¹|ì¡°ë¬¸|ì œ\d+ì¡°(?:ì˜\d+)?|DRF|OPEN\s*API|API)', re.I)

from modules import AdviceEngine, Intent, classify_intent, pick_mode, build_sys_for_mode

# law_fetch: ë£¨íŠ¸ ë˜ëŠ” íŒ¨í‚¤ì§€ ê²½ë¡œ ëª¨ë‘ í—ˆìš©
try:
    from law_fetch import fetch_article_block_by_mst
except Exception:
    from modules.law_fetch import fetch_article_block_by_mst  # noqa

# ì§ˆë¬¸ì—ì„œ ë²•ë ¹ëª…/ì¡°ë¬¸ ë¼ë²¨ ë½‘ê¸°
_LAW_ALIASES = {"ê±´ì„¤ì‚°ì—…ë²•": "ê±´ì„¤ì‚°ì—…ê¸°ë³¸ë²•"}  # ë™ìŒì´ì˜/ì•½ì¹­ êµì •í‘œ í•„ìš”ì‹œ ì¶”ê°€
def _extract_law_name(text: str) -> str | None:
    if not text:
        return None
    # ì˜ˆ: "ê±´ì„¤ì‚°ì—…ê¸°ë³¸ë²•", "ë¯¼ë²• ì‹œí–‰ë ¹"
    m = re.findall(r'([ê°€-í£0-9Â·\s]+ë²•(?:\s*ì‹œí–‰ë ¹|\s*ì‹œí–‰ê·œì¹™)?)', text)
    if not m:
        return None
    cand = sorted({t.strip() for t in m}, key=len, reverse=True)[0]
    cand_norm = re.sub(r'\s+', '', cand)
    return _LAW_ALIASES.get(cand_norm, cand_norm)

def _extract_article_label(text: str) -> str | None:
    # ì œ83ì¡°, ì œ83ì¡°ì˜2 ë“±
    m = re.search(r'ì œ\s*(\d{1,4})\s*ì¡°(?:\s*ì˜\s*(\d{1,3}))?', text or '')
    if not m:
        return None
    return f"ì œ{m.group(1)}ì¡°ì˜{m.group(2)}" if m.group(2) else f"ì œ{m.group(1)}ì¡°"

def _pick_best_law(items: list[dict], qname: str | None) -> dict | None:
    if not items:
        return None
    # "í˜„í–‰" ìš°ì„ 
    cand = [x for x in items if (x.get('í˜„í–‰ì—°í˜ì½”ë“œ') or x.get('ì—°í˜ì½”ë“œ') or '').startswith('í˜„í–‰')] or items
    if qname:
        qn = re.sub(r'\s+', '', qname)
        for x in cand:
            nm = re.sub(r'\s+', '', (x.get('ë²•ë ¹ëª…í•œê¸€') or x.get('ë²•ë ¹ëª…') or ''))
            if qn in nm:  # ë¶€ë¶„ì¼ì¹˜ ìš°ì„ 
                return x
    return cand[0]

def _slice_article_from_html(html_text: str, want: str) -> str | None:
    """DRF HTML ì „ì²´ì—ì„œ 'ì œNì¡°(â€¦)' ë¸”ë¡ë§Œ í…ìŠ¤íŠ¸ë¡œ ìŠ¬ë¼ì´ìŠ¤(ë³´í˜¸ìš© í´ë°±)."""
    if not (html_text and want):
        return None
    t = re.sub(r'<[^>]+>', '\n', html_text)
    t = re.sub(r'\n{2,}', '\n', t).strip()
    start = re.search(rf'{re.escape(want)}\s*(?=[\(\s]|$)', t)
    if not start:
        return None
    next_hdr = re.compile(r'ì œ\s*\d{1,4}\s*ì¡°(?:\s*ì˜\s*\d{1,3})?')
    m2 = next_hdr.search(t, start.end())
    return t[start.start(): (m2.start() if m2 else len(t))].strip() or None

def build_article_capsule(user_q: str, num_rows: int = 5) -> dict | None:
    """
    1) ì§ˆë¬¸ì—ì„œ ë²•ë ¹/ì¡°ë¬¸ì„ ê°ì§€ â†’ 2) ëª©ë¡ APIë¡œ MST ì‹ë³„ â†’ 3) DRFë¡œ í•´ë‹¹ ì¡°ë¬¸ ë³¸ë¬¸ë§Œ ì¶”ì¶œ
    ë°˜í™˜: {"sys_add": systemì— ë¶™ì¼ ë¬¸ìì—´, "ui": í™”ë©´ í‘œì‹œìš© dict}
    """
    want_law = _extract_law_name(user_q or "")
    want_art = _extract_article_label(user_q or "")
    wants_verbatim = bool(re.search(r'(ë³¸ë¬¸|ì›ë¬¸|ì „ë¬¸|ìš”ì•½\s*í•˜ì§€\s*ë§)', user_q or '', re.I))
    if not (wants_verbatim or want_art):
        return None

    # í›„ë³´ ìˆ˜ì§‘: ì•±ì— ì´ë¯¸ ìˆëŠ” í—¬í¼ë¥¼ ìµœìš°ì„  ì‚¬ìš©
    law_items = []
    try:
        # ìš°ì¸¡ í”Œë¼ì´ì•„ì›ƒ/í†µí•©ê²€ìƒ‰ì´ ìˆëŠ” ê²½ìš°
        bucket = find_all_law_data(user_q, num_rows=num_rows) or {}
        law_items = (bucket.get("ë²•ë ¹") or {}).get("items", [])
    except Exception:
        # ìµœì†Œ í´ë°±: ë‹¨ì¼ ê²€ìƒ‰ í—¬í¼ê°€ ìˆë‹¤ë©´ í™œìš©
        try:
            items, _, _ = search_law_data(want_law or (user_q or ""), num_rows=num_rows)
            law_items = items or []
        except Exception:
            pass

    best = _pick_best_law(law_items, want_law)
    if not best:
        return None

    mst = str(best.get('MST') or best.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸') or best.get('ë²•ë ¹ID') or '').strip()
    if not mst:
        return None

    eff = (best.get('ì‹œí–‰ì¼ì') or best.get('ê³µí¬ì¼ì') or '').strip().replace('-', '') or None
    # 1ìˆœìœ„ HTML â†’ 2ìˆœìœ„ HTML ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ â†’ 3ìˆœìœ„ JSON
    body, link = fetch_article_block_by_mst(mst, want_art, prefer="JSON", efYd=eff)
    if not body and want_art:
        html_all, link_all = fetch_article_block_by_mst(mst, None, prefer="HTML", efYd=eff)
        sliced = _slice_article_from_html(html_all or "", want_art)
        if sliced:
            body, link = sliced, (link or link_all)
    if not body:
        body, link = fetch_article_block_by_mst(mst, want_art, prefer="HTML", efYd=eff)
    if not body:
        return None

    law_name = (best.get('ë²•ë ¹ëª…í•œê¸€') or best.get('ë²•ë ¹ëª…') or '').strip()
    sys_add = (
        "\n\n[ë²•ë ¹ ë³¸ë¬¸ ìº¡ìŠ]\n"
        f"ë²•ë ¹ëª…: {law_name}\n"
        f"ì¡°ë¬¸: {want_art or '(ì „ì²´)'}\n"
        f"ë§í¬: {link}\n"
        f"{body.strip()[:2000]}\n"
    )
    return {
        "sys_add": sys_add,
        "ui": {"law_name": law_name, "art_label": want_art or '', "link": link, "text": body.strip()},
    }


import inspect

# --- per-turn nonce ledger (prevents double appends)
st.session_state.setdefault('_nonce_done', {})
# --- cache helpers: suggestions shouldn't jitter on reruns ---
def cached_suggest_for_tab(tab_key: str):
    import streamlit as st
    store = st.session_state.setdefault("__tab_suggest__", {})
    if tab_key not in store:
        from modules import suggest_keywords_for_tab
        store[tab_key] = suggest_keywords_for_tab(tab_key)  # â† ì—¬ê¸°!
    return store[tab_key]

def cached_suggest_for_law(law_name: str):
    import streamlit as st
    store = st.session_state.setdefault("__law_suggest__", {})
    if law_name not in store:
        from modules import suggest_keywords_for_law
        store[law_name] = suggest_keywords_for_law(law_name)  # â† ì—¬ê¸°!
    return store[law_name]


st.set_page_config(
    page_title="ì¸ê³µì§€ëŠ¥ ë²•ë¥ ìƒë‹´ ì „ë¬¸ê°€",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- Law helpers -------------------------------------------------------------
import re

LAW_ALIASES = {"ê±´ì„¤ì‚°ì—…ë²•": "ê±´ì„¤ì‚°ì—…ê¸°ë³¸ë²•"}  # í•„ìš”ì‹œ ì¶”ê°€

def extract_law_name(text: str) -> str | None:
    if not text: return None
    toks = re.findall(r'([ê°€-í£0-9Â·\s]+ë²•(?:\s*ì‹œí–‰ë ¹|\s*ì‹œí–‰ê·œì¹™)?)', text)
    if not toks: return None
    cand = sorted({t.strip() for t in toks}, key=len, reverse=True)[0]
    cand_norm = re.sub(r'\s+', '', cand)
    return LAW_ALIASES.get(cand_norm, cand_norm)

def extract_article_label(text: str) -> str | None:
    m = re.search(r'ì œ\s*(\d{1,4})\s*ì¡°(?:\s*ì˜\s*(\d{1,3}))?', text or '')
    if not m: return None
    return f"ì œ{m.group(1)}ì¡°ì˜{m.group(2)}" if m.group(2) else f"ì œ{m.group(1)}ì¡°"

def _pick_best_law(items: list[dict], qname: str | None) -> dict | None:
    if not items: return None
    cand = [x for x in items if (x.get('í˜„í–‰ì—°í˜ì½”ë“œ') or x.get('ì—°í˜ì½”ë“œ') or '').startswith('í˜„í–‰')] or items
    if qname:
        qn = re.sub(r'\s+', '', qname)
        for x in cand:
            nm = re.sub(r'\s+', '', (x.get('ë²•ë ¹ëª…í•œê¸€') or x.get('ë²•ë ¹ëª…') or ''))
            if qn in nm:  # ë¶€ë¶„ì¼ì¹˜ ìš°ì„ 
                return x
    return cand[0]





def _init_engine_lazy():
    if "engine" in st.session_state and st.session_state.engine is not None:
        return st.session_state.engine

    g = globals()
    c       = g.get("client")
    az      = g.get("AZURE")
    tools   = g.get("TOOLS")
    scc     = g.get("safe_chat_completion")
    t_one   = g.get("tool_search_one")
    t_multi = g.get("tool_search_multi")
    pre     = g.get("prefetch_law_context")
    # âœ… ë¨¼ì € ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¼ì´ë¨¸ë¡œ í´ë°±
    summar  = g.get("_summarize_laws_for_primer") or _summarize_laws_for_basic

    # (ì„ íƒ) ì•ˆì „ í™•ì¸
    # if summar is None:
    #     raise RuntimeError("ë²•ë ¹ í”„ë¼ì´ë¨¸ í•¨ìˆ˜ ë¡œë“œ ì‹¤íŒ¨")

    if not (c and az and tools and scc and t_one and t_multi):
        st.session_state.engine = None
        return None

    st.session_state.engine = AdviceEngine(
        client=c,
        model=az["deployment"],
        tools=tools,
        safe_chat_completion=scc,
        tool_search_one=t_one,
        tool_search_multi=t_multi,
        prefetch_law_context=pre,
        summarize_laws_for_primer=summar,  # â† ì—¬ê¸°ë¡œ ì „ë‹¬
        temperature=0.2,
    )
    return st.session_state.engine

# (ìœ„ì¹˜ ê¶Œì¥) render_prompt_inspector() ì •ì˜ ì¸ê·¼ â€” í•œ ë²ˆë§Œ ì •ì˜
import time, urllib.parse as up

def _trace_api(kind: str, url: str, params: dict | None = None, resp=None, sample_len: int = 500):
    """ì‚¬ì´ë“œë°” 'API Trace'ì— ìµœê·¼ í˜¸ì¶œì„ ëˆ„ì  ê¸°ë¡"""
    try:
        import streamlit as st
        rows = st.session_state.setdefault("_api_trace", [])
        full_url = url if not params else f"{url}?{up.urlencode(params, quote_via=up.quote)}"
        rows.append({
            "t": time.strftime("%H:%M:%S"),
            "kind": kind,                     # e.g. "list" or "drf"
            "url": full_url,
            "params": params or {},
            "status": getattr(resp, "status_code", None),
            "ctype": (getattr(resp, "headers", {}) or {}).get("content-type", ""),
            "sample": (getattr(resp, "text", "") or "")[:sample_len],
        })
        st.session_state["_api_trace"] = rows[-12:]  # ìµœê·¼ 12ê°œë§Œ ìœ ì§€
    except Exception:
        pass

def render_prompt_inspector():
    import streamlit as st, json
    with st.sidebar.expander("ğŸ§ª Prompt Inspector (LLM ì „ë‹¬ ë‚´ìš©)", expanded=True):
        p = st.session_state.get("_prompt_last") or ""
        st.write(f"System prompt ê¸¸ì´: {len(p)}ì")
        st.code(p[:4000] or "ë¹„ì–´ ìˆìŒ", language="markdown")

    with st.sidebar.expander("ğŸ“¡ API Trace (ìµœê·¼ 6ê±´)", expanded=False):
        rows = st.session_state.get("_api_trace") or []
        for e in list(rows)[-6:][::-1]:
            st.text(f"[{e.get('t')}] {e.get('kind')}  status={e.get('status')}  {e.get('ctype')}")
            st.code(e.get("url") or "", language="text")
            if e.get("params"):
                st.code(json.dumps(e["params"], ensure_ascii=False, indent=2), language="json")
            if e.get("sample"):
                st.text("â€¦ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:")
                st.code(e["sample"], language="text")
# app.py â€” _call_moleg_list()  (ë“œë¡­ì¸ êµì²´)

def _call_moleg_list(target: str, query: str, num_rows: int = 5, timeout: float = 8.0):
    """
    MOLEG(ë²•ì œì²˜) ëª©ë¡/ê²€ìƒ‰ API í˜¸ì¶œ
    1ìˆœìœ„: DRF(law.go.kr/DRF) - OC í•„ìš”
    2ìˆœìœ„: ê³µê³µë°ì´í„°í¬í„¸(apis.data.go.kr/1170000) - serviceKey í•„ìš” (XML ê¸°ë³¸)
    ë°˜í™˜: (items:list[dict], endpoint:str|None, err:str|None)
    """
    import requests, urllib.parse as up
    target = (target or "law").strip().lower()
    assert target in ("law", "admrul", "ordin", "trty")

    oc  = (globals().get("LAW_API_OC")  or "").strip()
    key = (globals().get("LAW_API_KEY") or "").strip()

    s = requests.Session()
    try:
        s.mount("https://", TLS12HttpAdapter())
        s.mount("http://",  TLS12HttpAdapter())
    except Exception:
        pass

    # --- DRF (ê¸°ì¡´ ê·¸ëŒ€ë¡œ) ---
    def call_drf():
        if not oc:
            return [], None, "DRF-OC-ë¯¸ì„¤ì •"
        base = "https://www.law.go.kr/DRF/lawSearch.do"
        params = {
            "OC": oc, "target": target, "type": "JSON",
            "query": (query or "").strip(),
            "numOfRows": max(1, min(int(num_rows or 5), 10)),
        }
        try:
            r = s.get(base, params=params, timeout=timeout, headers={
                "User-Agent":"Mozilla/5.0",
                "Accept":"application/json, text/javascript, */*; q=0.01",
                "Referer":"https://www.law.go.kr/DRF/index.do",
                "X-Requested-With":"XMLHttpRequest",
            })
            try: _trace_api("list", base, params, r)
            except Exception: pass
            if not r.ok or "json" not in (r.headers.get("content-type","").lower()):
                return [], r.url, f"DRF-{r.status_code}"
            data = r.json()
            # ë˜í¼ í‚¤ í’€ê¸°
            if isinstance(data, dict):
                for w in ("LawSearch","AdmrulSearch","OrdinSearch","TrtySearch"):
                    if w in data: data = data[w]; break
            # í•­ëª© ì¶”ì¶œ
            if isinstance(data, list):
                items = data
            elif isinstance(data, dict):
                items = (
                    data.get("law") or data.get("admrul") or data.get("ordin") or data.get("trty")
                    or data.get("response",{}).get("body",{}).get("items",[]) or data.get("items",[])
                    or []
                )
            else:
                items = []
            # í•„ë“œ ì •ê·œí™”
            norm=[]
            for it in items:
                if isinstance(it, dict):
                    row=dict(it); row.setdefault("name", row.get("ë²•ë ¹ëª…í•œê¸€") or row.get("ë²•ë ¹ëª…") or row.get("title") or "")
                    norm.append(row)
                else:
                    norm.append(it)
            return norm, r.url, None
        except Exception as e:
            return [], base + "?" + up.urlencode(params, quote_via=up.quote), f"DRF-EXC:{e}"

    # --- ODS (ìŠ¤í™ëŒ€ë¡œ: ëŒ€ìƒë³„ ì—”ë“œí¬ì¸íŠ¸ + XML ê¸°ë³¸) ---
    def call_ods():
        if not key:
            return [], None, "ODS-KEY-ë¯¸ì„¤ì •"

        # ëŒ€ìƒë³„ ì •ê·œ ì—”ë“œí¬ì¸íŠ¸ (ê°€ì´ë“œ ëª…ì‹œ)
        BASES = {
            "law":   "https://apis.data.go.kr/1170000/law/lawSearchList.do",
            "admrul":"https://apis.data.go.kr/1170000/admrul/admrulSearchList.do",
            "ordin": "https://apis.data.go.kr/1170000/ordin/ordinSearchList.do",
            "trty":  "https://apis.data.go.kr/1170000/trty/trtySearchList.do",
        }  # XML êµí™˜ í‘œì¤€, íŒŒë¼ë¯¸í„°: serviceKey/target/query/numOfRows/pageNo  :contentReference[oaicite:2]{index=2}

        base = BASES[target]
        # serviceKeyëŠ” URL-encoded ìƒíƒœ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        params = {
            "serviceKey": key,
            "target": target,
            "query": (query or "").strip() or "*",
            "numOfRows": max(1, min(int(num_rows or 5), 10)),
            "pageNo": 1,
        }

        try:
            r = s.get(base, params=params, timeout=timeout, headers={"User-Agent":"Mozilla/5.0", "Accept":"application/xml"})
            try: _trace_api("list", base, params, r)
            except Exception: pass

            if not r.ok:
                return [], r.url, f"ODS-{r.status_code}"

            ctype = (r.headers.get("content-type") or "").lower()
            text  = r.text or ""
            # XML ê¸°ë³¸ íŒŒì‹±
            items = []
            if ("xml" in ctype) or text.strip().startswith("<"):
                try:
                    import xml.etree.ElementTree as ET
                    root = ET.fromstring(text)
                    # ë£¨íŠ¸ëŠ” LawSearch/AdmRulSearch/OrdinSearch/TrtySearch ì¤‘ í•˜ë‚˜
                    # ê° í•­ëª© íƒœê·¸: law/admrul/law(trty ì¼€ì´ìŠ¤ì—ì„  Trtyë¡œ í‘œê¸°ë  ìˆ˜ ìˆìŒ)
                    rows = list(root.findall(".//law")) + list(root.findall(".//admrul")) \
                         + list(root.findall(".//ordin")) + list(root.findall(".//Trty")) + list(root.findall(".//trty"))
                    for node in rows:
                        row = {}
                        for child in list(node):
                            tag = child.tag.strip()
                            val = (child.text or "").strip()
                            # CDATA í¬í•¨ í…ìŠ¤íŠ¸ ì•ˆì „ ì²˜ë¦¬
                            row[tag] = val
                        # í•„ìˆ˜ í‚¤ ë³´ì •
                        if "ë²•ë ¹ëª…í•œê¸€" not in row and "ë²•ë ¹ëª…" in row:
                            row["ë²•ë ¹ëª…í•œê¸€"] = row["ë²•ë ¹ëª…"]
                        items.append(row)
                except Exception:
                    items = []
            else:
                # í˜¹ì‹œ JSONìœ¼ë¡œ ë‚´ë ¤ì˜¤ë©´ ìµœì†Œ íŒŒì‹± í´ë°±
                try:
                    data = r.json()
                    if isinstance(data, dict):
                        body = data.get("response",{}).get("body",{})
                        items = body.get("items",[]) or data.get("items",[])
                    elif isinstance(data, list):
                        items = data
                    else:
                        items = []
                except Exception:
                    return [], r.url, "ODS-UNPARSEABLE"

            return (items or []), r.url, None
        except Exception as e:
            from urllib.parse import urlencode, quote
            return [], base + "?" + urlencode(params, quote_via=quote), f"ODS-EXC:{e}"

    # --- ìš°ì„  DRF, ì‹¤íŒ¨ ì‹œ ODS í´ë°± ---
    items, ep, err = call_drf()
    if items: return items, ep, None
    items2, ep2, err2 = call_ods()
    if items2: return items2, ep2, None
    return [], (ep or ep2), (err or err2 or "NO_RESULT")




def render_api_diagnostics():
    import urllib.parse as up, requests, streamlit as st, re

    HEADERS_DRF = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Referer": "https://www.law.go.kr/DRF/index.do",
        "X-Requested-With": "XMLHttpRequest",
    }

    with st.sidebar.expander("ğŸ”§ API ì—°ê²° ì§„ë‹¨", expanded=True):
        st.write("LAW_API_KEY:", "âœ… ì„¤ì •ë¨" if (globals().get("LAW_API_KEY")) else "âŒ ì—†ìŒ")
        st.write("LAW_API_OC:",   f"âœ… '{globals().get('LAW_API_OC')}'" if (globals().get("LAW_API_OC")) else "âŒ ì—†ìŒ")

        # --- 1) ëª©ë¡ API í…ŒìŠ¤íŠ¸: try ì „ì— ê¸°ë³¸ê°’ ì¡ê¸° (ì—¬ê¸°!) ---
        items: list[dict] = []
        endpoint: str | None = None
        err: str | None = None
        try:
            last_q = (st.session_state.get('last_q') or '').strip()
            m = re.search(r'([ê°€-í£0-9Â·\s]+ë²•)', last_q)
            _kw = (m.group(1).strip() if m else "ë¯¼ë²•")

            items, endpoint, err = _call_moleg_list("law", _kw, num_rows=1)
            st.write("ëª©ë¡ API ì—”ë“œí¬ì¸íŠ¸:", endpoint or "-")
            st.write("ëª©ë¡ API ê²°ê³¼:", f"{len(items)}ê±´", ("OK" if not err else f"ì˜¤ë¥˜: {err}"))
        except Exception as e:
            st.error(f"ëª©ë¡ API ì˜ˆì™¸: {e}")

        # --- 2) DRF ë³¸ë¬¸ í…ŒìŠ¤íŠ¸: ì—¬ê¸°ì„œë„ ê¸°ë³¸ê°’ ë¨¼ì € ---
        body: str | None = None
        link: str | None = None
        try:
            if items:
                it = items[0]  # ë˜ëŠ” _pick_best(items, _kw)
                mst = (it.get("MST") or it.get("ë²•ë ¹ID") or "").strip()
                if mst:
                    eff = (it.get("ì‹œí–‰ì¼ì") or it.get("ê³µí¬ì¼ì") or "").strip().replace("-", "") or None
                    body, link = fetch_article_block_by_mst(mst, None, prefer="HTML", efYd=eff)
                    st.write("DRF ë³¸ë¬¸ ë§í¬:", link or "-")
                    st.write("ë³¸ë¬¸ ê¸¸ì´:", len(body or ""))
                else:
                    st.info("MSTê°€ ì—†ì–´ ë³¸ë¬¸ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            else:
                st.info("ëª©ë¡ ê²°ê³¼ê°€ ì—†ì–´ ë³¸ë¬¸ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"DRF ì˜ˆì™¸: {e}")


      
        # 2) DRF ë³¸ë¬¸(JSON â†’ XML â†’ HTML) í…ŒìŠ¤íŠ¸
        try:
            if items:
                mst = (items[0].get("MST") or items[0].get("ë²•ë ¹ID") or "").strip()
                oc  = (globals().get("LAW_API_OC") or "").strip()
                if mst and oc:
                    def try_fetch(typ):
                        url = "https://www.law.go.kr/DRF/lawService.do"
                        params = {"OC": oc, "target": "law", "MST": mst, "type": typ}
                        r = requests.get(url, params=params, headers=HEADERS_DRF, timeout=10)
                        return url, params, r

                    for typ in ("JSON", "XML", "HTML"):
                        url, params, r = try_fetch(typ)
                        ctype = (r.headers.get("content-type") or "").lower()
                        st.write(f"DRF({typ}) ìƒíƒœì½”ë“œ:", r.status_code, "| Content-Type:", ctype)
                        st.code(f"{url}?{up.urlencode(params, quote_via=up.quote)}", language="text")
                        st.text((r.text or "")[:500])
                        if ("json" in ctype) or ("xml" in ctype):
                            break
                else:
                    st.warning("MST ë˜ëŠ” OCê°€ ì—†ì–´ DRF í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€.")
        except Exception as e:
            st.error(f"DRF ì˜ˆì™¸: {e}")

render_prompt_inspector()


from typing import Optional
import re
import inspect
import streamlit as st
# _NEED_TOOLS ì „ì—­ì´ ì—†ë‹¤ë©´ ìë™ ìƒì„±
_NEED_TOOLS = globals().get("_NEED_TOOLS") or re.compile(r'(ë²•ë ¹|ì¡°ë¬¸|ì œ\d+ì¡°(?:ì˜\d+)?|DRF|OPEN\s*API|API|ë³¸ë¬¸|ì›ë¬¸|ìš”ì•½\s*í•˜ì§€\s*ë§)', re.I)

# === [REPLACE] ask_llm_with_tools ===
from typing import Optional

def ask_llm_with_tools(
    user_q: str,
    brief: bool = False,
    forced_mode: Optional[str] = None,
    num_rows: int = 8,
    stream: bool = True,
):
    """
    - í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    - 'ë³¸ë¬¸/ì›ë¬¸/ìš”ì•½ ê¸ˆì§€' + 'ì œnì¡°' ìš”ì²­ ì‹œ, DRF ì¡°ë¬¸ì„ systemì— ì„ ì£¼ì…
    - ì—”ì§„(history ì§€ì›/ë¯¸ì§€ì› ëª¨ë‘)ì— ì•ˆì „í•˜ê²Œ ì „ë‹¬
    """
    engine = _init_engine_lazy()
    if engine is None:
        return

    # 1) ëª¨ë“œ ê²°ì •
    det_intent, conf = classify_intent(user_q)
    try:
        valid = {m.value for m in Intent}
        mode = Intent(forced_mode) if (forced_mode in valid) else pick_mode(det_intent, conf)
    except Exception:
        mode = pick_mode(det_intent, conf)

    use_tools = mode in (Intent.LAWFINDER, Intent.MEMO)
    if not use_tools and _NEED_TOOLS.search(user_q or ""):
        use_tools = True

    # 2) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    sys_prompt = build_sys_for_mode(mode, brief=brief)

    # 2-1) 'ìš”ì•½ ê¸ˆì§€/ì›ë¬¸' ì‹ í˜¸ ìˆìœ¼ë©´ ì¸ìš© ì§€ì¹¨ ì¶”ê°€
    _WANTS_FULL = re.compile(r'(ë³¸ë¬¸|ì›ë¬¸|ì¡°ë¬¸\s*(?:ì „ë¬¸|ì „ì²´)|ìš”ì•½\s*í•˜ì§€\s*ë§)', re.I)
    if _WANTS_FULL.search(user_q or ""):
        sys_prompt += (
            "\n\n[ì¡°ë¬¸ ì¸ìš© ì§€ì¹¨]\n"
            "- ì‚¬ìš©ìê°€ ì¡°ë¬¸ ì›ë¬¸ì„ ì›í•˜ë©´, DRF/í”„ë¼ì´ë¨¸ ë³¸ë¬¸ì„ ê·¸ëŒ€ë¡œ ì¸ìš©í•œë‹¤.\n"
            "- ì„ì˜ ìš”ì•½Â·ì˜ì—­ ê¸ˆì§€, ë¬¸ì¥ ìˆœì„œ ìœ ì§€, ìµœëŒ€ 1500~2000ì.\n"
            "- ì¸ìš© ë’¤ì— ë²•ì œì²˜ ê³µì‹ ë§í¬(DRF/ìƒì„¸)ë¥¼ í•¨ê»˜ ì œê³µí•œë‹¤."
        )

    # 2-2) âœ… DRF ì¡°ë¬¸ ë³¸ë¬¸ 'ì„ í–‰ ì£¼ì…'
    st.session_state['last_q'] = user_q
    caps = build_article_capsule(user_q, num_rows=num_rows)
    if caps:
        sys_prompt += caps["sys_add"]                   # LLM systemì— ì›ë¬¸ ìº¡ìŠ ì£¼ì…
        st.session_state["_quote_capsule"] = caps["ui"] # UIì— ë°”ë¡œ ë³´ì—¬ì¤„ ë²„í¼ ì €ì¥

    # 2-3) ìµœê·¼ íˆìŠ¤í† ë¦¬
    try:
        msgs = st.session_state.get("messages", [])
        history = [{"role":m["role"], "content":m["content"]} for m in msgs if m.get("role") in ("user","assistant")]
        HISTORY_LIMIT = int(st.session_state.get("__history_limit__", 6))
        history = history[-HISTORY_LIMIT:]
    except Exception:
        history = []

    # 2-4) ì‚¬ì´ë“œë°” í™•ì¸ìš©
    st.session_state["_prompt_last"] = sys_prompt

    # 3) ì—”ì§„ í˜¸ì¶œ (history ì¸ìëª… ì•ˆì „ íƒì§€)
    try:
        sig = inspect.signature(engine.generate)
        params = set(sig.parameters.keys())
    except Exception:
        params = set()

    called = False
    for kw in ("history", "messages", "chat_history", "conversation"):
        if kw in params:
            yield from engine.generate(
                user_q,
                system_prompt=sys_prompt,
                allow_tools=use_tools,
                num_rows=num_rows,
                stream=stream,
                primer_enable=True,
                **{kw: history},
            )
            called = True
            break

    if not called:
        yield from engine.generate(
            user_q,
            system_prompt=sys_prompt,
            allow_tools=use_tools,
            num_rows=num_rows,
            stream=stream,
            primer_enable=True,
        )

    # 3-1) âœ… í™”ë©´ì— ì¡°ë¬¸ ì›ë¬¸ ë°”ë¡œ ì¶œë ¥
    caps_ui = st.session_state.pop("_quote_capsule", None)
    if caps_ui:
        st.markdown(
            f"**ìš”ì²­í•˜ì‹  {caps_ui['law_name']} {caps_ui['art_label']} ì¡°ë¬¸ ì›ë¬¸** Â· "
            f"[ë²•ì œì²˜ ì „ë¬¸ ë³´ê¸°]({caps_ui['link']})"
        )
        st.code(caps_ui["text"])


import io, os, re, json, time, html

if "_normalize_text" not in globals():
    def _normalize_text(s: str) -> str:
        """ë¶ˆí•„ìš”í•œ ê³µë°±/ë¹ˆ ì¤„ì„ ì •ëˆí•˜ëŠ” ì•ˆì „í•œ ê¸°ë³¸ ë²„ì „"""
        s = (s or "").replace("\r\n", "\n").replace("\r", "\n")
        # ì•ë’¤ ê³µë°± ì •ë¦¬
        s = s.strip()
        # 3ê°œ ì´ìƒ ì—°ì† ê°œí–‰ â†’ 2ê°œë¡œ
        s = re.sub(r"\n{3,}", "\n\n", s)
        # ë¬¸ì¥ ë ê³µë°± ì œê±°
        s = re.sub(r"[ \t]+\n", "\n", s)
        return s

def _esc(s: str) -> str:
    """HTML escape only"""
    return html.escape("" if s is None else str(s))

def _esc_br(s: str) -> str:
    """HTML escape + ì¤„ë°”ê¿ˆì„ <br>ë¡œ"""
    return _esc(s).replace("\n", "<br>")

from datetime import datetime            # _push_user_from_pending, ì €ì¥ ì‹œê° ë“±ì— í•„ìš”
import urllib.parse as up                # normalize_law_link, quote ë“±ì—ì„œ ì‚¬ìš©
import xml.etree.ElementTree as ET       # _call_moleg_list() XML íŒŒì‹±ì— í•„ìš”
from urllib.parse import quote
import requests
import streamlit.components.v1 as components
from openai import AzureOpenAI
from llm_safety import safe_chat_completion

# TLS 1.2 ê°•ì œìš© ì–´ëŒ‘í„° ì •ì˜
from requests.adapters import HTTPAdapter
from urllib3.util.ssl_ import create_urllib3_context
class TLS12HttpAdapter(HTTPAdapter):
    """TLS1.2 only adapter for requests"""
    def init_poolmanager(self, *args, **kwargs):
        context = create_urllib3_context()
        context.set_ciphers('HIGH:!aNULL:!eNULL:!SSLv2:!SSLv3')
        kwargs['ssl_context'] = context
        return super().init_poolmanager(*args, **kwargs)

from chatbar import chatbar
# (ì²¨ë¶€ íŒŒì‹±ì€ ë‚˜ì¤‘ í™•ì¥ìš©ìœ¼ë¡œ import ìœ ì§€)
from utils_extract import extract_text_from_pdf, extract_text_from_docx, read_txt, sanitize
from external_content import is_url, make_url_context
from external_content import extract_first_url
from typing import Iterable, List

import hashlib


# --- Utilities: de-duplicate repeated paragraphs/halves ---
def _dedupe_repeats(txt: str) -> str:
    if not txt:
        return txt
    n = len(txt)
    # Heuristic 1: if halves overlap (common duplication pattern)
    if n > 600:
        half = n // 2
        a, b = txt[:half].strip(), txt[half:].strip()
        if a and b and (a == b or a.startswith(b[:200]) or b.startswith(a[:200])):
            return a if len(a) >= len(b) else b
    # Heuristic 2: paragraph-level dedupe while preserving order
    parts = re.split(r"\n\s*\n", txt)
    seen = set()
    out_parts = []
    for p in parts:
        key = p.strip()
        norm = re.sub(r"\s+", " ", key).strip().lower()
        if norm and norm in seen:
            continue
        if norm:
            seen.add(norm)
        out_parts.append(p)
    return "\n\n".join(out_parts)


def _hash_text(s: str) -> str:
    return hashlib.md5((s or "").encode("utf-8")).hexdigest()


# í–‰ì •ê·œì¹™ ì†Œê´€ ë¶€ì²˜ ë“œë¡­ë‹¤ìš´ ì˜µì…˜
MINISTRIES = [
    "ë¶€ì²˜ ì„ íƒ(ì„ íƒ)",
    "êµ­ë¬´ì¡°ì •ì‹¤", "ê¸°íšì¬ì •ë¶€", "êµìœ¡ë¶€", "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€",
    "ì™¸êµë¶€", "í†µì¼ë¶€", "ë²•ë¬´ë¶€", "í–‰ì •ì•ˆì „ë¶€", "ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€",
    "ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€", "ì‚°ì—…í†µìƒìì›ë¶€", "ë³´ê±´ë³µì§€ë¶€", "í™˜ê²½ë¶€",
    "ê³ ìš©ë…¸ë™ë¶€", "ì—¬ì„±ê°€ì¡±ë¶€", "êµ­í† êµí†µë¶€", "í•´ì–‘ìˆ˜ì‚°ë¶€",
    "ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€", "ê¸ˆìœµìœ„ì›íšŒ", "ë°©ì†¡í†µì‹ ìœ„ì›íšŒ", "ê³µì •ê±°ë˜ìœ„ì›íšŒ",
    "êµ­ê°€ë³´í›ˆë¶€", "ì¸ì‚¬í˜ì‹ ì²˜", "ì›ìë ¥ì•ˆì „ìœ„ì›íšŒ", "ì§ˆë³‘ê´€ë¦¬ì²­",
]
# === UI/ë™ì‘ ì˜µì…˜ ===
SHOW_SEARCH_DEBUG = False     # â† í†µí•© ê²€ìƒ‰ íŒ¨ë„ì˜ ë””ë²„ê·¸(ì‹œë„/LLM plans/ì—ëŸ¬) ê°ì¶”ê¸°

SHOW_STREAM_PREVIEW = False  # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ê°„ ë¯¸ë¦¬ë³´ê¸° ë„ê¸°

# ==============================
# ì¶”ì²œ í‚¤ì›Œë“œ (íƒ­ë³„) + í—¬í¼
# ==============================

# ë²•ë ¹ëª… ê¸°ë°˜ ì¶”ì²œ(ë²•ë ¹ íƒ­ ì „ìš©)
SUGGESTED_LAW_KEYWORDS = {
    "ë¯¼ë²•": ["ì œ839ì¡°", "ì¬ì‚°ë¶„í• ", "ì´í˜¼", "ì œ840ì¡°", "ì¹œê¶Œ"],
    "í˜•ë²•": ["ì œ307ì¡°", "ëª…ì˜ˆí›¼ì†", "ì‚¬ê¸°", "í­í–‰", "ìƒí•´"],
    "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•": ["ë³´ì¦ê¸ˆ", "ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹", "ëŒ€í•­ë ¥", "ìš°ì„ ë³€ì œê¶Œ"],
    "ìƒê°€ê±´ë¬¼ ì„ëŒ€ì°¨ë³´í˜¸ë²•": ["ë³´ì¦ê¸ˆ", "ê¶Œë¦¬ê¸ˆ", "ê°±ì‹ ìš”êµ¬ê¶Œ", "ëŒ€í•­ë ¥"],
    "ê·¼ë¡œê¸°ì¤€ë²•": ["í•´ê³ ", "ì—°ì°¨", "í‡´ì§ê¸ˆ", "ì„ê¸ˆì²´ë¶ˆ"],
    "ê°œì¸ì •ë³´ ë³´í˜¸ë²•": ["ìˆ˜ì§‘ì´ìš©", "ì œ3ìì œê³µ", "ìœ ì¶œí†µì§€", "ê³¼ì§•ê¸ˆ"],
}
FALLBACK_LAW_KEYWORDS = ["ì •ì˜", "ëª©ì ", "ë²Œì¹™"]

def cached_suggest_for_law(law_name: str) -> list[str]:
    if not law_name:
        return FALLBACK_LAW_KEYWORDS
    if law_name in SUGGESTED_LAW_KEYWORDS:
        return SUGGESTED_LAW_KEYWORDS[law_name]
    for k in SUGGESTED_LAW_KEYWORDS:
        if k in law_name:
            return SUGGESTED_LAW_KEYWORDS[k]
    return FALLBACK_LAW_KEYWORDS

# íƒ­ë³„ ê¸°ë³¸ ì¶”ì²œ(í–‰ì •ê·œì¹™/ìì¹˜ë²•ê·œ/ì¡°ì•½/íŒë¡€/í—Œì¬/í•´ì„ë¡€)
SUGGESTED_TAB_KEYWORDS = {
    "admrul": ["ê³ ì‹œ", "í›ˆë ¹", "ì˜ˆê·œ", "ì§€ì¹¨", "ê°œì •"],
    "ordin":  ["ì¡°ë¡€", "ê·œì¹™", "ê·œì •", "ì‹œí–‰", "ê°œì •"],
    "trty":   ["ë¹„ì¤€", "ë°œíš¨", "ì–‘ì", "ë‹¤ì", "í˜‘ì •"],
    # íŒë¡€/í—Œì¬ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ìš© ë³´ì¡°(ì •í™• ë§í¬ëŠ” ì‚¬ê±´ë²ˆí˜¸Â·ì‚¬ê±´í‘œì‹œê°€ ë” ì í•©)
    "prec":   ["ì†í•´ë°°ìƒ", "ëŒ€ì—¬ê¸ˆ", "ì‚¬ê¸°", "ì´í˜¼", "ê·¼ë¡œ"],
    "cc":     ["ìœ„í—Œ", "í•©í—Œ", "ê°í•˜", "ì¹¨í•´", "ê¸°ê°"],
    "expc":   ["ìœ ê¶Œí•´ì„", "ì§ˆì˜íšŒì‹ ", "ë²•ë ¹í•´ì„", "ì ìš©ë²”ìœ„"],
}
def cached_suggest_for_tab(tab_kind: str) -> list[str]:
    return SUGGESTED_TAB_KEYWORDS.get(tab_kind, [])

def inject_sticky_layout_css(mode: str = "wide"):
    PRESETS = {
        "wide":   {"center": "1160px", "bubble_max": "760px"},
        "narrow": {"center": "880px",  "bubble_max": "640px"},
    }
    p = PRESETS.get(mode, PRESETS["wide"])

    # ì „ì—­ CSS ë³€ìˆ˜(í•œ êµ°ë°ì—ì„œë§Œ ì„ ì–¸)
    root_vars = (
        ":root {"
        " --center-col: 1160px;"
        " --bubble-max: 760px;"
        " --chatbar-h: 56px;"
        " --chat-gap: 12px;"
        " --rail: 460px;"
        " --hgap: 24px;"
        "}"
    )

    css = f"""
    <style>
      {root_vars}

      /* ë³¸ë¬¸/ì…ë ¥ì°½ ê³µí†µ ì¤‘ì•™ ì •ë ¬ & ë™ì¼ í­ */
      .block-container, .stChatInput {{
        max-width: var(--center-col) !important;
        margin-left: auto !important;
        margin-right: auto !important;
      }}

      /* ì±„íŒ… ë§í’ì„  ìµœëŒ€ í­ */
      [data-testid="stChatMessage"] {{
        max-width: var(--bubble-max) !important;
        width: 100% !important;
      }}
      [data-testid="stChatMessage"] .stMarkdown,
      [data-testid="stChatMessage"] .stMarkdown > div {{
        width: 100% !important;
      }}

      /* ëŒ€í™” ì „ ì¤‘ì•™ íˆì–´ë¡œ */
      .center-hero {{
        min-height: calc(100vh - 220px);
        display: flex; flex-direction: column; align-items: center; justify-content: center;
      }}
      .center-hero .stFileUploader, .center-hero .stTextInput {{
        width: 720px; max-width: 92vw;
      }}

.post-chat-ui .stFileUploader, .post-chat-ui .stTextInput {{ width: 720px; max-width: 92vw; }}
.post-chat-ui {{ margin-top: 8px; }}


      /* ì—…ë¡œë” ê³ ì •: ì•µì»¤ ë‹¤ìŒ í˜•ì œ ì—…ë¡œë” */
      #bu-anchor + div[data-testid='stFileUploader'] {{
        position: fixed;
        left: 50%; transform: translateX(-50%);
        bottom: calc(var(--chatbar-h) + var(--chat-gap) + 12px);
        width: clamp(340px, calc(var(--center-col) - 2*var(--hgap)), calc(100vw - var(--rail) - 2*var(--hgap)));
        max-width: calc(100vw - var(--rail) - 2*var(--hgap));
        z-index: 60;
        background: rgba(0,0,0,0.35);
        padding: 10px 12px; border-radius: 12px;
        backdrop-filter: blur(6px);
      }}
      #bu-anchor + div [data-testid='stFileUploader'] {{
        background: transparent !important; border: none !important;
      }}

      /* ì…ë ¥ì°½ í•˜ë‹¨ ê³ ì • */
      section[data-testid="stChatInput"] {{
        position: fixed; left: 50%; transform: translateX(-50%);
        bottom: 0; z-index: 70;
        width: clamp(340px, calc(var(--center-col) - 2*var(--hgap)), calc(100vw - var(--rail) - 2*var(--hgap)));
        max-width: calc(100vw - var(--rail) - 2*var(--hgap));
      }}

      /* ë³¸ë¬¸ì´ í•˜ë‹¨ ê³ ì • UIì™€ ê²¹ì¹˜ì§€ ì•Šê²Œ */
      .block-container {{
        padding-bottom: calc(var(--chatbar-h) + var(--chat-gap) + 130px) !important;
      }}

      
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

# í˜¸ì¶œ ìœ„ì¹˜: íŒŒì¼ ë§¨ ì•„ë˜, ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ê·¸ë¦° ë’¤
inject_sticky_layout_css("wide")

# ----- FINAL OVERRIDE: ìš°ì¸¡ í†µí•©ê²€ìƒ‰ íŒ¨ë„ ê°„ê²©/ìœ„ì¹˜ í™•ì • -----

# --- Right flyout: ìƒë‹¨ ê³ ì • + í•˜ë‹¨(ì±„íŒ…ì°½)ê³¼ ê²¹ì¹˜ì§€ ì•Šê²Œ ---
# --- Right flyout: í•˜ë‹¨ ë‹µë³€ì°½(ì…ë ¥ì°½) ìœ„ì— ë§ì¶° ê³ ì • ---
import streamlit as st
st.markdown("""
<style>
  :root{
    /* ìˆ«ìë§Œ ë°”ê¾¸ë©´ ë¯¸ì„¸ì¡°ì • ë©ë‹ˆë‹¤ */
    --flyout-width: 360px;     /* ìš°ì¸¡ íŒ¨ë„ í­ */
    --flyout-gap:   80px;      /* ë³¸ë¬¸ê³¼ íŒ¨ë„ ì‚¬ì´ ê°€ë¡œ ê°„ê²© */
    --chatbar-h:    56px;      /* í•˜ë‹¨ ì…ë ¥ì°½ ë†’ì´ */
    --chat-gap:     12px;      /* ì…ë ¥ì°½ ìœ„ ì—¬ë°± */
    /* íŒ¨ë„ í•˜ë‹¨ì´ ë©ˆì¶œ ìœ„ì¹˜(= ì…ë ¥ì°½ ë°”ë¡œ ìœ„) */
    --flyout-bottom: calc(var(--chatbar-h) + var(--chat-gap) + 16px);
  }

  @media (min-width:1280px){
    /* ë³¸ë¬¸ì´ íŒ¨ë„ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ìš°ì¸¡ ì—¬ë°± í™•ë³´ */
    .block-container{
      padding-right: calc(var(--flyout-width) + var(--flyout-gap)) !important;
    }

    /* íŒ¨ë„: í™”ë©´ í•˜ë‹¨ ê¸°ì¤€ìœ¼ë¡œ â€˜ì…ë ¥ì°½ ìœ„â€™ì— ë”± ë¶™ì´ê¸° */
    #search-flyout{
      position: fixed !important;
      bottom: var(--flyout-bottom) !important;  /* â¬… í•µì‹¬: ë‹µë³€ì°½ ìœ„ì— ì •ë ¬ */
      top: auto !important;                     /* ê¸°ì¡´ top ê·œì¹™ ë¬´ë ¥í™” */
      right: 24px !important; left: auto !important;

      width: var(--flyout-width) !important;
      max-width: 38vw !important;

      /* íŒ¨ë„ ë‚´ë¶€ë§Œ ìŠ¤í¬ë¡¤ë˜ê²Œ ìµœëŒ€ ë†’ì´ ì œí•œ */
      max-height: calc(100vh - var(--flyout-bottom) - 24px) !important;
      overflow: auto !important;

      z-index: 58 !important; /* ì…ë ¥ì°½(ë³´í†µ z=70)ë³´ë‹¤ ë‚®ê²Œ */
    }
  }

  /* ëª¨ë°”ì¼/ì¢ì€ í™”ë©´ì€ ìì—° íë¦„ */
  @media (max-width:1279px){
    #search-flyout{ position: static !important; max-height:none !important; overflow:visible !important; }
    .block-container{ padding-right: 0 !important; }
  }
</style>
""", unsafe_allow_html=True)



# --- ê°„ë‹¨ í† í°í™”/ì •ê·œí™”(ì´ë¯¸ ì“°ê³  ìˆë˜ ê²ƒê³¼ í˜¸í™˜) ---
# === Tokenize & Canonicalize (ìœ í‹¸ ìµœìƒë‹¨ì— ë°°ì¹˜) ===
import re
from typing import Iterable, List

TOKEN_RE = re.compile(r"[ê°€-í£A-Za-z0-9]{2,}")

def _tok(s: str) -> List[str]:
    """í•œê¸€/ì˜ë¬¸/ìˆ«ì 2ì ì´ìƒ í† í°ë§Œ ì¶”ì¶œ"""
    return TOKEN_RE.findall(s or "")

_CANON = {
    # ìì£¼ ë‚˜ì˜¤ëŠ” ì¶•ì•½/ë™ì˜ì–´ë§Œ ìµœì†Œí™” (í•„ìš” ì‹œ í™•ì¥)
    "ì†ë°°": "ì†í•´ë°°ìƒ",
    "ì°¨ëŸ‰": "ìë™ì°¨",
    "êµíŠ¹ë²•": "êµí†µì‚¬ê³ ì²˜ë¦¬",
}

def _canonize(tokens: Iterable[str]) -> List[str]:
    """í† í°ì„ í‘œì¤€í˜•ìœ¼ë¡œ ì¹˜í™˜"""
    return [_CANON.get(t, t) for t in tokens]


# --- ë ˆë²¤ìŠˆíƒ€ì¸: 1ê¸€ì ì´ë‚´ ì˜¤íƒˆì êµì •ìš©(ê°€ë²¼ìš´ êµ¬í˜„) ---
def _lev1(a: str, b: str) -> int:
    # ê±°ë¦¬ 0/1/2ë§Œ ë¹ ë¥´ê²Œ íŒë³„
    if a == b: return 0
    if abs(len(a) - len(b)) > 1: return 2
    # ê°™ì€ ê¸¸ì´: ì¹˜í™˜ 1íšŒ ì´ë‚´ ê²€ì‚¬
    if len(a) == len(b):
        diff = sum(1 for x, y in zip(a, b) if x != y)
        return 1 if diff == 1 else 2
    # í•˜ë‚˜ ê¸¸ì´ ì°¨: ì‚½ì…/ì‚­ì œ 1íšŒ ì´ë‚´ ê²€ì‚¬
    if len(a) > len(b): a, b = b, a
    i = j = edits = 0
    while i < len(a) and j < len(b):
        if a[i] == b[j]:
            i += 1; j += 1
        else:
            edits += 1; j += 1
            if edits > 1: return 2
    return 1 if edits <= 1 else 2

def _closest_token_1edit(t: str, U: set[str]) -> str | None:
    best = None; best_d = 2
    for u in U:
        d = _lev1(t, u)
        if d < best_d:
            best, best_d = u, d
            if best_d == 0: break
    return best if best_d <= 1 else None

def _sanitize_plan_q(user_q: str, q: str) -> str:
    """
    í”Œëœ q ì•ˆì˜ í† í° ì¤‘ ì‚¬ìš©ì ì§ˆë¬¸ì— ì—†ëŠ” í† í°ì„
    'í•œ ê¸€ì ì´ë‚´'ë¡œ ê°€ê¹Œìš´ ì‚¬ìš©ì í† í°ìœ¼ë¡œ êµì²´(ì˜ˆ: ì£¼ì°¨ì â†’ ì£¼ì°¨ì¥).
    """
    U = set(_canonize(_tok(user_q)))
    T = _canonize(_tok(q))
    repl = {}
    for t in T:
        if t not in U and len(t) >= 2:
            cand = _closest_token_1edit(t, U)
            if cand:
                repl[t] = cand
    # í•œêµ­ì–´ëŠ” \b ê²½ê³„ê°€ ì•½í•˜ë¯€ë¡œ ë‹¨ìˆœ ì¹˜í™˜(ë¶€ë¶„ì¹˜í™˜ ìœ„í—˜ ë‚®ìŒ)
    for a, b in repl.items():
        q = q.replace(a, b)
    return q

# ---- ì˜¤ë¥¸ìª½ í”Œë¡œíŒ… íŒ¨ë„ ë Œë”ëŸ¬ ----
def render_search_flyout(user_q: str, num_rows: int = 8,
                         hint_laws: list[str] | None = None,
                         hint_articles: list[tuple[str,str]] | None = None,
                         show_debug: bool = False):
    results = find_all_law_data(user_q, num_rows=num_rows, hint_laws=hint_laws)

    def _pick(*cands):
        for c in cands:
            if isinstance(c, str) and c.strip():
                return c.strip()
        return ""
    
    from urllib.parse import urlencode, quote

    def _pick(*cands):
        for c in cands:
            if isinstance(c, str) and c.strip():
                return c.strip()
        return ""

    from urllib.parse import urlencode, quote

    def _build_law_link(it: dict, eff: str | None = None, out_type: str = "HTML") -> str:
        link = _pick(
            it.get("ë²•ë ¹ìƒì„¸ë§í¬"),
            it.get("ìƒì„¸ë§í¬"),
            it.get("url"), it.get("link"), it.get("detail_url"),
        )
        if link:
            return normalize_law_link(link)
        mst = _pick(it.get("MST"), it.get("mst"), it.get("LawMST"))
        if not mst:
            return ""
        oc = (globals().get("LAW_API_OC") or "").strip()
        if not oc:
            return ""
        qs = {"OC": oc, "target": "law", "MST": str(mst), "type": out_type}
        ef_clean = (eff or "").replace("-", "")
        if ef_clean:
            qs["efYd"] = ef_clean
        return "https://www.law.go.kr/DRF/lawService.do?" + urlencode(qs, quote_via=quote)

    # â”€â”€ ì—¬ê¸°ë¶€í„° HTML ì¡°ë¦½ë¶€ ...
    html: list[str] = []
     
    def _law_item_li(it):
        title = _pick(it.get("ë²•ë ¹ëª…í•œê¸€"), it.get("ë²•ë ¹ëª…"), it.get("title_kr"), it.get("title"), it.get("name_ko"), it.get("name"))
        dept  = _pick(it.get("ì†Œê´€ë¶€ì²˜"), it.get("ë¶€ì²˜ëª…"), it.get("dept"), it.get("department"))
        eff   = _pick(it.get("ì‹œí–‰ì¼ì"), it.get("eff"), it.get("effective_date"))
        pub   = _pick(it.get("ê³µí¬ì¼ì"), it.get("pub"), it.get("promulgation_date"))
        link  = _build_law_link(it, eff)

        parts = [f'<span class="title">{title or "(ì œëª© ì—†ìŒ)"} </span>']
        meta  = []
        if dept: meta.append(f"ì†Œê´€ë¶€ì²˜: {dept}")
        if eff or pub: meta.append(f"ì‹œí–‰ì¼ì: {eff} / ê³µí¬ì¼ì: {pub}")
        if meta: parts.append(f'<div class="meta">{" / ".join(meta)}</div>')
        if link: parts.append(f'<a href="{link}" target="_blank" rel="noreferrer">ë²•ë ¹ ìƒì„¸ë³´ê¸°</a>')
        return "<li>" + "\n".join(parts) + "</li>"

    # í—¤ë”
    html = ['<div id="search-flyout">', '<h3>ğŸ“š í†µí•© ê²€ìƒ‰ ê²°ê³¼</h3>', '<details open><summary>ì—´ê¸°/ì ‘ê¸°</summary>']

    # ë²„í‚· ë Œë”
    for label in ["ë²•ë ¹", "í–‰ì •ê·œì¹™", "ìì¹˜ë²•ê·œ", "ì¡°ì•½"]:
        pack  = results.get(label) or {}
        items = pack.get("items") or []
        html.append(f'<h4>ğŸ” {label}</h4>')
        if not items:
            html.append('<p>ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ</p>')
        else:
            html.append('<ol class="law-list">')
            html += [_law_item_li(it) for it in items]
            html.append('</ol>')

        if show_debug:
            tried = (pack.get("debug") or {}).get("tried") or []
            plans = (pack.get("debug") or {}).get("plans") or []
            err   = pack.get("error")
            dbg = []
            if tried: dbg.append("ì‹œë„: " + " | ".join(tried))
            if plans: dbg.append("LLM plans: " + " | ".join([f"{p.get('target')}:{p.get('q')}" for p in plans]))
            if err:   dbg.append("ì˜¤ë¥˜: " + err)
            if dbg:   html.append("<small class='debug'>" + "<br/>".join(dbg) + "</small>")

    html.append("</details></div>")
    st.markdown("\n".join(html), unsafe_allow_html=True)

  # â¬‡ï¸ ì´ ë¸”ë¡ë§Œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš” (ê¸°ì¡´ header st.markdown(...) ë¸”ë¡ì€ ì‚­ì œ)
# app.py (í•˜ë‹¨)

# =========================================
# ì„¸ì…˜ì— ì„ì‹œë¡œ ë‹´ì•„ ë‘” ì²« ì§ˆë¬¸ì„ messagesë¡œ ì˜®ê¸°ëŠ” ìœ í‹¸
# (ì´ ë¸”ë¡ì„ íŒŒì¼ ìƒë‹¨ â€˜ë ˆì´ì•„ì›ƒ/ìŠ¤íƒ€ì¼ ì£¼ì…â€™ ì§í›„ ì •ë„ë¡œ ì˜¬ë ¤ë‘¡ë‹ˆë‹¤)
# =========================================
from datetime import datetime

has_chat = bool(st.session_state.get("messages")) or bool(st.session_state.get("_pending_user_q"))


# âœ… ì¤‘ìš”: â€˜ìµœì´ˆ í™”ë©´â€™ ë Œë”ë§ ì „ì— ë¨¼ì € í˜¸ì¶œ

from datetime import datetime
import time
import streamlit as st

def _push_user_from_pending() -> str | None:
    """í¼ì—ì„œ ë„£ì–´ë‘” _pending_user_që¥¼ ë©”ì‹œì§€ë¡œ ì˜®ê¹€ (ì¤‘ë³µ ë°©ì§€ í¬í•¨)"""
    q = st.session_state.pop("_pending_user_q", None)
    nonce = st.session_state.pop("_pending_user_nonce", None)
    if not q:
        return None
    if nonce and st.session_state.get("_last_user_nonce") == nonce:
        return None

    # === ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬: ì—…ë¡œë“œëœ íŒŒì¼ í…ìŠ¤íŠ¸ë¥¼ ì§ˆë¬¸ ë’¤ì— ë¶€ì°© ===
    try:
        att_payload = st.session_state.pop("_pending_user_files", None)
    except Exception:
        att_payload = None

    # ìš°ì„ ìˆœìœ„: ëª…ì‹œ payload > í¬ìŠ¤íŠ¸-ì±— ì—…ë¡œë” > í”„ë¦¬ì±— ì—…ë¡œë” > í•˜ë‹¨ ì—…ë¡œë”
    files_to_read = []
    try:
        if att_payload:
            for it in att_payload:
                name = it.get("name") or "uploaded"
                data = it.get("data", b"")
                mime = it.get("type") or ""
                files_to_read.append(("__bytes__", name, data, mime))
    except Exception:
        pass
    # ìŠ¤íŠ¸ë¦¼ë¦¿ ì—…ë¡œë”ì—ì„œ ì§ì ‘ ì½ê¸° (fallback)
    for key in ("post_files", "first_files", "bottom_files"):
        try:
            for f in (st.session_state.get(key) or []):
                files_to_read.append(("__widget__", getattr(f, "name", "uploaded"), f, getattr(f, "type", "")))
        except Exception:
            pass

    def _try_extract(name, src, mime):
        txt = ""
        try:
            # utils_extract ì‚¬ìš© ìš°ì„ 
            if name.lower().endswith(".pdf"):
                try:
                    txt = extract_text_from_pdf(src)
                except Exception:
                    import io
                    try:
                        data = src if isinstance(src, (bytes, bytearray)) else src.read()
                        txt = extract_text_from_pdf(io.BytesIO(data))
                    except Exception:
                        txt = ""
            elif name.lower().endswith(".docx"):
                try:
                    txt = extract_text_from_docx(src)
                except Exception:
                    import io
                    try:
                        data = src if isinstance(src, (bytes, bytearray)) else src.read()
                        txt = extract_text_from_docx(io.BytesIO(data))
                    except Exception:
                        txt = ""
            elif name.lower().endswith(".txt"):
                try:
                    if hasattr(src, "read"):
                        data = src.read()
                        try: src.seek(0)
                        except Exception: pass
                    else:
                        data = src if isinstance(src, (bytes, bytearray)) else b""
                    txt = read_txt(data)
                except Exception:
                    try:
                        txt = data.decode("utf-8", errors="ignore")
                    except Exception:
                        txt = ""
        except Exception:
            txt = ""
        return sanitize(txt) if "sanitize" in globals() else txt

    ATTACH_LIMIT_PER_FILE = 6000   # chars
    ATTACH_TOTAL_LIMIT    = 16000  # chars

    pieces = []
    total = 0
    for kind, name, src, mime in files_to_read[:6]:
        try:
            t = _try_extract(name, src if kind=="__widget__" else src, mime) or ""
        except Exception:
            t = ""
        if not t:
            continue
        t = t.strip()
        if not t:
            continue
        t = t[:ATTACH_LIMIT_PER_FILE]
        if total + len(t) > ATTACH_TOTAL_LIMIT:
            t = t[: max(0, ATTACH_TOTAL_LIMIT - total) ]
        if not t:
            break
        pieces.append(f"### {name}\\n{t}")
        total += len(t)
        if total >= ATTACH_TOTAL_LIMIT:
            break

    attach_block = "\\n\\n".join(pieces) if pieces else ""

    # === ìµœì¢… ì½˜í…ì¸  í•©ì„± ===
    content_final = q.strip()
    if attach_block:
        content_final += "\\n\\n[ì²¨ë¶€ ë¬¸ì„œ ë°œì·Œ]\\n" + attach_block + "\\n"
    else:
        content_final = q.strip()
    # (NEW) content_finalì´ ì—†ìœ¼ë©´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ì´ˆê¸°í™”
    content_final = locals().get('content_final', (q or "").strip())
    st.session_state.messages.append({
        "role": "user",
        "content": content_final,
        "ts": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    })
    st.session_state["_last_user_nonce"] = nonce
    st.session_state["current_turn_nonce"] = nonce  # âœ… ì´ í„´ì˜ nonce í™•ì •
    # reset duplicate-answer guard for a NEW user turn
    st.session_state.pop('_last_ans_hash', None)

    return content_final

def render_pre_chat_center():
    st.markdown('<section class="center-hero">', unsafe_allow_html=True)
    st.markdown('<h1 style="font-size:38px;font-weight:800;letter-spacing:-.5px;margin-bottom:24px;">ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?</h1>', unsafe_allow_html=True)

    # ì¤‘ì•™ ì—…ë¡œë”
    st.file_uploader(
        "Drag and drop files here",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="first_files",
    )

    # ì…ë ¥ í¼
    with st.form("first_ask", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”...", key="first_input")
        sent = st.form_submit_button("ì „ì†¡", use_container_width=True)

    # âœ… ëŒ€í™” ìŠ¤íƒ€í„° ë²„íŠ¼ (2ì¤„ 2ì¤„)
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ê±´ì„¤í˜„ì¥ ì¤‘ëŒ€ì¬í•´ ë°œìƒì‹œ ì²˜ë¦¬ ì ˆì°¨ëŠ”?", use_container_width=True):
            st.session_state["_pending_user_q"] = "ê±´ì„¤í˜„ì¥ ì¤‘ëŒ€ì¬í•´ ë°œìƒì‹œ ì²˜ë¦¬ ì ˆì°¨ëŠ”?"
            st.session_state["_pending_user_nonce"] = time.time_ns()
            st.rerun()
    with col2:
        if st.button("ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€ ë°©ë²• ì•Œë ¤ì¤˜", use_container_width=True):
            st.session_state["_pending_user_q"] = "ì„ëŒ€ì°¨ ê³„ì•½ í•´ì§€ ë°©ë²• ì•Œë ¤ì¤˜"
            st.session_state["_pending_user_nonce"] = time.time_ns()
            st.rerun()

    col3, col4 = st.columns(2)
    with col3:
        if st.button("ìœ ë£Œì£¼ì°¨ì¥ì— ì£¼ì°¨ëœ ì°¨ì—ì„œ ë„ë‚œ ì‚¬ê±´ì´ ë‚¬ì–´", use_container_width=True):
            st.session_state["_pending_user_q"] = "ìœ ë£Œì£¼ì°¨ì¥ì— ì£¼ì°¨ëœ ì°¨ì—ì„œ ë„ë‚œ ì‚¬ê±´ì´ ë‚¬ì–´?"
            st.session_state["_pending_user_nonce"] = time.time_ns()
            st.rerun()
    with col4:
        if st.button("êµí†µì‚¬ê³  í•©ì˜ ì‹œ ì£¼ì˜í•  ì ì€?", use_container_width=True):
            st.session_state["_pending_user_q"] = "êµí†µì‚¬ê³  í•©ì˜ ì‹œ ì£¼ì˜í•  ì ì€?"
            st.session_state["_pending_user_nonce"] = time.time_ns()
            st.rerun()

    st.markdown("</section>", unsafe_allow_html=True)

    if sent and (q or "").strip():
        st.session_state["_pending_user_q"] = q.strip()
        st.session_state["_pending_user_nonce"] = time.time_ns()
        st.rerun()


# ê¸°ì¡´ render_bottom_uploader() ì „ë¶€ êµì²´

# [ADD] ë‹µë³€ ì™„ë£Œ í›„ì—ë„ í”„ë¦¬ì±—ê³¼ ë™ì¼í•œ UI ì‚¬ìš©
def render_post_chat_simple_ui():
    import time, io
    st.markdown('<section class="post-chat-ui">', unsafe_allow_html=True)

    # ì—…ë¡œë” (í”„ë¦¬ì±—ê³¼ ë™ì¼)
    post_files = st.file_uploader(
        "Drag and drop files here",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="post_files",
    )

    # í…ìŠ¤íŠ¸ ì…ë ¥ + ì „ì†¡ ë²„íŠ¼ (í”„ë¦¬ì±—ê³¼ ë™ì¼)
    with st.form("next_ask", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”...", key="next_input")
        sent = st.form_submit_button("ì „ì†¡", use_container_width=True)

    st.markdown("</section>", unsafe_allow_html=True)

    if sent and (q or "").strip():
        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì„¸ì…˜ì— ë³´ê´€ (ë°”ë¡œ reruní•  ê²ƒì´ë¯€ë¡œ ë°”ì´íŠ¸ë¡œ ì €ì¥)
        safe_payload = []
        try:
            for f in (post_files or []):
                try:
                    data = f.read()
                    f.seek(0)
                except Exception:
                    data = None
                safe_payload.append({
                    "name": getattr(f, "name", "uploaded"),
                    "type": getattr(f, "type", ""),
                    "data": data,
                })
        except Exception:
            pass
        st.session_state["_pending_user_q"] = (q or "").strip()
        st.session_state["_pending_user_nonce"] = time.time_ns()
        st.session_state["_pending_user_files"] = safe_payload
        st.rerun()
def render_bottom_uploader():
    # ì—…ë¡œë” ë°”ë¡œ ì•ì— 'ì•µì»¤'ë§Œ ì¶œë ¥
    st.markdown('<div id="bu-anchor"></div>', unsafe_allow_html=True)

    # ì´ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì—…ë¡œë”ë¥¼ CSSì—ì„œ #bu-anchor + div[...] ë¡œ ê³ ì • ë°°ì¹˜
    st.file_uploader(
        "Drag and drop files here",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="bottom_files",
        help="ëŒ€í™” ì¤‘ì—ëŠ” ì—…ë¡œë“œ ë°•ìŠ¤ê°€ í•˜ë‹¨ì— ê³ ì •ë©ë‹ˆë‹¤.",
    )

# --- ì‘ë™ í‚¤ì›Œë“œ ëª©ë¡(í•„ìš”ì‹œ ë³´ê°•/ìˆ˜ì •) ---
LINKGEN_KEYWORDS = {
    "ë²•ë ¹": ["ì œì •", "ì „ë¶€ê°œì •", "ê°œì •", "íì§€", "ë¶€ì¹™", "ì •ì •", "ì‹œí–‰", "ë³„í‘œ", "ë³„ì§€ì„œì‹"],
    "í–‰ì •ê·œì¹™": ["í›ˆë ¹", "ì˜ˆê·œ", "ê³ ì‹œ", "ì§€ì¹¨", "ê³µê³ ", "ì „ë¶€ê°œì •", "ê°œì •", "ì •ì •", "íì§€"],
    "ìì¹˜ë²•ê·œ": ["ì¡°ë¡€", "ê·œì¹™", "í›ˆë ¹", "ì˜ˆê·œ", "ì „ë¶€ê°œì •", "ê°œì •", "ì •ì •", "íì§€"],
    "ì¡°ì•½": ["ì„œëª…", "ë¹„ì¤€", "ë°œíš¨", "ê³µí¬", "íê¸°"],
    "íŒë¡€": ["ëŒ€ë²•ì›", "ì „ì›í•©ì˜ì²´", "í•˜ê¸‰ì‹¬", "ì†í•´ë°°ìƒ", "ë¶ˆë²•í–‰ìœ„"],
    "í—Œì¬": ["ìœ„í—Œ", "í•©í—Œ", "í•œì •ìœ„í—Œ", "í•œì •í•©í—Œ", "í—Œë²•ë¶ˆí•©ì¹˜"],
    "í•´ì„ë¡€": ["ìœ ê¶Œí•´ì„", "ë²•ë ¹í•´ì„", "ì§ˆì˜íšŒì‹ "],
    "ìš©ì–´/ë³„í‘œ": ["ìš©ì–´", "ì •ì˜", "ë³„í‘œ", "ì„œì‹"],
}

# --- í‚¤ì›Œë“œ ìœ„ì ¯ í—¬í¼: st_tagsê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ multiselectë¡œ ëŒ€ì²´ ---
try:
    from streamlit_tags import st_tags
    def kw_input(label, options, key):
        return st_tags(
            label=label,
            text="ì‰¼í‘œ(,) ë˜ëŠ” Enterë¡œ ì¶”ê°€/ì‚­ì œ",
            value=options,           # âœ… ê¸°ë³¸ê°’: ì „ë¶€ ì±„ì›€
            suggestions=options,
            maxtags=len(options),
            key=key,
        )
except Exception:
    def kw_input(label, options, key):
        return st.multiselect(
            label, options=options, default=options,  # âœ… ê¸°ë³¸ê°’: ì „ë¶€ ì„ íƒ
            key=key, help="í•„ìš” ì—†ëŠ” í‚¤ì›Œë“œëŠ” ì„ íƒ í•´ì œí•˜ì„¸ìš”."
        )



# =============================
# Utilities
# =============================
_CASE_NO_RE = re.compile(r'(19|20)\d{2}[ê°€-í£]{1,3}\d{1,6}')
_HBASE = "https://www.law.go.kr"
LAW_PORTAL_BASE = "https://www.law.go.kr/"

def _chat_started() -> bool:
    msgs = st.session_state.get("messages", [])
    # ì‹¤ì œ ì‚¬ìš©ì ë©”ì‹œì§€ê°€ í•˜ë‚˜ë¼ë„ ìˆì–´ì•¼ 'ëŒ€í™” ì‹œì‘'ìœ¼ë¡œ ê°„ì£¼
    return any(
        (m.get("role") == "user") and (m.get("content") or "").strip()
        for m in msgs
    ) or bool(st.session_state.get("_pending_user_q"))

# --- ìµœì¢… í›„ì²˜ë¦¬ ìœ í‹¸: ë‹µë³€ ë³¸ë¬¸ì„ ì •ë¦¬í•˜ê³  ì¡°ë¬¸ì— ì¸ë¼ì¸ ë§í¬ë¥¼ ë¶™ì¸ë‹¤ ---
# === [NEW] MEMO í…œí”Œë¦¿ ê°•ì œ & 'í•µì‹¬ íŒë‹¨' ë§í¬ ì œê±° ìœ í‹¸ ===
import re as _re_memo

_MEMO_HEADS = [
    (_re_memo.compile(r'(?mi)^\s*1\s*[\.\)]\s*(ì‚¬ê±´\s*ìš”ì§€|ìë¬¸\s*ìš”ì§€)\s*:?.*$', _re_memo.M), "1. ìë¬¸ìš”ì§€ :"),
    (_re_memo.compile(r'(?mi)^\s*2\s*[\.\)]\s*(ì ìš©\s*ë²•ë ¹\s*/?\s*ê·¼ê±°|ë²•ì \s*ê·¼ê±°)\s*:?.*$', _re_memo.M), "2. ì ìš© ë²•ë ¹/ê·¼ê±°"),
    (_re_memo.compile(r'(?mi)^\s*3\s*[\.\)]\s*(í•µì‹¬\s*íŒë‹¨)\s*:?.*$', _re_memo.M), "3. í•µì‹¬ íŒë‹¨"),
    (_re_memo.compile(r'(?mi)^\s*4\s*[\.\)]\s*(ê¶Œê³ \s*ì¡°ì¹˜)\s*:?.*$', _re_memo.M), "4. ê¶Œê³  ì¡°ì¹˜"),
]

def enforce_memo_template(md: str) -> str:
    if not md:
        return md
    out = md
    for pat, fixed in _MEMO_HEADS:
        out = pat.sub(fixed, out)
    # ë³¸ë¬¸ ë‚´ 'ì‚¬ê±´ìš”ì§€' í‘œê¸°ë¥¼ 'ìë¬¸ìš”ì§€'ë¡œ í†µì¼
    out = _re_memo.sub(r'(?i)ì‚¬ê±´\s*ìš”ì§€', 'ìë¬¸ìš”ì§€', out)
    return out

_SEC_CORE_TITLE = _re_memo.compile(r'(?mi)^\s*3\s*[\.\)]\s*í•µì‹¬\s*íŒë‹¨\s*$', _re_memo.M)
_SEC_NEXT_TITLE2 = _re_memo.compile(r'(?m)^\s*\d+\s*[\.\)]\s+')

def strip_links_in_core_judgment(md: str) -> str:
    if not md:
        return md
    m = _SEC_CORE_TITLE.search(md)
    if not m:
        return md
    start = m.end()
    n = _SEC_NEXT_TITLE2.search(md, start)
    end = n.start() if n else len(md)
    block = md[start:end]
    # [í…ìŠ¤íŠ¸](http...) í˜•íƒœì˜ ë§í¬ ì œê±°
    block = _re_memo.sub(r'\[([^\]]+)\]\((?:https?:\/\/)[^)]+\)', r'\1', block)
    return md[:start] + block + md[end:]

def apply_final_postprocess(full_text: str, collected_laws: list) -> str:
    # 1) normalize (fallback í¬í•¨)
    try:
        ft = _normalize_text(full_text)
    except NameError:
        import re as _re
        def _normalize_text(s: str) -> str:
            s = (s or "").replace("\r\n", "\n").replace("\r", "\n").strip()
            s = _re.sub(r"\n{3,}", "\n\n", s)
            s = _re.sub(r"[ \t]+\n", "\n", s)
            return s
        ft = _normalize_text(full_text)

    # 2) ë¶ˆë¦¿ ë¬¸ì í†µì¼: â€¢, * â†’ -  (ì¸ë¼ì¸ ë§í¬ ì¹˜í™˜ ëˆ„ë½ ë°©ì§€)
    ft = (
        ft.replace("\u2022 ", "- ")  # ìœ ë‹ˆì½”ë“œ ë¶ˆë¦¿
          .replace("â€¢ ", "- ")
          .replace("* ", "- ")
    )

    # âœ… (NEW) MEMO ì œëª©/ë²ˆí˜¸/ì½œë¡  ê°•ì œ
    ft = enforce_memo_template(ft)


    # 3) ì¡°ë¬¸ ì¸ë¼ì¸ ë§í¬ ë³€í™˜:  - ë¯¼ë²• ì œ839ì¡°ì˜2 â†’ [ë¯¼ë²• ì œ839ì¡°ì˜2](...)
    ft = link_articles_in_law_and_explain_sections(ft)
    ft = strip_redundant_article_link_words(ft)   # â† ì‰ì—¬ "ì œnì¡° ë§í¬" ì œê±°
# 4) ë³¸ë¬¸ ë‚´ [ë²•ë ¹ëª…](URL) êµì • ...
    ft = fix_links_with_lawdata(ft, collected_laws)


    # 4) ë³¸ë¬¸ ë‚´ [ë²•ë ¹ëª…](URL) êµì •(ë²•ì œì²˜ ê³µì‹ ë§í¬ë¡œ)
    ft = fix_links_with_lawdata(ft, collected_laws)

    # âœ… (NEW) '3. í•µì‹¬ íŒë‹¨' ì„¹ì…˜ì˜ ë§í¬ ì œê±°
    ft = strip_links_in_core_judgment(ft)


    # 5) ë§¨ ì•„ë˜ 'ì°¸ê³  ë§í¬(ì¡°ë¬¸)' ì„¹ì…˜ ì œê±°(ì¤‘ë³µ ë°©ì§€)
    ft = strip_reference_links_block(ft)

    # 6) ì¤‘ë³µ/ë¹ˆ ì¤„ ì •ë¦¬
    ft = _dedupe_blocks(ft)

    return ft



# --- ë‹µë³€(ë§ˆí¬ë‹¤ìš´)ì—ì„œ 'ë²•ë ¹ëª…'ë“¤ì„ ì¶”ì¶œ(ë³µìˆ˜) ---

# [ë¯¼ë²• ì œ839ì¡°ì˜2](...), [ê°€ì‚¬ì†Œì†¡ë²• ì œ2ì¡°](...) ë“±
_LAW_IN_LINK = re.compile(r'\[([^\]\n]+?)\s+ì œ\d+ì¡°(ì˜\d+)?\]')
# ë¶ˆë¦¿/ì¼ë°˜ ë¬¸ì¥ ë‚´: "OOë²•/ë ¹/ê·œì¹™/ì¡°ë¡€" (+ì„ íƒì  'ì œnì¡°')
_LAW_INLINE  = re.compile(r'([ê°€-í£A-Za-z0-9Â·\s]{2,40}?(?:ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€))(?:\s*ì œ\d+ì¡°(ì˜\d+)?)?')

def extract_law_names_from_answer(md: str) -> list[str]:
    if not md:
        return []
    names = set()

    # 1) ë§í¬ í…ìŠ¤íŠ¸ ì•ˆì˜ ë²•ë ¹ëª…
    for m in _LAW_IN_LINK.finditer(md):
        nm = (m.group(1) or "").strip()
        if nm:
            names.add(nm)

    # 2) ì¼ë°˜ í…ìŠ¤íŠ¸/ë¶ˆë¦¿ì—ì„œ ë²•ë ¹ëª… íŒ¨í„´
    for m in _LAW_INLINE.finditer(md):
        nm = (m.group(1) or "").strip()
        # ê³¼ì í•© ë°©ì§€: ë„ˆë¬´ ì§§ì€/ê¸´ ê²ƒ ì œì™¸
        if 2 <= len(nm) <= 40:
            names.add(nm)

    # ì •ë¦¬(ì¤‘ë³µ ì œê±° + ê¸¸ì´ ì»· + ìƒìœ„ 6ê°œ)
    out, seen = [], set()
    for n in names:
        n2 = n[:40]
        if n2 and n2 not in seen:
            seen.add(n2)
            out.append(n2)
    return out[:6]

# ===== ì¡°ë¬¸ ì¶”ì¶œ: ë‹µë³€ì—ì„œ (ë²•ë ¹ëª…, ì œnì¡°[ì˜m]) í˜ì–´ ì¶”ì¶œ =====
import re as _re_art

_ART_INLINE = _re_art.compile(
    r'(?P<law>[ê°€-í£A-Za-z0-9Â·\s]{2,40}?(?:ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€))\s*ì œ(?P<num>\d{1,4})ì¡°(?P<ui>ì˜\d{1,3})?'
)

def extract_article_pairs_from_answer(md: str) -> list[tuple[str, str]]:
    pairs = []
    for m in _ART_INLINE.finditer(md or ""):
        law = (m.group("law") or "").strip()
        art = f"ì œ{m.group('num')}ì¡°{m.group('ui') or ''}"
        if law:
            pairs.append((law, art))
    # ìˆœì„œ ìœ ì§€ ì¤‘ë³µ ì œê±°
    seen = set(); out = []
    for p in pairs:
        if p not in seen:
            seen.add(p)
            out.append(p)
    return out[:8]

def normalize_law_link(u: str) -> str:
    """ìƒëŒ€/ìŠ¤í‚´ëˆ„ë½ ë§í¬ë¥¼ www.law.go.kr ì ˆëŒ€ URLë¡œ êµì •"""
    if not u: return ""
    u = u.strip()
    if u.startswith("http://") or u.startswith("https://"): return u
    if u.startswith("//"): return "https:" + u
    if u.startswith("/"):  return up.urljoin(LAW_PORTAL_BASE, u.lstrip("/"))
    return up.urljoin(LAW_PORTAL_BASE, u)

def _normalize_text(s: str) -> str:
    s = (s or "").replace("\r\n", "\n").replace("\r", "\n")
    lines = [ln.rstrip() for ln in s.split("\n")]
    while lines and not lines[0].strip():
        lines.pop(0)
    while lines and not lines[-1].strip():
        lines.pop()
    merged, i = [], 0
    num_pat = re.compile(r'^\s*((\d+)|([IVXLC]+)|([ivxlc]+))\s*[\.\)]\s*$')
    while i < len(lines):
        cur = lines[i]; m = num_pat.match(cur)
        if m:
            j = i + 1
            while j < len(lines) and not lines[j].strip(): j += 1
            if j < len(lines):
                number = (m.group(2) or m.group(3) or m.group(4)).upper()
                title = lines[j].lstrip()
                merged.append(f"{number}. {title}")
                i = j + 1; continue
        merged.append(cur); i += 1
    out, prev_blank = [], False
    for ln in merged:
        if ln.strip() == "":
            if not prev_blank: out.append("")
            prev_blank = True
        else:
            prev_blank = False; out.append(ln)
    return "\n".join(out)

# === [PATCH A] ì¡°ë¬¸ ì§ë§í¬(ì¸ë¼ì¸) + í•˜ë‹¨ 'ì°¸ê³  ë§í¬' ì„¹ì…˜ ì œê±° ===
import re
from urllib.parse import quote

# ì¡°ë¬¸ íŒ¨í„´: ë¯¼ë²• ì œ839ì¡°ì˜2, ë¯¼ì‚¬ì†Œì†¡ë²• ì œ163ì¡° ë“±
# app.py â€” [PATCH] ì¡°ë¬¸ íŒ¨í„´: ë¶ˆë¦¿(*)ì´ 'ì„ íƒ'ì´ ë˜ë„ë¡
_ART_PAT_BULLET = re.compile(
    r'(?m)^(?P<prefix>\s*(?:[-*â€¢]\s*)?)'                  # ë¶ˆë¦¿ ê¸°í˜¸ë¥¼ ì˜µì…˜ìœ¼ë¡œ
    r'(?P<law>[ê°€-í£A-Za-z0-9Â·()\s]{2,40})\s*'
    r'ì œ(?P<num>\d{1,4})ì¡°(?P<ui>(ì˜\d{1,3}){0,2})'
    r'(?P<tail>[^\n]*)$'
)


# --- [NEW] 'ì ìš© ë²•ë ¹/ê·¼ê±°' + 'í•´ì„¤' ì„¹ì…˜ì—ì„œë§Œ ì¡°ë¬¸ ë§í¬ í™œì„±í™” ---
# ì„¹ì…˜ ì œëª© ì¸ì‹
_SEC_LAW_TITLES    = re.compile(r'(?mi)^\s*\d+\s*[\.\)]\s*(ì ìš©\s*ë²•ë ¹\s*/?\s*ê·¼ê±°|ë²•ì \s*ê·¼ê±°)\s*$')
_SEC_EXPLAIN_TITLE = re.compile(r'(?mi)^\s*(?:#{1,6}\s*)?í•´ì„¤\s*:?\s*$')
# ë‹¤ìŒ ìƒìœ„ ì„¹ì…˜(ì˜ˆ: "3. í•µì‹¬ íŒë‹¨") ì‹œì‘ ë¼ì¸
_SEC_NEXT_TITLE = re.compile(r'(?m)^\s*\d+\s*[\.\)]\s+')

# í•´ì„¤ ì„¹ì…˜ ë‚´ë¶€ì˜ 'ë§¨ëª¸ URL'(ìˆœìˆ˜ ë¬¸ìì—´ URL)ì„ <URL> í˜•íƒœë¡œ ê°ì‹¸ì„œ ìë™ ë§í¬í™”
_URL_BARE = re.compile(r'(?<!\()(?<!\])\b(https?://[^\s<>)]+)\b')
def autolink_bare_urls_in_explain(md: str) -> str:
    if not md:
        return md
    m = _SEC_EXPLAIN_TITLE.search(md)
    if not m:
        return md
    start = m.end()
    n = _SEC_NEXT_TITLE.search(md, start)
    end = n.start() if n else len(md)
    block = md[start:end]
    # ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ ë§í¬([text](url))ëŠ” ê·¸ëŒ€ë¡œ ë‘ê³ , ë§¨ëª¸ URLë§Œ <url>ë¡œ ê°ì‹¼ë‹¤
    def _wrap(match):
        url = match.group(1)
        return f'<{url}>'
    block = _URL_BARE.sub(_wrap, block)
    return md[:start] + block + md[end:]
st.markdown(
    """
    <div style="text-align:center; padding: 6px 0 2px;">
      <h1 style="
          margin:0;
          font-size:48px;
          font-weight:800;
          line-height:1.1;
          letter-spacing:-0.5px;">
        ì¸ê³µì§€ëŠ¥ <span style="color:#2F80ED">ë²•ë¥  ìƒë‹´ê°€</span>
      </h1>
    </div>
    <hr style="margin: 12px 0 20px; border: 0; height: 1px; background: #eee;">
    """,
    unsafe_allow_html=True
)

# ë³¸ë¬¸
st.markdown("""
êµ­ê°€ë²•ë ¹ì •ë³´ DBë¥¼ ì§ì ‘ ì ‘ì†í•˜ì—¬ ìµœì‹  ë²•ë ¹ì„ ì¡°íšŒí•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.  
ì €ëŠ” ë‚´ë¶€ DBë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ ì±„íŒ… ê¸°ë¡, ì²¨ë¶€íŒŒì¼ ë“± ì‚¬ìš©ìì˜ ê¸°ë¡ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.             
""")

# í•˜ìœ„ ë²•ë ¹ ì†Œì œëª©(ì˜ˆ: "1) ì‚°ì—…ì•ˆì „ë³´ê±´ë²•")
# ë²ˆí˜¸/í—¤ë”©/ë¶ˆë¦¿ì´ ìˆì–´ë„ ì—†ì–´ë„ ì¡íˆê²Œ ì™„í™”
_LAW_HEADING_LINE = re.compile(
    r'(?m)^\s*(?:\d+\s*[\.\)]\s*)?(?:#{1,6}\s*)?(?:[*-]\s*)?(?P<law>[ê°€-í£A-Za-z0-9Â·()\s]{2,40}?ë²•)\s*$'
)


# ë¶ˆë¦¿ì— "ë²•ë ¹ëª… ì œnì¡° ..." íŒ¨í„´(ê¸°ì¡´ ì „ì—­ì˜ _ART_PAT_BULLET ì¬ì‚¬ìš©)
# _ART_PAT_BULLET, _deep_article_url ì´ ì´ë¯¸ ì •ì˜ë¼ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

# ë¶ˆë¦¿ì— "ì œnì¡°"ë§Œ ìˆê³  ë²•ë ¹ëª…ì´ ìƒëµëœ ë‹¨ìˆœí˜•
_BULLET_ART_SIMPLE = re.compile(
    r'(?m)^(?P<prefix>\s*[-*â€¢]\s*)ì œ(?P<num>\d{1,4})ì¡°(?P<ui>(ì˜\d{1,3}){0,2})?(?P<title>\([^)]+\))?(?P<tail>[^\n]*)$'
)

# í•´ì„¤ ì„¹ì…˜ì—ì„œì˜ ì¸ë¼ì¸ "ë²•ë ¹ëª… ì œnì¡°" íŒ¨í„´
_ART_INLINE_IN_EXPL = re.compile(
    r'(?P<law>[ê°€-í£A-Za-z0-9Â·()\s]{1,40}?ë²•)\s*ì œ(?P<num>\d{1,4})ì¡°(?P<ui>(ì˜\d{1,3}){0,2})?'
)

def _link_block_with_bullets(block: str) -> str:
    """ë²•ë ¹/ê·¼ê±° ì„¹ì…˜ ë¸”ë¡: ì†Œì œëª©ì˜ ë²•ë ¹ëª…ì„ ê¸°ì–µí•´ ì•„ë˜ ë¶ˆë¦¿ì˜ 'ì œnì¡°'ì— ë§í¬ ë¶€ì—¬."""
    cur_law = None
    out = []
    for line in block.splitlines():
        mh = _LAW_HEADING_LINE.match(line)
        if mh:
            cur_law = (mh.groupdict().get('law') or (mh.group(1) if mh.lastindex else "") or "").strip() or cur_law
            out.append(line)
            continue

        mf = _ART_PAT_BULLET.match(line)
        if mf:
            law = (mf.group("law") or "").strip() or cur_law
            if law:
                art  = f"ì œ{mf.group('num')}ì¡°{mf.group('ui') or ''}"
                url  = _deep_article_url(law, art)
                tail = (mf.group("tail") or "")
                out.append(f"{mf.group('prefix')}[{law} {art}]({url}){tail}")
                continue

        ms = _BULLET_ART_SIMPLE.match(line)
        if ms and cur_law:
            art   = f"ì œ{ms.group('num')}ì¡°{ms.group('ui') or ''}"
            title = (ms.group('title') or '')
            tail  = (ms.group('tail') or '')
            url   = _deep_article_url(cur_law, art)
            txt = f"{art}{title or ''}"                      # ì˜ˆ: "ì œ76ì¡°(ì™¸êµ­ì—ì„œì˜ í˜¼ì¸ì‹ ê³ )"
            out.append(f"{ms.group('prefix')}[{txt}]({url}){tail}")

            continue

        out.append(line)
    return "\n".join(out)

def _link_inline_in_explain(block: str) -> str:
    """í•´ì„¤ ì„¹ì…˜ ë¸”ë¡: ì¸ë¼ì¸ 'ë²•ë ¹ëª… ì œnì¡°'ë¥¼ ë§í¬ë¡œ ì¹˜í™˜."""
    def repl(m):
        law = m.group('law').strip()
        art = f"ì œ{m.group('num')}ì¡°{m.group('ui') or ''}"
        return f"[{law} {art}]({_deep_article_url(law, art)})"
    return _ART_INLINE_IN_EXPL.sub(repl, block)

def link_articles_in_law_and_explain_sections(md: str) -> str:
    """
    '2. ì ìš© ë²•ë ¹/ê·¼ê±°'ì™€ 'í•´ì„¤' ì„¹ì…˜ì—ì„œë§Œ ì¡°ë¬¸ ë§í¬ë¥¼ í™œì„±í™”í•œë‹¤.
    ê·¸ ì™¸(ì˜ˆ: '3. í•µì‹¬ íŒë‹¨')ì—ëŠ” ë§í¬ë¥¼ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤.
    """
    if not md:
        return md

    ranges = []

    # ì ìš© ë²•ë ¹/ê·¼ê±° ì„¹ì…˜(1ê°œ ê°€ì •)
    m = _SEC_LAW_TITLES.search(md)
    if m:
        n = _SEC_NEXT_TITLE.search(md, m.end())
        ranges.append(("law", m.start(), n.start() if n else len(md)))

    # í•´ì„¤ ì„¹ì…˜(ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆìŒ)
    for m in _SEC_EXPLAIN_TITLE.finditer(md):
        n = _SEC_NEXT_TITLE.search(md, m.end())
        ranges.append(("explain", m.start(), n.start() if n else len(md)))

    if not ranges:
        return md

    ranges.sort(key=lambda x: x[1])

    out = []
    last = 0
    for kind, s, e in ranges:
        out.append(md[last:s])
        block = md[s:e]
        if kind == "law":
            out.append(_link_block_with_bullets(block))
        else:  # explain
            out.append(_link_inline_in_explain(block))
        last = e
    out.append(md[last:])
    return "".join(out)


# í•˜ë‹¨ 'ì°¸ê³  ë§í¬' ì œëª©(ëª¨ë¸ì´ 7. ë˜ëŠ” 7) ë“±ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ì¼€ì´ìŠ¤ í¬í•¨)
_REF_BLOCK_PAT = re.compile(
    r'(?ms)^\s*\d+\s*[\.\)]\s*ì°¸ê³ \s*ë§í¬\s*[:ï¼š]?\s*\n(?:\s*[-*â€¢].*\n?)+'
)
# ì•ì— ê³µë°±ì´ ìˆì–´ë„ ë§¤ì¹­ë˜ë„ë¡ ë³´ê°•
_REF_BLOCK2_PAT = re.compile(r'\n[ \t]*###\s*ì°¸ê³ \s*ë§í¬\(ì¡°ë¬¸\)[\s\S]*$', re.M)

# app.py â€” ì•ˆì „ ë§í¬ í—¬í¼ (ê¸°ì¡´ _deep_article_url ëŒ€ì²´)
from urllib.parse import quote as _q

def _article_url_or_main(law: str, art_label: str, verify: bool = True, timeout: float = 2.5) -> str:
    base = "https://www.law.go.kr/ë²•ë ¹"
    law = (law or "").strip(); art = (art_label or "").strip()
    cand = [
        f"{base}/{law}/{art}",                         # 1) ë¯¸ì¸ì½”ë”©
        f"{base}/{_q(law, safe='')}/{_q(art, safe='')}" # 2) ì¸ì½”ë”©
    ]
    if not verify:
        return cand[0]
    try:
        import requests
        bad = ["ì‚­ì œ", "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°ë¬¸ì…ë‹ˆë‹¤", "í•´ë‹¹ í•œê¸€ì£¼ì†Œëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "í•œê¸€ ë²•ë ¹ì£¼ì†Œë¥¼ í™•ì¸í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤"]
        for deep in cand:
            r = requests.get(deep, timeout=timeout, allow_redirects=True)
            if (200 <= r.status_code < 400) and not any(sig in r.text[:6000] for sig in bad):
                return deep
        return f"{base}/{law}"  # ëª¨ë‘ ì‹¤íŒ¨ â†’ ë©”ì¸
    except Exception:
        return f"{base}/{law}"



def _deep_article_url(law: str, art_label: str) -> str:
    # ê³¼ê±° í˜¸ì¶œë¶€ í˜¸í™˜ìš©. í•­ìƒ ì•ˆì „ ê²€ì¦ + ë©”ì¸í˜ì´ì§€ í´ë°±.
    return _article_url_or_main(law, art_label, verify=True)

def link_inline_articles_in_bullets(markdown: str) -> str:
    """ë¶ˆë¦¿ ë¼ì¸ ì¤‘ 'ë²•ë ¹ëª… ì œNì¡°(ì˜M)'ë¥¼ [í…ìŠ¤íŠ¸](ì¡°ë¬¸URL)ë¡œ êµì²´"""
    def repl(m: re.Match) -> str:
        law = m.group("law").strip()
        art = f"ì œ{m.group('num')}ì¡°{m.group('ui') or ''}"
        url = _deep_article_url(law, art)
        tail = (m.group("tail") or "")
        # tailì´ " (ì¬ì‚°ë¶„í• )" ê°™ì€ ë¶€ê°€ì„¤ëª…ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³´ì¡´
        linked = f"{m.group('prefix')}[{law} {art}]({url}){tail}"
        return linked
    return _ART_PAT_BULLET.sub(repl, markdown or "")

def strip_reference_links_block(markdown: str) -> str:
    """ë§¨ ì•„ë˜ 'ì°¸ê³  ë§í¬' ì„¹ì…˜ì„ ì œê±°(ëª¨ë¸/ëª¨ë“ˆì´ ìƒì„±í•œ ë¸”ë¡ ëª¨ë‘ ì»¤ë²„)"""
    if not markdown:
        return markdown
    txt = _REF_BLOCK_PAT.sub("", markdown)
    txt = _REF_BLOCK2_PAT.sub("", txt)
    return txt


# ëª¨ë¸ì´ ì¢…ì¢… ë§Œë“¤ì–´ë‚´ëŠ” "ì œnì¡° ë§í¬" ê°™ì€ ì‰ì—¬ ë‹¨ì–´ ì œê±°
import re as _re_fix
_WORD_LINK_GHOST = _re_fix.compile(r'(?mi)\s*ì œ\d{1,4}ì¡°(?:ì˜\d{1,3}){0,2}\s*ë§í¬\b')

def strip_redundant_article_link_words(s: str) -> str:
    return _WORD_LINK_GHOST.sub('', s)


# === ìƒˆë¡œ ì¶”ê°€: ì¤‘ë³µ ì œê±° ìœ í‹¸ ===
def _dedupe_blocks(text: str) -> str:
    s = _normalize_text(text or "")

    # 1) ì™„ì „ ë™ì¼ ë¬¸ë‹¨ì˜ ì—°ì† ì¤‘ë³µ ì œê±°
    lines, out, prev = s.split("\n"), [], None
    for ln in lines:
        if ln.strip() and ln == prev:
            continue
        out.append(ln); prev = ln
    s = "\n".join(out)

    # 2) "ë²•ë¥  ìë¬¸ ë©”ëª¨"ë¡œ ì‹œì‘í•˜ëŠ” ë™ì¼ ë³¸ë¬¸ 2ì¤‘ ì¶œë ¥ ë°©ì§€
    pat = re.compile(r'(ë²•ë¥ \s*ìë¬¸\s*ë©”ëª¨[\s\S]{50,}?)(?:\n+)\1', re.I)
    s = pat.sub(r'\1', s)

    # 3) ë‚´ë¶€ ì ˆì°¨ ë¬¸êµ¬ ë…¸ì¶œ ì‹œ ì œê±°(ì˜ë„ ë¶„ì„/ì¶”ê°€ ê²€ìƒ‰/ì¬ê²€ìƒ‰)
    s = re.sub(
        r'^\s*\d+\.\s*\*\*?(ì‚¬ìš©ìì˜ ì˜ë„ ë¶„ì„|ì¶”ê°€ ê²€ìƒ‰|ì¬ê²€ìƒ‰)\*\*?.*?(?=\n\d+\.|\Z)',
        '',
        s,
        flags=re.M | re.S
    )

    # ë¹ˆ ì¤„ ì •ë¦¬
    s = re.sub(r'\n{3,}', '\n\n', s)
    return s

# === add: ì—¬ëŸ¬ ë²•ë ¹ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ìš”ì•½í•´ì„œ LLMì— ë¨¹ì¼ í”„ë¼ì´ë¨¸ ===
def _summarize_laws_for_basic(law_items: list[dict], max_items: int = 6) -> str:
    """
    ì—¬ëŸ¬ ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§§ê²Œ ìš”ì•½í•´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì£¼ì….
    - ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ ì¼ë¶€ë§Œ (max_items)
    - í˜•ì‹: "ê´€ë ¨ ë²•ë ¹ í›„ë³´: 1) ë²•ë ¹ëª…(êµ¬ë¶„, ì†Œê´€ë¶€ì²˜, ì‹œí–‰/ê³µí¬)"
    """
    if not law_items:
        return ""
    rows = []
    for i, d in enumerate(law_items[:max_items], 1):
        nm = d.get("ë²•ë ¹ëª…","").strip()
        kind = d.get("ë²•ë ¹êµ¬ë¶„","").strip()
        dept = d.get("ì†Œê´€ë¶€ì²˜ëª…","").strip()
        eff = d.get("ì‹œí–‰ì¼ì","").strip()
        pub = d.get("ê³µí¬ì¼ì","").strip()
        rows.append(f"{i}) {nm} ({kind}; {dept}; ì‹œí–‰ {eff}, ê³µí¬ {pub})")
    body = "\n".join(rows)
    return (
        "ì•„ë˜ëŠ” ì‚¬ìš©ì ì‚¬ê±´ê³¼ ê´€ë ¨ë„ê°€ ë†’ì€ ë²•ë ¹ í›„ë³´ ëª©ë¡ì´ë‹¤. "
        "ë‹µë³€ì„ ì‘ì„±í•  ë•Œ ê°ê°ì˜ ì ìš© ë²”ìœ„ì™€ ì±…ì„ì£¼ì²´, êµ¬ì„±ìš”ê±´Â·ì˜ë¬´Â·ì œì¬ë¥¼ êµì°¨ ê²€í† í•˜ë¼.\n"
        f"{body}\n"
        "ê°€ëŠ¥í•˜ë©´ ê° ë²•ë ¹ì„ ë¶„ë¦¬ëœ ì†Œì œëª©ìœ¼ë¡œ ì •ë¦¬í•˜ê³ , í•µì‹¬ ì¡°ë¬¸(1~2ê°œ)ë§Œ ê°„ë‹¨ ì¸ìš©í•˜ë¼."
    )
# --- ì¡°ë¬¸ ë³¸ë¬¸ ìº¡ìŠ ë²„ì „ìœ¼ë¡œ ë®ì–´ì“°ê¸° ---

# === add: LLM-ìš°ì„  í›„ë³´ â†’ ê° í›„ë³´ë¡œ MOLEG API ë‹¤ê±´ ì¡°íšŒ/ëˆ„ì  ===
def prefetch_law_context(user_q: str, num_rows_per_law: int = 3) -> list[dict]:
    """
    1) LLMì´ ë²•ë ¹ í›„ë³´ë¥¼ ë½‘ëŠ”ë‹¤ (extract_law_candidates_llm)  # :contentReference[oaicite:4]{index=4}
    2) í›„ë³´ë“¤ ê°ê°ì— ëŒ€í•´ _call_moleg_list("law", ...) í˜¸ì¶œ    # :contentReference[oaicite:5]{index=5}
    3) ê²°ê³¼ë¥¼ ì „ë¶€ í•©ì³ì„œ ë°˜í™˜ (ì¤‘ë³µì€ ê°„ë‹¨ ì œê±°)
    """
    seen = set()
    merged: list[dict] = []

    # 1) í›„ë³´
    law_names = extract_law_candidates_llm(user_q) or []

    # í›„ë³´ê°€ 0ê°œë©´ _clean_query_for_api()ë¡œ ë§ˆì§€ë§‰ í´ë°±
    if not law_names:
        law_names = [_clean_query_for_api(user_q)]  # :contentReference[oaicite:6]{index=6}

    # 2) ê° í›„ë³´ë¡œ ë‹¤ê±´ ì¡°íšŒ
    for name in law_names:
        if not name:
            continue
        items, _, _ = _call_moleg_list("law", name, num_rows=num_rows_per_law)  # :contentReference[oaicite:7]{index=7}
        for it in (items or []):
            key = (it.get("ë²•ë ¹ëª…",""), it.get("ë²•ë ¹êµ¬ë¶„",""), it.get("ì‹œí–‰ì¼ì",""))
            if key not in seen:
                seen.add(key)
                merged.append(it)

    return merged

# === add: LLM-ìš°ì„  ì§ˆì˜ì–´ ì„ íƒ í—¬í¼ ===
# === fix: LLM-ìš°ì„  ì§ˆì˜ì–´ ì„ íƒ (í´ë°±ì€ í›„ë³´ê°€ ì—†ì„ ë•Œë§Œ) ===
# ============================================
# [PATCH B] í†µí•© ê²€ìƒ‰ ê²°ê³¼ì— 'ê°€ì‚¬ì†Œì†¡ë²•'ë„ í•­ìƒ í›„ë³´ì— í¬í•¨
# - LLMì´ 'ë¯¼ë²•'ë§Œ ê³¨ë¼ë„, ì§ˆë¬¸ì´ ì´í˜¼/ì¬ì‚°ë¶„í• /ì–‘ìœ¡ ë“± ê°€ì‚¬ í‚¤ì›Œë“œë¥¼
#   í¬í•¨í•˜ë©´ 'ê°€ì‚¬ì†Œì†¡ë²•'ì„ í›„ë³´ì— ì¶”ê°€í•˜ì—¬ ìš°ì¸¡ íŒ¨ë„ì— ë…¸ì¶œë˜ë„ë¡ ë³´ê°•
# - ê·¸ëŒ€ë¡œ ë¶™ì—¬ ë„£ì–´ ê¸°ì¡´ choose_law_queries_llm_first ë¥¼ êµì²´í•˜ì„¸ìš”.
# ============================================

from typing import List

# 1) í‚¤ì›Œë“œ â†’ ëŒ€í‘œ ë²•ë ¹ ë§µ: ì—†ìœ¼ë©´ ë§Œë“¤ê³ , ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
try:
    KEYWORD_TO_LAW  # noqa: F821  # ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
except NameError:   # ì—†ì–´ë„ ì•ˆì „í•˜ê²Œ ìƒì„±
    KEYWORD_TO_LAW = {}

KEYWORD_TO_LAW.update({
    # ê°€ì‚¬ ì‚¬ê±´ í•µì‹¬ í‚¤ì›Œë“œ â†’ ê°€ì‚¬ì†Œì†¡ë²•
    "ì´í˜¼": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì¬ì‚°ë¶„í• ": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì–‘ìœ¡": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì–‘ìœ¡ë¹„": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì¹œê¶Œ": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ë©´ì ‘êµì„­": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ê°€ì‚¬": "ê°€ì‚¬ì†Œì†¡ë²•",
    "í˜‘ì˜ì´í˜¼": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì¬íŒìƒ ì´í˜¼": "ê°€ì‚¬ì†Œì†¡ë²•",
})


def choose_law_queries_llm_first(user_q: str) -> List[str]:
    """
    1) LLMì´ ì œì•ˆí•œ ë²•ë ¹ í›„ë³´ë¥¼ ìš°ì„  ì±„íƒ
    2) í›„ë³´ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì •ê·œí™” ì§ˆì˜ í´ë°± ì¶”ê°€
    3) â˜…í•­ìƒâ˜… í‚¤ì›Œë“œ ë§¤í•‘ìœ¼ë¡œ ë³´ê°•(ê°€ì‚¬ì†Œì†¡ë²• ë“±) â€” ì¤‘ë³µì€ ì œê±°
    """
    ordered: List[str] = []
    text = (user_q or "")

    # 1) LLM í›„ë³´ ìš°ì„ 
    try:
        llm_candidates = extract_law_candidates_llm(user_q) or []  # ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
    except NameError:
        llm_candidates = []
    for nm in llm_candidates:
        nm = (nm or "").strip()
        if nm and nm not in ordered:
            ordered.append(nm)

    # 2) í›„ë³´ê°€ ì—†ìœ¼ë©´ í´ë¦° ì§ˆì˜ í´ë°±
    if not ordered:
        try:
            cleaned = _clean_query_for_api(user_q)  # ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
        except NameError:
            cleaned = None
        if cleaned:
            ordered.append(cleaned)

    # 3) í‚¤ì›Œë“œ íŒíŠ¸ë¡œ í•­ìƒ ë³´ê°• (ê°€ì‚¬ í‚¤ì›Œë“œ â†’ ê°€ì‚¬ì†Œì†¡ë²• ë“±)
    for kw, mapped in KEYWORD_TO_LAW.items():
        if kw and (kw in text) and mapped not in ordered:
            ordered.append(mapped)

    return ordered

def render_bubble_with_copy(message: str, key: str):
    """ì–´ì‹œìŠ¤í„´íŠ¸ ë§í’ì„  ì „ìš© ë³µì‚¬ ë²„íŠ¼"""
    message = _normalize_text(message or "")
    st.markdown(message)
    safe_raw_json = json.dumps(message)
    html_tpl = '''
    <div class="copy-row" style="margin-bottom:8px">
      <button id="copy-__KEY__" class="copy-btn">
        <svg width="14" height="14" viewBox="0 0 24 24" fill="none">
          <path d="M9 9h9v12H9z" stroke="currentColor"/>
          <path d="M6 3h9v3" stroke="currentColor"/>
          <path d="M6 6h3v3" stroke="currentColor"/>
        </svg>
        ë³µì‚¬
      </button>
    </div>
    <script>
    (function(){
      const btn = document.getElementById("copy-__KEY__");
      if (!btn) return;
      btn.addEventListener("click", async () => {
        try {
          await navigator.clipboard.writeText(__SAFE__);
          const old = btn.innerHTML; btn.innerHTML = "ë³µì‚¬ë¨!";
          setTimeout(()=>btn.innerHTML = old, 1200);
        } catch(e) { alert("ë³µì‚¬ ì‹¤íŒ¨: " + e); }
      });
    })();
    </script>
    '''
    html_out = html_tpl.replace("__KEY__", str(key)).replace("__SAFE__", safe_raw_json)
    components.html(html_out, height=40)

def copy_url_button(url: str, key: str, label: str = "ë§í¬ ë³µì‚¬"):
    if not url: return
    safe = json.dumps(url)
    html_tpl = '''
      <div style="display:flex;gap:8px;align-items:center;margin-top:6px">
        <button id="copy-url-__KEY__" style="padding:6px 10px;border:1px solid #ddd;border-radius:8px;cursor:pointer">
          __LABEL__
        </button>
        <span id="copied-__KEY__" style="font-size:12px;color:var(--text-color,#888)"></span>
      </div>
      <script>
        (function(){
          const btn = document.getElementById("copy-url-__KEY__");
          const msg = document.getElementById("copied-__KEY__");
          if(!btn) return;
          btn.addEventListener("click", async () => {
            try {
              await navigator.clipboard.writeText(__SAFE__);
              msg.textContent = "ë³µì‚¬ë¨!";
              setTimeout(()=>msg.textContent="", 1200);
            } catch(e) {
              msg.textContent = "ë³µì‚¬ ì‹¤íŒ¨";
            }
          });
        })();
      </script>
    '''
    html_out = (html_tpl
                .replace("__KEY__", str(key))
                .replace("__SAFE__", safe)
                .replace("__LABEL__", html.escape(label)))
    components.html(html_out, height=40)

def _henc(s: str) -> str: return up.quote((s or "").strip())
def hangul_by_name(domain: str, name: str) -> str: return f"{_HBASE}/{_henc(domain)}/{_henc(name)}"

# "ì œ839ì¡°" ê°™ì€ íŒ¨í„´ ì¸ì‹ìš©
_ARTICLE_RE = re.compile(r"^ì œ?\d+ì¡°(ì˜\d+)?$")

def resolve_article_from_keywords(keys):
    ARTICLE_SYNONYMS = {
        "ì¬ì‚°ë¶„í• ": "ì œ839ì¡°ì˜2",
        "ì´í˜¼": "ì œ834ì¡°",
    }
    keys = [k.strip() for k in (keys or []) if k]
    for k in keys:
        if k in ARTICLE_SYNONYMS:
            return ARTICLE_SYNONYMS[k]
    for k in keys:
        if _ARTICLE_RE.match(k):
            return k
    return None

def hangul_law_article(name: str, subpath: str) -> str: return f"{_HBASE}/ë²•ë ¹/{_henc(name)}/{_henc(subpath)}"

def hangul_law_with_keys(name: str, keys) -> str:
    """í‚¤ì›Œë“œê°€ ì¡°ë¬¸ì„ ê°€ë¦¬í‚¤ë©´ ì¡°ë¬¸ìœ¼ë¡œ, ì•„ë‹ˆë©´ ê²€ìƒ‰ìœ¼ë¡œ."""
    art = resolve_article_from_keywords(keys)
    if art:
        return hangul_law_article(name, art)
    q = " ".join([name] + [k for k in (keys or []) if k]) if keys else name
    return build_fallback_search("law", q)

def hangul_admrul_with_keys(name: str, issue_no: str, issue_date: str) -> str: return f"{_HBASE}/í–‰ì •ê·œì¹™/{_henc(name)}/({_henc(issue_no)},{_henc(issue_date)})"
def hangul_ordin_with_keys(name: str, no: str, date: str) -> str: return f"{_HBASE}/ìì¹˜ë²•ê·œ/{_henc(name)}/({_henc(no)},{_henc(date)})"
def hangul_trty_with_keys(no: str, eff_date: str) -> str: return f"{_HBASE}/ì¡°ì•½/({_henc(no)},{_henc(eff_date)})"
def expc_public_by_id(expc_id: str) -> str: return f"https://www.law.go.kr/LSW/expcInfoP.do?expcSeq={up.quote(expc_id)}"
def lstrm_public_by_id(trm_seqs: str) -> str: return f"https://www.law.go.kr/LSW/lsTrmInfoR.do?trmSeqs={up.quote(trm_seqs)}"
def licbyl_file_download(fl_seq: str) -> str: return f"https://www.law.go.kr/LSW/flDownload.do?flSeq={up.quote(fl_seq)}"

def extract_case_no(text: str) -> str | None:
    if not text: return None
    m = _CASE_NO_RE.search(text.replace(" ", ""))
    return m.group(0) if m else None

def validate_case_no(case_no: str) -> bool:
    case_no = (case_no or "").replace(" ", "")
    return bool(_CASE_NO_RE.fullmatch(case_no))

def build_case_name_from_no(case_no: str, court: str = "ëŒ€ë²•ì›", disposition: str = "íŒê²°") -> str | None:
    case_no = (case_no or "").replace(" ", "")
    if not validate_case_no(case_no): return None
    return f"{court} {case_no} {disposition}"

def build_scourt_link(case_no: str) -> str:
    return f"https://glaw.scourt.go.kr/wsjo/panre/sjo050.do?saNo={up.quote(case_no)}"

def is_reachable(url: str) -> bool:
    try:
        r = requests.get(url, timeout=8, allow_redirects=True)
        if not (200 <= r.status_code < 400):
            return False
        text = r.text[:4000]
        bad_signals = [
            "í•´ë‹¹ í•œê¸€ì£¼ì†Œëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "í•œê¸€ ë²•ë ¹ì£¼ì†Œë¥¼ í™•ì¸í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤",
        ]
        return not any(sig in text for sig in bad_signals)
    except Exception:
        return False

def build_fallback_search(kind: str, q: str) -> str:
    qq = up.quote((q or "").strip())
    if kind in ("law", "admrul", "ordin", "trty"):
        return f"https://www.law.go.kr/LSW/lsSc.do?query={qq}"
    if kind == "prec":
        return f"https://glaw.scourt.go.kr/wsjo/panre/sjo050.do?saNo={qq}"
    if kind == "cc":
        return f"https://www.law.go.kr/LSW/lsSc.do?query={qq}"
    return f"https://www.law.go.kr/LSW/lsSc.do?query={qq}"

def present_url_with_fallback(main_url: str, kind: str, q: str, label_main="ìƒˆ íƒ­ì—ì„œ ì—´ê¸°"):
    if main_url and is_reachable(main_url):
        st.code(main_url, language="text")
        st.link_button(label_main, main_url, use_container_width=True)
        copy_url_button(main_url, key=str(abs(hash(main_url))))
    else:
        fb = build_fallback_search(kind, q)
        st.warning("ì§ì ‘ ë§í¬ê°€ ì—´ë¦¬ì§€ ì•Šì•„ **ëŒ€ì²´ ê²€ìƒ‰ ë§í¬**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        st.code(fb, language="text")
        st.link_button("ëŒ€ì²´ ê²€ìƒ‰ ë§í¬ ì—´ê¸°", fb, use_container_width=True)
        copy_url_button(fb, key=str(abs(hash(fb))))

def render_pinned_question():
    last_q = (st.session_state.get("last_q") or "").strip()
    if not last_q:
        return

    st.markdown(
        f"""
        <div class="pinned-q">
          <div class="label">ìµœê·¼ ì§ˆë¬¸</div>
          <div class="text">{_esc_br(last_q)}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

# ë‹µë³€ ë‚´ ë§í¬ë¥¼ ìˆ˜ì§‘ëœ ë²•ë ¹ ìƒì„¸ë§í¬ë¡œ êµì •
def fix_links_with_lawdata(markdown: str, law_data: list[dict]) -> str:
    import re
    if not markdown or not law_data:
        return markdown
    name_to_url = {
        d["ë²•ë ¹ëª…"]: (d["ë²•ë ¹ìƒì„¸ë§í¬"] or f"https://www.law.go.kr/ë²•ë ¹/{_henc(d['ë²•ë ¹ëª…'])}")
        for d in law_data if d.get("ë²•ë ¹ëª…")
    }
    pat = re.compile(r'\[([^\]]+)\]\((https?://www\.law\.go\.kr/[^\)]+)\)')
    def repl(m):
        text, url = m.group(1), m.group(2)
        if text in name_to_url:
            return f'[{text}]({name_to_url[text]})'
        return m.group(0)
    return pat.sub(repl, markdown)

# =============================
# Secrets / Clients / Session
# =============================
# --- secrets & config ---------------------------------------------------------
from dataclasses import dataclass
import streamlit as st

@dataclass
class Secrets:
    law_api_key: str        # ëª©ë¡/ê²€ìƒ‰ serviceKey
    law_api_oc: str         # DRF ìƒì„¸ OC (ì´ë©”ì¼ @ ì•ë¶€ë¶„)
    az: dict | None         # azure_openai ë¸”ë¡(ì—†ìœ¼ë©´ None)

def load_secrets() -> Secrets:
    s = st.secrets
    law_api_key = s.get("LAW_API_KEY", "")
    law_api_oc  = s.get("LAW_API_OC", "")
    az          = s.get("azure_openai", None)

    if not law_api_key:
        st.error("`LAW_API_KEY`ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit â†’ App settings â†’ Secretsì— ì¶”ê°€í•˜ì„¸ìš”.")
    if not law_api_oc:
        st.warning("`LAW_API_OC`ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. DRF ìƒì„¸(ì¡°ë¬¸ ë³¸ë¬¸) í˜¸ì¶œì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆì–´ìš”.")

    return Secrets(law_api_key, law_api_oc, az)

SECRETS    = load_secrets()
LAW_API_KEY = SECRETS.law_api_key
LAW_API_OC  = SECRETS.law_api_oc
AZURE       = SECRETS.az

import os
os.environ["LAW_API_OC"] = LAW_API_OC           # í™˜ê²½ë³€ìˆ˜ë¡œë„ ë…¸ì¶œ(ë°±ì—… ê²½ë¡œ)
import modules.law_fetch as LF
LF.LAW_API_OC = LAW_API_OC                      # law_fetch ëª¨ë“ˆ ì „ì—­ìœ¼ë¡œ ì§ì ‘ ì£¼ì…


# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
client = None
if AZURE:
    try:
        from openai import AzureOpenAI
        client = AzureOpenAI(
            api_key=AZURE["api_key"],
            api_version=AZURE["api_version"],
            azure_endpoint=AZURE["endpoint"],
        )
    except Exception as e:
        st.error(f"Azure OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# =============================
# MOLEG API (Law Search) â€” unified
# =============================
import ssl
from urllib3.poolmanager import PoolManager

MOLEG_BASES = [
    "https://apis.data.go.kr/1170000",
    "http://apis.data.go.kr/1170000",
]

class TLS12HttpAdapter2(HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs):
        ctx = ssl.create_default_context()
        ctx.minimum_version = ssl.TLSVersion.TLSv1_2
        ctx.maximum_version = ssl.TLSVersion.TLSv1_2
        self.poolmanager = PoolManager(*args, ssl_context=ctx, **kwargs)

# íŒŒì¼ ì–´ë”˜ê°€(ì‚¬ì´ë“œë°” ë Œë” ê·¼ì²˜)ì— 1ë²ˆë§Œ ì„ ì–¸
import time, urllib.parse as up
def _trace_api(kind: str, url: str, params: dict | None = None, resp=None, sample_len: int = 500):
    """ì‚¬ì´ë“œë°”ì—ì„œ ë³¼ ìˆ˜ ìˆê²Œ ìµœê·¼ API í˜¸ì¶œì„ ëˆ„ì  ê¸°ë¡"""
    try:
        import streamlit as st
        rows = st.session_state.setdefault("_api_trace", [])
        full_url = url if not params else f"{url}?{up.urlencode(params, quote_via=up.quote)}"
        rows.append({
            "t": time.strftime("%H:%M:%S"),
            "kind": kind,                      # "list" / "drf" ë“±
            "url": full_url,
            "params": params or {},
            "status": getattr(resp, "status_code", None),
            "ctype": (getattr(resp, "headers", {}) or {}).get("content-type", ""),
            "sample": (getattr(resp, "text", "") or "")[:sample_len],
        })
        st.session_state["_api_trace"] = rows[-12:]  # ìµœê·¼ 12ê°œë§Œ ìœ ì§€
    except Exception:
        pass


# í†µí•© ë¯¸ë¦¬ë³´ê¸° ì „ìš©: ê³¼í•œ ë¬¸ì¥ë¶€í˜¸/ë”°ì˜´í‘œ ì œê±° + 'ë²•ë ¹ëª… (ì œnì¡°)'ë§Œ ì¶”ì¶œ
def _clean_query_for_api(q: str) -> str:
    q = (q or "").strip()
    q = re.sub(r'[â€œâ€"\'â€˜â€™.,!?()<>\\[\\]{}:;~â€¦]', ' ', q)
    q = re.sub(r'\\s+', ' ', q).strip()
    # ë²•ë ¹ëª…(OOë²•/ë ¹/ê·œì¹™/ì¡°ë¡€) + (ì œnì¡°) íŒ¨í„´
    name = re.search(r'([ê°€-í£A-Za-z0-9Â·\\s]{1,40}?(ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€))', q)
    article = re.search(r'ì œ\\d+ì¡°(ì˜\\d+)?', q)
    if name and article: return f"{name.group(0).strip()} {article.group(0)}"
    if name: return name.group(0).strip()
    return q

# === add: LLM ë¦¬ë­ì»¤(ë§¥ë½ í•„í„°) ===
def rerank_laws_with_llm(user_q: str, law_items: list[dict], top_k: int = 8) -> list[dict]:
    if not law_items or client is None:
        return law_items
    names = [d.get("ë²•ë ¹ëª…","").strip() for d in law_items if d.get("ë²•ë ¹ëª…")]
    names_txt = "\n".join(f"- {n}" for n in names[:25])

    SYS = (
        "ë„ˆëŠ” ì‚¬ê±´ê³¼ ê´€ë ¨ëœ 'ë²•ë ¹ëª…'ë§Œ ë‚¨ê¸°ëŠ” í•„í„°ì•¼. ì§ˆë¬¸ ë§¥ë½ê³¼ ë¬´ê´€í•˜ë©´ ì œì™¸í•˜ê³ , JSONë§Œ ë°˜í™˜í•´.\n"
        'í˜•ì‹: {"pick":["í˜•ë²•","ì‚°ì—…ì•ˆì „ë³´ê±´ë²•"]}'
    )
    prompt = (
        "ì‚¬ìš©ì ì§ˆë¬¸:\n" + (user_q or "") + "\n\n"
        "í›„ë³´ ë²•ë ¹ ëª©ë¡:\n" + names_txt + "\n\n"
        "ì‚¬ê±´ì— ì§ì ‘ ê´€ë ¨ëœ ê²ƒë§Œ 3~8ê°œ ê³ ë¥´ê³  ë‚˜ë¨¸ì§€ëŠ” ì œì™¸í•´."
    )

    try:
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYS},
                      {"role":"user","content": prompt}],
            temperature=0.0, max_tokens=96,
        )
        txt = (resp.choices[0].message.content or "").strip()
        import re, json as _json
        if "```" in txt:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", txt); 
            if m: txt = m.group(1).strip()
        if not txt.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", txt); 
            if m: txt = m.group(0)
        data = _json.loads(txt)
        picks = [s.strip() for s in data.get("pick", []) if s.strip()]
        if not picks:
            return law_items
        name_to_item = {}
        for d in law_items:
            nm = d.get("ë²•ë ¹ëª…","").strip()
            if nm and nm not in name_to_item:
                name_to_item[nm] = d
        return [name_to_item[n] for n in picks if n in name_to_item][:top_k]
    except Exception:
        return law_items

def _filter_plans(user_q: str, plans: list[dict]) -> list[dict]:
    U = set(_canonize(_tok(user_q)))
    seen=set(); out=[]
    for p in plans or []:
        t = (p.get("target") or "").strip()
        q = (p.get("q") or "").strip()
        if not t or not q:
            continue
        T = set(_canonize(_tok(q)))
        if (U & T) or (p.get("must")):   # ì‚¬ìš©ìì™€ 1í† í° ì´ìƒ ê²¹ì¹˜ê±°ë‚˜, mustê°€ ìˆìœ¼ë©´ í†µê³¼
            key=(t,q)
            if key not in seen:
                seen.add(key)
                out.append(p)          # â† must/must_not ë³´ì¡´!
    return out[:10]


# === add/replace: ë²•ë ¹ëª… í›„ë³´ ì¶”ì¶œê¸° (LLM, ê²¬ê³  ë²„ì „) ===
@st.cache_data(show_spinner=False, ttl=300)
def extract_law_candidates_llm(q: str) -> list[str]:
    """
    ì‚¬ìš©ì ì„œìˆ ì—ì„œ ê´€ë ¨ 'ë²•ë ¹ëª…'ë§Œ 1~3ê°œ ì¶”ì¶œ.
    - JSON ì™¸ í…ìŠ¤íŠ¸/ì½”ë“œíœìŠ¤ê°€ ì„ì—¬ë„ íŒŒì‹±
    - 1ì°¨ ì‹¤íŒ¨ ì‹œ ì—„ê²© í”„ë¡¬í”„íŠ¸ë¡œ 1íšŒ ì¬ì‹œë„
    """
    if not q or (client is None):
        return []

    def _parse_json_laws(txt: str) -> list[str]:
        import re, json as _json
        t = (txt or "").strip()
        # ```json ... ``` ë˜ëŠ” ``` ... ``` ì œê±°
        if "```" in t:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", t)
            if m:
                t = m.group(1).strip()
        # ë³¸ë¬¸ ì¤‘ JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
        if not t.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", t)
            if m:
                t = m.group(0)
        data = _json.loads(t)
        laws = [s.strip() for s in (data.get("laws", []) or []) if s and s.strip()]
        # ì¤‘ë³µ/ê¸¸ì´ ì •ë¦¬
        seen, out = set(), []
        for name in laws:
            nm = name[:40]
            if nm and nm not in seen:
                seen.add(nm); out.append(nm)
        return out

    # 1) ì¼ë°˜ í”„ë¡¬í”„íŠ¸
    try:
        SYSTEM_EXTRACT1 = (
            "ë„ˆëŠ” í•œêµ­ ì‚¬ê±´ ì„¤ëª…ì—ì„œ 'ê´€ë ¨ ë²•ë ¹ëª…'ë§Œ 1~3ê°œ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ë‹¤. "
            "ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ë¼.\n"
            'í˜•ì‹: {"laws":["í˜•ë²•","ì‚°ì—…ì•ˆì „ë³´ê±´ë²•"]}'
        )
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_EXTRACT1},
                      {"role":"user","content": q.strip()}],
            temperature=0.0,
            max_tokens=128,
        )
        laws = _parse_json_laws(resp.choices[0].message.content)
        if laws:
            return laws[:3]
    except Exception:
        pass

    # 2) ì—„ê²© í”„ë¡¬í”„íŠ¸ë¡œ 1íšŒ ì¬ì‹œë„
    try:
        SYSTEM_EXTRACT2 = (
            "JSON ONLY. No code fences. No commentary. "
            'Return exactly: {"laws":["ë²•ë ¹ëª…1","ë²•ë ¹ëª…2"]}'
        )
        resp2 = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_EXTRACT2},
                      {"role":"user","content": q.strip()}],
            temperature=0.0,
            max_tokens=96,
        )
        laws2 = _parse_json_laws(resp2.choices[0].message.content)
        if laws2:
            return laws2[:3]
    except Exception:
        pass

    # ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
    return []

# === LLM í”Œë˜ë„ˆ & í”Œëœ í•„í„° ===
import re, json

# === LLM í”Œë˜ë„ˆ & í”Œëœ í•„í„° ===
def _filter_items_by_plan(user_q: str, items: list[dict], plan: dict) -> list[dict]:
    name_get = lambda d: (d.get("ë²•ë ¹ëª…") or "")
    must = set(_canonize(plan.get("must") or []))
    must_not = set(_canonize(plan.get("must_not") or []))
    qtok = set(_canonize(_tok(plan.get("q",""))))
    target = (plan.get("target") or "").strip()

    kept = []
    for it in (items or []):
        nm = name_get(it)
        N = set(_canonize(_tok(nm)))

        # 1) q í† í°ì€ í•˜ë“œ í•„í„° (ìµœì†Œí•œì˜ ì •í•©ì„± í™•ë³´)
        if qtok and not (N & qtok):
            continue

        # 2) ì œì™¸ í† í°ì€ ê³„ì† í•˜ë“œ í•„í„°
        if must_not and (N & must_not):
            continue

        # 3) mustëŠ” 'ë­í‚¹ìš©'ìœ¼ë¡œë§Œ ì‚¬ìš© (í•˜ë“œ í•„í„° ì œê±°)
        kept.append((it, N))

    # ë­í‚¹: ì‚¬ìš©ì/í”Œëœ ê´€ë ¨ë„ + must ë§¤ì¹­ ë³´ë„ˆìŠ¤(-3ì”©)
    def score(pair):
        it, N = pair
        base = _rel_score(user_q, name_get(it), plan.get("q",""))
        bonus = -3 * len(N & must)
        return base + bonus

    kept.sort(key=score)
    return [it for it, _ in kept]

@st.cache_data(show_spinner=False, ttl=180)
def propose_api_queries_llm(user_q: str) -> list[dict]:
    if not user_q or client is None:
        return []

    SYS = (
        "ë„ˆëŠ” í•œêµ­ ë²•ì œì²˜(Open API) ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì„¤ê³„í•œë‹¤. JSON ONLY.\n"
        'í˜•ì‹: {"queries":[{"target":"law|admrul|ordin|trty","q":"ê²€ìƒ‰ì–´",'
        '"must":["ë°˜ë“œì‹œ í¬í•¨"], "must_not":["ì œì™¸í•  ë‹¨ì–´"]}, ...]}\n'
        # â˜… í•µì‹¬ ì§€ì‹œ
        "- **ë°˜ë“œì‹œ `ë²•ë ¹ëª…`(ì˜ˆ: í˜•ë²•, ë¯¼ë²•, ë„ë¡œêµí†µë²•, êµí†µì‚¬ê³ ì²˜ë¦¬ íŠ¹ë¡€ë²•) ë˜ëŠ” "
        "'ë²•ë ¹ëª… + í•µì‹¬ì–´(ì˜ˆ: í˜•ë²• ê³¼ì‹¤ì¹˜ìƒ)` í˜•íƒœë¡œ ì§ˆì˜ë¥¼ ë§Œë“¤ ê²ƒ.**\n"
        "- **ì‚¬ê±´ ì„œìˆ (ì˜ˆ: ì§€í•˜ ì£¼ì°¨ì¥ì—ì„œ ê³¼ì†â€¦) ìì²´ë¥¼ ì§ˆì˜ë¡œ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ.**\n"
        "- mustëŠ” 1~3ê°œë¡œ ê°„ê²°í•˜ê²Œ, must_notì€ ë¶„ëª…íˆ ë‹¤ë¥¸ ì¶•ì¼ ë•Œë§Œ."
          # === ê·œì¹™(ì¤‘ìš”) ===
        "- target=law ì¸ ê²½ìš°, qì—ëŠ” **í•­ìƒ ë²•ë ¹ëª…ë§Œ** ì ëŠ”ë‹¤. ì˜ˆ: ë¯¼ë²•, í˜•ë²•, ë„ë¡œêµí†µë²•.\n"
        "- í‚¤ì›Œë“œ(ì˜ˆ: ì†í•´ë°°ìƒ, ê³¼ì‹¤ì¹˜ìƒ, ê³¼ì† ë“±)ëŠ” qì— ë¶™ì´ì§€ ë§ê³  **must**ì—ë§Œ ë„£ëŠ”ë‹¤.\n"
        "- ì‚¬ê±´ ì„œìˆ (ì˜ˆ: ì£¼ì°¨ì¥ì—ì„œ ì‚¬ê³ â€¦)ì„ që¡œ ì“°ì§€ ë§ê³  ë°˜ë“œì‹œ ë²•ë ¹ëª…/í–‰ì •ê·œì¹™ëª…/ì¡°ë¡€ëª… ë“±ë§Œ ì‚¬ìš©í•œë‹¤.\n"
        "- ì˜ˆì‹œ1: 'ë¯¼ë²• ì†í•´ë°°ìƒ' â†’ {\"target\":\"law\",\"q\":\"ë¯¼ë²•\",\"must\":[\"ì†í•´ë°°ìƒ\"]}\n"
        "- ì˜ˆì‹œ2: 'í˜•ë²• ê³¼ì‹¤ì¹˜ìƒ' â†’ {\"target\":\"law\",\"q\":\"í˜•ë²•\",\"must\":[\"ê³¼ì‹¤ì¹˜ìƒ\"]}\n"
        "- ì˜ˆì‹œ3: 'ì£¼ì°¨ì¥ì—ì„œ ì‚¬ê³ ' â†’ {\"target\":\"law\",\"q\":\"ë„ë¡œêµí†µë²•\",\"must\":[\"ì£¼ì°¨ì¥\",\"ì‚¬ê³ \"]}\n"
    )
   
    try:
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYS},
                      {"role":"user","content": user_q.strip()}],
            temperature=0.0, max_tokens=220,
        )
        txt = (resp.choices[0].message.content or "").strip()
        if "```" in txt:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", txt); 
            if m: txt = m.group(1).strip()
        if not txt.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", txt); 
            if m: txt = m.group(0)

        data = json.loads(txt) if txt else {}
        out=[]
        for it in (data.get("queries") or []):
            t = (it.get("target") or "").strip()
            q = (it.get("q") or "").strip()
            must = [x.strip() for x in (it.get("must") or []) if x.strip()]
            must_not = [x.strip() for x in (it.get("must_not") or []) if x.strip()]
            if t in {"law","admrul","ordin","trty"} and q:
                out.append({"target":t,"q":q[:60],"must":must[:4],"must_not":must_not[:6]})
        return out[:10]
    except Exception:
        return []

# --- ê´€ë ¨ë„ ìŠ¤ì½”ì–´(ì‘ì„ìˆ˜ë¡ ê´€ë ¨)
def _rel_score(user_q: str, item_name: str, plan_q: str) -> int:
    U = set(_canonize(_tok(user_q)))
    I = set(_canonize(_tok(item_name)))
    P = set(_canonize(_tok(plan_q)))
    if not I:
        return 999
    # êµì§‘í•©ì´ ë§ê³ , ì‚¬ìš©ìÂ·í”Œëœ í† í°ê³¼ ê²¹ì¹ ìˆ˜ë¡ ê°€ì 
    inter_ui = len(U & I)
    inter_pi = len(P & I)
    score = 100 - 10*inter_ui - 5*inter_pi
    # ì™„ì „ ë¬´ê´€(êµì§‘í•© 0)ì´ë¼ë©´ í° íŒ¨ë„í‹°
    if inter_ui == 0 and inter_pi == 0:
        score += 100
    return max(score, 0)

# íŒŒì¼ ìƒë‹¨ ì•„ë¬´ ê³³(ìœ í‹¸ ê·¼ì²˜)ì— ì¶”ê°€
_LAWISH_RE = re.compile(r"(ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€|ë²•ë¥ )|ì œ\d+ì¡°")
def _lawish(q: str) -> bool:
    return bool(_LAWISH_RE.search(q or ""))

def find_all_law_data(query: str, num_rows: int = 3, hint_laws: list[str] | None = None):
    results = {}

    # 0) LLM í”Œëœ ìƒì„±
    plans = propose_api_queries_llm(query)  # ê¸°ì¡´ LLM í”Œë˜ë„ˆ ì‚¬ìš©:contentReference[oaicite:1]{index=1}

    # âœ… 0-0) ë‹µë³€/ì§ˆë¬¸ì—ì„œ ì–»ì€ 'íŒíŠ¸ ë²•ë ¹ë“¤'ì„ ìµœìš°ì„  ì‹œë“œë¡œ ì£¼ì…
    if hint_laws:
        seed = [{"target":"law","q":nm, "must":[nm], "must_not": []}
                for nm in hint_laws if nm]
        # ì•ì— ë°°ì¹˜ + (target,q) ì¤‘ë³µ ì œê±°
        seen=set(); merged = seed + (plans or [])
        plans = []
        for p in merged:
            key=(p.get("target"), p.get("q"))
            if key not in seen and p.get("target") and p.get("q"):
                seen.add(key); plans.append(p)

    # ì˜¤íƒˆì ë³´ì •/ì •í•©ì„± í•„í„°/ë²•ë ¹í˜• ìš°ì„  íë¦„(ê¸°ì¡´) ìœ ì§€:contentReference[oaicite:2]{index=2}
    for p in plans or []:
        p["q"] = _sanitize_plan_q(query, p.get("q",""))
    plans = _filter_plans(query, plans)                      # ì‚¬ìš©ìì™€ í† í° êµì§‘í•© or must ìˆìœ¼ë©´ í†µê³¼:contentReference[oaicite:3]{index=3}

    good = [p for p in (plans or []) if _lawish(p.get("q",""))]  # ë²•/ë ¹/ê·œì¹™/ì¡°ë¡€/ì œnì¡° í¬í•¨:contentReference[oaicite:4]{index=4}
    if good:
        plans = good[:10]
    else:
        # LLM í›„ë³´(ì§ˆë¬¸ ê¸°ì¤€) â†’ ê·œì¹™ í´ë°±(ìµœì†Œí™”) ìˆœìœ¼ë¡œ êµ¬ì œ
        names = extract_law_candidates_llm(query) or []      # LLM ê¸°ë°˜ í›„ë³´ ì¶”ì¶œê¸°:contentReference[oaicite:5]{index=5}
        if not names:
            # ê·œì¹™ ë§µì€ í´ë°±ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
            names = [v for k, v in KEYWORD_TO_LAW.items() if k in (query or "")]
        if names:
            plans = [{"target":"law","q":n,"must":[n],"must_not":[]} for n in names][:6]
        else:
            kw = (extract_keywords_llm(query) or [])[:5]     # í‚¤ì›Œë“œ ë¹…ë¨ í´ë°±:contentReference[oaicite:6]{index=6}
            tmp=[]
            for i in range(len(kw)):
                for j in range(i+1, len(kw)):
                    tmp.append({"target":"law","q":f"{kw[i]} {kw[j]}","must":[kw[i],kw[j]],"must_not":[]})
            plans = tmp[:8]

    # (ì´í•˜ ì‹¤í–‰/ë¦¬ë­í¬/íŒ¨í‚¹ì€ ê¸°ì¡´ê³¼ ë™ì¼):contentReference[oaicite:7]{index=7}
    tried, err = [], []
    buckets = {"ë²•ë ¹":("law",[]), "í–‰ì •ê·œì¹™":("admrul",[]), "ìì¹˜ë²•ê·œ":("ordin",[]), "ì¡°ì•½":("trty",[])}
    for plan in plans:
        t, qx = plan["target"], plan["q"]
        tried.append(f"{t}:{qx}")
        if not qx.strip():
            err.append(f"{t}:(blank) dropped"); continue
        try:
            items, endpoint, e = _call_moleg_list(t, qx, num_rows=num_rows)  # MOLEG API í˜¸ì¶œ:contentReference[oaicite:8]{index=8}
            items = _filter_items_by_plan(query, items, plan)                # ì •í•©ì„± í•„í„° + ì •ë ¬:contentReference[oaicite:9]{index=9}
            if items:
                for label,(tt,arr) in buckets.items():
                    if t==tt: arr.extend(items)
            if e: err.append(f"{t}:{qx} â†’ {e}")
        except Exception as ex:
            err.append(f"{t}:{qx} â†’ {ex}")

    for label,(tt,arr) in buckets.items():
        if arr and tt=="law" and len(arr)>=2:
            arr = rerank_laws_with_llm(query, arr, top_k=8)  # LLM ë¦¬ë­ì»¤(ë§¥ë½ í•„í„°):contentReference[oaicite:10]{index=10}
        results[label] = {
            "items": arr, "endpoint": None,
            "error": "; ".join(err) if err else None,
            "debug": {"plans": plans, "tried": tried},
        }
    return results


# ìºì‹œëœ ë‹¨ì¼ ë²•ë ¹ ê²€ìƒ‰
@st.cache_data(show_spinner=False, ttl=300)
def search_law_data(query: str, num_rows: int = 10):
    return _call_moleg_list("law", query, num_rows=num_rows)

# ğŸ”½ ì—¬ê¸°ì— ì¶”ê°€ (search_law_data ì•„ë˜)

# ìì—°ì–´ â†’ ëŒ€í‘œ ë²•ë ¹ëª… í´ë°±ìš© ë§µ
KEYWORD_TO_LAW = {
    "ê°œì¸ì •ë³´": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
    "ëª…í•¨": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
    "ê³ ê°ì •ë³´": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
    # === êµí†µì‚¬ê³  ê³„ì—´(ì¶”ê°€) ===
    "êµí†µì‚¬ê³ ": "êµí†µì‚¬ê³ ì²˜ë¦¬ íŠ¹ë¡€ë²•",
    "ê³¼ì‹¤ì¹˜ìƒ": "í˜•ë²•",          # LLMì´ 'í˜•ë²• ê³¼ì‹¤ì¹˜ìƒ'ìœ¼ë¡œ í™•ì¥
    "ê³¼ì†": "ë„ë¡œêµí†µë²•",
    "ìŒì£¼ìš´ì „": "ë„ë¡œêµí†µë²•",
    "ì£¼ì°¨ì¥": "ë„ë¡œêµí†µë²•",
}


SYSTEM_EXTRACT = """ë„ˆëŠ” í•œêµ­ ë²•ë ¹ëª…ì„ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ì•¼.
ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê´€ë ¨ 'ë²•ë ¹ëª…(ê³µì‹ëª…)' í›„ë³´ë¥¼ 1~3ê°œ ë½‘ì•„ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•´.
í˜•ì‹: {"laws":["ê°œì¸ì •ë³´ ë³´í˜¸ë²•","ê°œì¸ì •ë³´ ë³´í˜¸ë²• ì‹œí–‰ë ¹"]} ë‹¤ë¥¸ ë§ ê¸ˆì§€.
ë²•ë ¹ëª…ì´ ì• ë§¤í•˜ë©´ ê°€ì¥ ìœ ë ¥í•œ ê²ƒ 1ê°œë§Œ.
"""

# ===== ê°•ê±´í•œ í‚¤ì›Œë“œ ì¶”ì¶œê¸° (êµì²´) =====
@st.cache_data(show_spinner=False, ttl=300)
def extract_keywords_llm(q: str) -> list[str]:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 2~6ê°œë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì¶œí•œë‹¤.
    íŒŒì´í”„ë¼ì¸: LLM(í‘œì¤€) -> LLM(ì—„ê²© ì¬ì‹œë„) -> ê·œì¹™ ê¸°ë°˜ í´ë°±.
    """
    if not q or (client is None):
        return []

    def _parse_json_keywords(txt: str) -> list[str]:
        # ì½”ë“œíœìŠ¤/ì¡í…ìŠ¤íŠ¸ ì œê±° + JSON ë¸”ëŸ­ë§Œ ì¶”ì¶œ
        import re, json as _json
        t = (txt or "").strip()
        if "```" in t:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", t)
            if m:
                t = m.group(1).strip()
        if not t.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", t)
            if m:
                t = m.group(0)
        data = _json.loads(t)
        kws = [s.strip() for s in (data.get("keywords", []) or []) if s and s.strip()]
        # ê°„ë‹¨ ì •ê·œí™”/ì¤‘ë³µì œê±°
        seen, out = set(), []
        for k in kws:
            k2 = k[:20]  # ê³¼ë„í•œ ê¸¸ì´ ì»·
            if len(k2) >= 2 and k2 not in seen:
                seen.add(k2); out.append(k2)
        return out

    # 1) LLM 1ì°¨
    try:
        SYSTEM_KW = (
            "ë„ˆëŠ” í•œêµ­ ë²•ë¥  ì§ˆì˜ì˜ í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ì•¼. "
            "ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ê³ , ì„¤ëª…/ì½”ë“œë¸”ë¡/ì£¼ì„ì€ ê¸ˆì§€.\n"
            'í˜•ì‹: {"keywords":["í­í–‰","ìœ„í˜‘","ì •ë‹¹ë°©ìœ„","ê³¼ì‰ë°©ìœ„","ë³‘ì› ì´ì†¡"]}'
        )
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_KW},
                      {"role":"user","content": q.strip()}],
            temperature=0.0, max_tokens=96,
        )
        kws = _parse_json_keywords(resp.choices[0].message.content)
        if kws:
            return kws[:6]
    except Exception as e:
        st.session_state["_kw_extract_err1"] = str(e)

    # 2) LLM 2ì°¨(ì—„ê²© ì¬ì‹œë„)
    try:
        SYSTEM_KW_STRICT = (
            "JSON ONLY. No code fences, no commentary. "
            'Format: {"keywords":["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3"]} '
            "í‚¤ì›Œë“œëŠ” 2~6ê°œ, ëª…ì‚¬/ì§§ì€ êµ¬ ì¤‘ì‹¬."
        )
        resp2 = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_KW_STRICT},
                      {"role":"user","content": q.strip()}],
            temperature=0.0, max_tokens=96,
        )
        kws2 = _parse_json_keywords(resp2.choices[0].message.content)
        if kws2:
            return kws2[:6]
    except Exception as e:
        st.session_state["_kw_extract_err2"] = str(e)

    # 3) ê·œì¹™ ê¸°ë°˜ í´ë°±(LLM ì‹¤íŒ¨/ì°¨ë‹¨/ë„¤íŠ¸ì›Œí¬ ì˜ˆì™¸ ëŒ€ë¹„)
    def _rule_based_kw(text: str) -> list[str]:
        t = (text or "")
        # ë„ë©”ì¸ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë§¤ì¹­(ë“±ì¥í•˜ëŠ” ê²ƒë§Œ ì±„íƒ)
        WL = [
            "í­í–‰", "ìƒí•´", "í˜‘ë°•", "ìœ„í˜‘", "ì œì§€", "ì •ë‹¹ë°©ìœ„", "ê³¼ì‰ë°©ìœ„",
            "ì‚´ì¸", "ì‚¬ë§", "ë¶€ìƒ", "ì‘ê¸‰", "ë³‘ì›", "ì´ì†¡", "ê²½ì°°", "ì‹ ê³ ",
            "ê±´ì„¤í˜„ì¥", "í˜„ì¥ì†Œì¥", "ê·¼ë¡œì", "ì‚°ì—…ì•ˆì „", "ì¤‘ëŒ€ì¬í•´",
        ]
        hits = [w for w in WL if w in t]
        # ì¶”ê°€: ê°„ë‹¨ í•œê¸€ í† í°(2~6ì) ì¶”ì¶œë¡œ ë¹ˆì¹¸ ë§‰ê¸°
        import re
        tokens = re.findall(r"[ê°€-í£]{2,6}", t)
        # ê¸°ëŠ¥ì–´/ë¶ˆìš©ì–´(ê°„ë‹¨) ì œê±°
        STOP = {"ê·¸ë¦¬ê³ ","í•˜ì§€ë§Œ","ê·¸ëŸ¬ë‚˜","ë•Œë¬¸","ê²½ìš°","ê´€ë ¨","ë¬¸ì œ","ì–´ë–¤","ì–´ë–»ê²Œ","ìˆëŠ”ì§€"}
        tokens = [x for x in tokens if x not in STOP]
        # í•©ì¹˜ê³  ì¤‘ë³µ ì œê±°
        combined = hits + tokens
        seen, out = set(), []
        for k in combined:
            if k not in seen:
                seen.add(k); out.append(k)
        return out[:6]

    kws3 = _rule_based_kw(q)
    if kws3:
        # ë¹ˆ ê²°ê³¼ë¥¼ ìºì‹œì— ë‚¨ê¸°ì§€ ì•Šë„ë¡: ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ ë°”ë¡œ ë°˜í™˜ ë§ê³  ì˜ˆì™¸ë¡œ í˜ë¦¬ê¸°
        return kws3

    # ìµœì¢…ì ìœ¼ë¡œë„ ë¹„ë©´ ìºì‹œ ë°©ì§€ìš© ë””ë²„ê·¸ íŒíŠ¸ë§Œ ë‚¨ê¸°ê³  ë¹ˆ ë¦¬ìŠ¤íŠ¸
    st.session_state["_kw_extract_debug"] = "all_stages_failed"
    return []


# ê°„ë‹¨ í´ë°±(ì˜ˆë¹„ â€” ë„êµ¬ ëª¨ë“œ ê¸°ë³¸ì´ë¯€ë¡œ ìµœì†Œí™”)
def find_law_with_fallback(user_query: str, num_rows: int = 10):
    laws, endpoint, err = search_law_data(user_query, num_rows=num_rows)
    if laws: return laws, endpoint, err, "primary"
    keyword_map = {"ì •ë‹¹ë°©ìœ„":"í˜•ë²•","ì „ì„¸":"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•","ìƒê°€ì„ëŒ€ì°¨":"ìƒê°€ê±´ë¬¼ ì„ëŒ€ì°¨ë³´í˜¸ë²•","ê·¼ë¡œê³„ì•½":"ê·¼ë¡œê¸°ì¤€ë²•","í•´ê³ ":"ê·¼ë¡œê¸°ì¤€ë²•","ê°œì¸ì •ë³´":"ê°œì¸ì •ë³´ ë³´í˜¸ë²•","ì‚°ì¬":"ì‚°ì—…ì¬í•´ë³´ìƒë³´í—˜ë²•","ì´í˜¼":"ë¯¼ë²•"}
    text = (user_query or "")
    for k, law_name in keyword_map.items():
        if k in text:
            laws2, ep2, err2 = search_law_data(law_name, num_rows=num_rows)
            if laws2: return laws2, ep2, err2, f"fallback:{law_name}"
    return [], endpoint, err, "none"

def _append_message(role: str, content: str, **extra):
    
    txt = (content or "").strip()
    is_code_only = (txt.startswith("```") and txt.endswith("```"))
    if not txt or is_code_only:
        return
    msgs = st.session_state.get("messages", [])
    if msgs and isinstance(msgs[-1], dict) and msgs[-1].get("role")==role and (msgs[-1].get("content") or "").strip()==txt:
        # skip exact duplicate of the last message (role+content)
        return
    st.session_state.messages.append({"role": role, "content": txt, **extra})



def format_law_context(law_data: list[dict]) -> str:
    """
    ê²€ìƒ‰ëœ ë²•ë ¹ ëª©ë¡ì„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ í¬ë§·í•œë‹¤.
    ëˆ„ë½ í‚¤ì— ëŒ€ë¹„í•´ .get()ê³¼ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•˜ê³ , ë§í¬ê°€ ì—†ìœ¼ë©´ 'ì—†ìŒ'ìœ¼ë¡œ í‘œì‹œí•œë‹¤.
    """
    if not law_data:
        return "ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    rows = []
    normalizer = globals().get("normalize_law_link")  # ì„ íƒì : ìˆìœ¼ë©´ ë§í¬ ì •ê·œí™”

    for i, law in enumerate(law_data, 1):
        if not isinstance(law, dict):
            rows.append(f"{i}. (ì•Œ ìˆ˜ ì—†ëŠ” í•­ëª©)")
            continue

        name = law.get("ë²•ë ¹ëª…") or law.get("ë²•ë ¹ëª…í•œê¸€") or law.get("title") or "(ì œëª© ì—†ìŒ)"
        kind = law.get("ë²•ë ¹êµ¬ë¶„") or law.get("kind") or "-"
        dept = law.get("ì†Œê´€ë¶€ì²˜ëª…") or law.get("ë¶€ì²˜ëª…") or "-"
        eff  = law.get("ì‹œí–‰ì¼ì") or law.get("effective_date") or "-"
        pub  = law.get("ê³µí¬ì¼ì") or law.get("promulgation_date") or "-"

        link = (
            law.get("ë²•ë ¹ìƒì„¸ë§í¬")
            or law.get("ìƒì„¸ë§í¬")
            or law.get("detail_url")
            or ""
        )
        if callable(normalizer) and link:
            try:
                link = normalizer(link) or link
            except Exception:
                pass

        rows.append(
            f"{i}. {name} ({kind})\n"
            f"   - ì†Œê´€ë¶€ì²˜: {dept}\n"
            f"   - ì‹œí–‰ì¼ì: {eff} / ê³µí¬ì¼ì: {pub}\n"
            f"   - ë§í¬: {link if link else 'ì—†ìŒ'}"
        )

    return "\n\n".join(rows)


def animate_law_results(law_data: list[dict], delay: float = 1.0):
    if not law_data:
        st.info("ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    n = len(law_data)
    prog = st.progress(0.0, text="ê´€ë ¨ ë²•ë ¹ ë¯¸ë¦¬ë³´ê¸°")
    placeholder = st.empty()
    for i, law in enumerate(law_data, 1):
        with placeholder.container():
            st.markdown(
                f"""
                <div class='law-slide'>
                    <div style='font-weight:700'>ğŸ” {i}. {law['ë²•ë ¹ëª…']} <span style='opacity:.7'>({law['ë²•ë ¹êµ¬ë¶„']})</span></div>
                    <div style='margin-top:6px'>ì†Œê´€ë¶€ì²˜: {law['ì†Œê´€ë¶€ì²˜ëª…']}</div>
                    <div>ì‹œí–‰ì¼ì: {law['ì‹œí–‰ì¼ì']} / ê³µí¬ì¼ì: {law['ê³µí¬ì¼ì']}</div>
                    {f"<div style='margin-top:6px'><a href='{law['ë²•ë ¹ìƒì„¸ë§í¬']}' target='_blank'>ë²•ë ¹ ìƒì„¸ë³´ê¸°</a></div>" if law.get('ë²•ë ¹ìƒì„¸ë§í¬') else ''}
                </div>
                """,
                unsafe_allow_html=True,
            )
        prog.progress(i / n, text=f"ê´€ë ¨ ë²•ë ¹ ë¯¸ë¦¬ë³´ê¸° {i}/{n}")
        time.sleep(max(0.0, delay))
    prog.empty()

# =============================
# Azure í•¨ìˆ˜ì½œ(íˆ´) â€” ë˜í¼ & ìŠ¤í‚¤ë§ˆ & ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
# =============================
SUPPORTED_TARGETS = ["law", "admrul", "ordin", "trty"]

def tool_search_one(target: str, query: str, num_rows: int = 5):
    if target not in SUPPORTED_TARGETS:
        return {"error": f"unsupported target: {target}"}
    items, endpoint, err = _call_moleg_list(target, query, num_rows=num_rows)
    return {"target": target, "query": query, "endpoint": endpoint, "error": err, "items": items}

def tool_search_multi(queries: list, num_rows: int = 5):
    out = []
    for q in queries:
        t = q.get("target","law"); s = q.get("query","")
        out.append(tool_search_one(t, s, num_rows=num_rows))
    return out

TOOLS = [
    {
        "type":"function",
        "function":{
            "name":"search_one",
            "description":"MOLEG ëª©ë¡ APIì—ì„œ ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ë¥¼ ê²€ìƒ‰í•œë‹¤.",
            "parameters":{
                "type":"object",
                "properties":{
                    "target":{"type":"string","enum":SUPPORTED_TARGETS},
                    "query":{"type":"string"},
                    "num_rows":{"type":"integer","minimum":1,"maximum":10,"default":5}
                },
                "required":["target","query"]
            }
        }
    },
    {
        "type":"function",
        "function":{
            "name":"search_multi",
            "description":"ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬/ì§ˆì˜ì–´ë¥¼ í•œ ë²ˆì— ê²€ìƒ‰í•œë‹¤.",
            "parameters":{
                "type":"object",
                "properties":{
                    "queries":{
                        "type":"array",
                        "items":{
                            "type":"object",
                            "properties":{
                                "target":{"type":"string","enum":SUPPORTED_TARGETS},
                                "query":{"type":"string"}
                            },
                            "required":["target","query"]
                        }
                    },
                    "num_rows":{"type":"integer","minimum":1,"maximum":10,"default":5}
                },
                "required":["queries"]
            }
        }
    }
]

# ============================
# [GPT PATCH] app.py ì—°ê²°ë¶€
# ë¶™ì—¬ë„£ëŠ” ìœ„ì¹˜: client/AZURE/TOOLS ë“± ì¤€ë¹„ê°€ ëë‚œ "ì•„ë˜",
#               ì‚¬ì´ë“œë°”/ë ˆì´ì•„ì›ƒ ë Œë”ë§ì´ ì‹œì‘ë˜ê¸° "ìœ„"
# ============================

# 1) imports
#from modules import AdviceEngine, Intent, classify_intent, pick_mode, build_sys_for_mode  # noqa: F401

# 2) ì—”ì§„ ìƒì„± (í•œ ë²ˆë§Œ)
#engine = None
#try:
    # ì•„ë˜ ê°ì²´ë“¤ì€ app.py ìƒë‹¨ì—ì„œ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # - client, AZURE, TOOLS
    # - safe_chat_completion
    # - tool_search_one, tool_search_multi
    # - prefetch_law_context, _summarize_laws_for_primer
    #if client and AZURE and TOOLS:
     #   engine = AdviceEngine(
      #      client=client,
       #     model=AZURE["deployment"],
        #    tools=TOOLS,
          #  safe_chat_completion=safe_chat_completion,
           # tool_search_one=tool_search_one,
 #           tool_search_multi=tool_search_multi,
  #          prefetch_law_context=prefetch_law_context,            # ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
   #         summarize_laws_for_primer=_summarize_laws_for_primer, # ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
    #        temperature=0.2,
        #)
#except NameError:
    # ë§Œì•½ ìœ„ ê°ì²´ë“¤ì´ ì•„ì§ ì •ì˜ë˜ê¸° ì „ ìœ„ì¹˜ë¼ë©´,
    # ì´ íŒ¨ì¹˜ë¥¼ í•´ë‹¹ ì •ì˜ 'ì•„ë˜'ë¡œ ì˜®ê²¨ ë¶™ì´ì„¸ìš”.
 #   pass

# =============================
# í‚¤ì›Œë“œ ê¸°ë³¸ê°’/ìœ„ì ¯ í—¬í¼ (with st.sidebar: ìœ„ì— ë°°ì¹˜)
# =============================

# íƒ­ë³„ ê¸°ë³¸ í‚¤ì›Œë“œ 1ê°œ(ì—†ìœ¼ë©´ ì²« í•­ëª© ì‚¬ìš©)
DEFAULT_KEYWORD = {
    "ë²•ë ¹": "ê°œì •",
    "í–‰ì •ê·œì¹™": "ê°œì •",
    "ìì¹˜ë²•ê·œ": "ê°œì •",
    "ì¡°ì•½": "ë¹„ì¤€",
    "íŒë¡€": "ëŒ€ë²•ì›",
    "í—Œì¬": "ìœ„í—Œ",
    "í•´ì„ë¡€": "ìœ ê¶Œí•´ì„",
    "ìš©ì–´/ë³„í‘œ": "ì •ì˜",   # â† 'ìš©ì–´' ëŒ€ì‹  'ì •ì˜'ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ê¶Œì¥
}

def one_default(options, prefer=None):
    """ì˜µì…˜ ëª©ë¡ì—ì„œ ê¸°ë³¸ìœ¼ë¡œ 1ê°œë§Œ ì„ íƒí•´ ë°˜í™˜"""
    if not options:
        return []
    if prefer and prefer in options:
        return [prefer]
    return [options[0]]

# st_tagsê°€ ìˆìœ¼ë©´ íƒœê·¸ ìœ„ì ¯, ì—†ìœ¼ë©´ multiselectë¡œ ë™ì‘
try:
    from streamlit_tags import st_tags
    def kw_input(label, options, key, tab_name=None):
        prefer = DEFAULT_KEYWORD.get(tab_name)
        return st_tags(
            label=label,
            text="ì‰¼í‘œ(,) ë˜ëŠ” Enterë¡œ ì¶”ê°€/ì‚­ì œ",
            value=one_default(options, prefer),   # âœ… ê¸°ë³¸ 1ê°œë§Œ
            suggestions=options,
            maxtags=len(options),
            key=key,
        )
except Exception:
    def kw_input(label, options, key, tab_name=None):
        prefer = DEFAULT_KEYWORD.get(tab_name)
        return st.multiselect(
            label=label,
            options=options,
            default=one_default(options, prefer), # âœ… ê¸°ë³¸ 1ê°œë§Œ
            key=key,
            help="í•„ìš”í•œ í‚¤ì›Œë“œë§Œ ì¶”ê°€ë¡œ ì„ íƒí•˜ì„¸ìš”.",
        )

# =============================
# Sidebar: ë§í¬ ìƒì„±ê¸° (ë¬´ì¸ì¦)
# =============================
with st.sidebar:
    # --- ì‚¬ì´ë“œë°”: ìƒˆ ëŒ€í™” ë²„íŠ¼(ë§í¬ ìƒì„±ê¸° ìœ„) ---
    if st.button("ğŸ†• ìƒˆ ëŒ€í™”", type="primary", use_container_width=True, key="__btn_new_chat__"):
        for k in ("messages", "_last_user_nonce", "_pending_user_q", "_pending_user_nonce", "_last_ans_hash"):
            st.session_state.pop(k, None)
        st.session_state["_clear_input"] = True
        st.rerun()

    st.header("ğŸ”— ë§í¬ ìƒì„±ê¸° (ë¬´ì¸ì¦)")
    tabs = st.tabs(["ë²•ë ¹", "í–‰ì •ê·œì¹™", "ìì¹˜ë²•ê·œ", "ì¡°ì•½", "íŒë¡€", "í—Œì¬", "í•´ì„ë¡€", "ìš©ì–´/ë³„í‘œ"])

    # persist/restore active sidebar tab across reruns
    st.markdown("""
<script>
(function(){
  const KEY = "left_sidebar_active_tab";
  function labelOf(btn){ return (btn?.innerText || btn?.textContent || "").trim(); }
  function restore(){
    const want = sessionStorage.getItem(KEY);
    if(!want) return false;
    const btns = Array.from(window.parent.document.querySelectorAll('[data-testid="stSidebar"] [role="tablist"] button[role="tab"]'));
    if(btns.length === 0) return false;
    const match = btns.find(b => labelOf(b) === want);
    if(!match) return false;
    if(match.getAttribute('aria-selected') !== 'true'){ match.click(); }
    return true;
  }
  function bind(){
    const root = window.parent.document.querySelector('[data-testid="stSidebar"]');
    if(!root) return;
    // Save when user clicks a tab
    root.addEventListener('click', (e)=>{
      const b = e.target.closest('button[role="tab"]');
      if(b){ sessionStorage.setItem(KEY, labelOf(b)); }
    }, true);
    // Keep trying to restore selection until ready
    const tid = setInterval(()=>{ if(restore()) clearInterval(tid); }, 100);
    setTimeout(()=>clearInterval(tid), 4000);
    // Also restore when DOM changes (e.g., reruns)
    new MutationObserver(()=>restore()).observe(root, {subtree:true, childList:true, attributes:true});
  }
  window.addEventListener('load', bind, {once:true});
  setTimeout(bind, 0);
})();
</script>
""", unsafe_allow_html=True)

    # ê³µí†µ ì¶”ì²œ í”„ë¦¬ì…‹(ëª¨ë‘ 1ê°œë§Œ ê¸°ë³¸ ì„ íƒë˜ë„ë¡ kw_input + DEFAULT_KEYWORD í™œìš©)
    adm_suggest    = cached_suggest_for_tab("admrul")
    ordin_suggest  = cached_suggest_for_tab("ordin")
    trty_suggest   = cached_suggest_for_tab("trty")
    case_suggest   = cached_suggest_for_tab("prec")
    cc_suggest     = cached_suggest_for_tab("cc")
    interp_suggest = cached_suggest_for_tab("expc")
    term_suggest   = ["ì •ì˜", "ìš©ì–´", "ë³„í‘œ", "ì„œì‹"]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë²•ë ¹
    with tabs[0]:
        law_name = st.text_input("ë²•ë ¹ëª…", value="ë¯¼ë²•", key="sb_law_name")
        # ë²•ë ¹ëª… ê¸°ë°˜ ì¶”ì²œ
        law_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)",
                            cached_suggest_for_law(law_name),
                            key="sb_law_keys",
                            tab_name="ë²•ë ¹")

        if st.button("ë²•ë ¹ ìƒì„¸ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_law"):
            url = hangul_law_with_keys(law_name, law_keys) if law_keys else hangul_by_name("ë²•ë ¹", law_name)
            st.session_state["gen_law"] = {"url": url, "kind": "law", "q": law_name}

        if "gen_law" in st.session_state:
            d = st.session_state["gen_law"]
            present_url_with_fallback(d["url"], d["kind"], d["q"], label_main="ìƒˆ íƒ­ì—ì„œ ì—´ê¸°")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í–‰ì •ê·œì¹™
    with tabs[1]:
        adm_name = st.text_input("í–‰ì •ê·œì¹™ëª…", value="ìˆ˜ì…í†µê´€ì‚¬ë¬´ì²˜ë¦¬ì—ê´€í•œê³ ì‹œ", key="sb_adm_name")
        dept     = st.selectbox("ì†Œê´€ ë¶€ì²˜(ì„ íƒ)", MINISTRIES, index=0, key="sb_adm_dept")
        adm_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", adm_suggest, key="sb_adm_keys", tab_name="í–‰ì •ê·œì¹™")

        colA, colB = st.columns(2)
        with colA: issue_no = st.text_input("ê³µí¬ë²ˆí˜¸(ì„ íƒ)", value="", key="sb_adm_no")
        with colB: issue_dt = st.text_input("ê³µí¬ì¼ì(YYYYMMDD, ì„ íƒ)", value="", key="sb_adm_dt")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("í–‰ì •ê·œì¹™ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_adm"):
                url = hangul_admrul_with_keys(adm_name, issue_no, issue_dt) if (issue_no and issue_dt) else hangul_by_name("í–‰ì •ê·œì¹™", adm_name)
                st.session_state["gen_adm"] = {"url": url, "kind": "admrul", "q": adm_name}
        with col2:
            if st.button("í–‰ì •ê·œì¹™(ë¶€ì²˜/í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_adm_dept"):
                keys = " ".join(adm_keys) if adm_keys else ""
                q = " ".join([x for x in [adm_name,
                                          (dept if dept and dept != MINISTRIES[0] else ""),
                                          keys] if x])
                url = build_fallback_search("admrul", q)
                st.session_state["gen_adm_dept"] = {"url": url, "kind": "admrul", "q": q}

        if "gen_adm" in st.session_state:
            d = st.session_state["gen_adm"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_adm_dept" in st.session_state:
            d = st.session_state["gen_adm_dept"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìì¹˜ë²•ê·œ
    with tabs[2]:
        ordin_name = st.text_input("ìì¹˜ë²•ê·œëª…", value="ì„œìš¸íŠ¹ë³„ì‹œê²½ê´€ì¡°ë¡€", key="sb_ordin_name")
        local_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", ordin_suggest, key="sb_local_keys", tab_name="ìì¹˜ë²•ê·œ")

        colA, colB = st.columns(2)
        with colA: ordin_no = st.text_input("ê³µí¬ë²ˆí˜¸(ì„ íƒ)", value="", key="sb_ordin_no")
        with colB: ordin_dt = st.text_input("ê³µí¬ì¼ì(YYYYMMDD, ì„ íƒ)", value="", key="sb_ordin_dt")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ìì¹˜ë²•ê·œ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_ordin"):
                url = hangul_ordin_with_keys(ordin_name, ordin_no, ordin_dt) if (ordin_no and ordin_dt) else hangul_by_name("ìì¹˜ë²•ê·œ", ordin_name)
                st.session_state["gen_ordin"] = {"url": url, "kind": "ordin", "q": ordin_name}
        with col2:
            if st.button("ìì¹˜ë²•ê·œ(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_ordin_kw"):
                q = " ".join([ordin_name] + (local_keys or []))
                url = build_fallback_search("ordin", q)
                st.session_state["gen_ordin_kw"] = {"url": url, "kind": "ordin", "q": q}

        if "gen_ordin" in st.session_state:
            d = st.session_state["gen_ordin"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_ordin_kw" in st.session_state:
            d = st.session_state["gen_ordin_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¡°ì•½
    with tabs[3]:
        trty_no = st.text_input("ì¡°ì•½ ë²ˆí˜¸", value="2193", key="sb_trty_no")
        eff_dt  = st.text_input("ë°œíš¨ì¼ì(YYYYMMDD)", value="20140701", key="sb_trty_eff")
        trty_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", trty_suggest, key="sb_trty_keys", tab_name="ì¡°ì•½")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ì¡°ì•½ ìƒì„¸ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_trty"):
                url = hangul_trty_with_keys(trty_no, eff_dt)
                st.session_state["gen_trty"] = {"url": url, "kind": "trty", "q": trty_no}
        with col2:
            if st.button("ì¡°ì•½(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_trty_kw"):
                q = " ".join([trty_no] + (trty_keys or [])) if trty_no else " ".join(trty_keys or [])
                url = build_fallback_search("trty", q)
                st.session_state["gen_trty_kw"] = {"url": url, "kind": "trty", "q": q}

        if "gen_trty" in st.session_state:
            d = st.session_state["gen_trty"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_trty_kw" in st.session_state:
            d = st.session_state["gen_trty_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íŒë¡€
    with tabs[4]:
        case_no = st.text_input("ì‚¬ê±´ë²ˆí˜¸(ì˜ˆ: 2010ë‹¤52349)", value="2010ë‹¤52349", key="sb_case_no")
        case_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", case_suggest, key="sb_case_keys", tab_name="íŒë¡€")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ëŒ€ë²•ì› íŒë¡€ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_prec"):
                url = build_scourt_link(case_no)
                st.session_state["gen_prec"] = {"url": url, "kind": "prec", "q": case_no}
        with col2:
            if st.button("íŒë¡€(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_prec_kw"):
                q = " ".join([case_no] + (case_keys or [])) if case_no else " ".join(case_keys or [])
                url = build_fallback_search("prec", q)
                st.session_state["gen_prec_kw"] = {"url": url, "kind": "prec", "q": q}

        if "gen_prec" in st.session_state:
            d = st.session_state["gen_prec"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_prec_kw" in st.session_state:
            d = st.session_state["gen_prec_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—Œì¬
    with tabs[5]:
        cc_q = st.text_input("í—Œì¬ ì‚¬ê±´/í‚¤ì›Œë“œ", value="2022í—Œë§ˆ1312", key="sb_cc_q")
        cc_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", cc_suggest, key="sb_cc_keys", tab_name="í—Œì¬")

        if st.button("í—Œì¬ ê²€ìƒ‰ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_cc"):
            q = " ".join([cc_q] + (cc_keys or [])) if cc_q else " ".join(cc_keys or [])
            url = build_fallback_search("cc", q)
            st.session_state["gen_cc"] = {"url": url, "kind": "cc", "q": q}

        if "gen_cc" in st.session_state:
            d = st.session_state["gen_cc"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•´ì„ë¡€
    with tabs[6]:
        colA, colB = st.columns(2)
        with colA:
            expc_id = st.text_input("í•´ì„ë¡€ ID", value="313107", key="sb_expc_id")
            if st.button("í•´ì„ë¡€ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_expc"):
                url = expc_public_by_id(expc_id)
                st.session_state["gen_expc"] = {"url": url, "kind": "expc", "q": expc_id}
        with colB:
            interp_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", interp_suggest, key="sb_interp_keys", tab_name="í•´ì„ë¡€")
            if st.button("í•´ì„ë¡€(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_expc_kw"):
                q = " ".join([expc_id] + (interp_keys or [])) if expc_id else " ".join(interp_keys or [])
                url = build_fallback_search("expc", q)
                st.session_state["gen_expc_kw"] = {"url": url, "kind": "expc", "q": q}

        if "gen_expc" in st.session_state:
            d = st.session_state["gen_expc"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_expc_kw" in st.session_state:
            d = st.session_state["gen_expc_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìš©ì–´/ë³„í‘œ
    with tabs[7]:
        col1, col2 = st.columns(2)
        with col1:
            term_id   = st.text_input("ìš©ì–´ ID", value="100034", key="sb_term_id")
            term_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", term_suggest, key="sb_term_keys", tab_name="ìš©ì–´/ë³„í‘œ")
            if st.button("ìš©ì–´ì‚¬ì „ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_term"):
                url = f"https://www.law.go.kr/LSW/termInfoR.do?termSeq={up.quote(term_id)}"
                st.session_state["gen_term"] = {"url": url, "kind": "term", "q": term_id}
        with col2:
            flseq = st.text_input("ë³„í‘œÂ·ì„œì‹ íŒŒì¼ ID", value="110728887", key="sb_flseq")
            if st.button("ë³„í‘œ/ì„œì‹ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", key="sb_btn_file"):
                url = licbyl_file_download(flseq)
                st.session_state["gen_file"] = {"url": url, "kind": "file", "q": flseq}

        if "gen_term" in st.session_state:
            d = st.session_state["gen_term"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_file" in st.session_state:
            d = st.session_state["gen_file"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

# 1) pending â†’ messages ë¨¼ì € ì˜®ê¹€
user_q = _push_user_from_pending()

# capture the nonce associated with this pending input (if any)
# === ì§€ê¸ˆ í„´ì´ 'ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ëŸ°'ì¸ì§€ ì—¬ë¶€ (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ í‘œì‹œ/ìˆ¨ê¹€ì— ì‚¬ìš©)
ANSWERING = bool(user_q)
st.session_state["__answering__"] = ANSWERING

# 2) ëŒ€í™” ì‹œì‘ ì—¬ë¶€ ê³„ì‚° (êµì²´ëœ í•¨ìˆ˜)
chat_started = _chat_started()

# chat_started ê³„ì‚° ì§í›„ì— ì¶”ê°€
st.markdown(f"""
<script>
document.body.classList.toggle('chat-started', {str(chat_started).lower()});
document.body.classList.toggle('answering', {str(ANSWERING).lower()});
</script>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* âœ… í¬ìŠ¤íŠ¸-ì±— UI(ì—…ë¡œë”+ì…ë ¥í¼)ëŠ” 'ë‹µë³€ ìƒì„± ì¤‘'ì—ë§Œ ìˆ¨ê¹€ */
body.answering .post-chat-ui{ margin-top: 8px; }

/* âœ… ê¸°ì¡´ chatbar ì»´í¬ë„ŒíŠ¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì™„ì „ ìˆ¨ê¹€ */
#chatbar-fixed { display: none !important; }
/* ë‹µë³€ ì¤‘ì¼ ë•Œë§Œ í•˜ë‹¨ ì—¬ë°± ì¶•ì†Œ */
body.answering .block-container { 
    padding-bottom: calc(var(--chat-gap) + 24px) !important; 
}
</style>
""", unsafe_allow_html=True)

# âœ… PRE-CHAT: ì™„ì „ ì¤‘ì•™(ë·°í¬íŠ¸ ê¸°ì¤€) + ì—¬ë°± ì œê±°
if not chat_started:
    st.markdown("""
    <style>
      /* í”„ë¦¬ì±—: ìš°ì¸¡ íŒ¨ë„ë§Œ ìˆ¨ê¸°ê³ , ìŠ¤í¬ë¡¤ì„ ì ê°€ ìƒë‹¨ ê³ ì • */
      #search-flyout{ display:none !important; }
      html, body{ height:100%; overflow-y:hidden !important; }
      .main > div:first-child{ height:100vh !important; }
      .block-container{ min-height:100vh !important; padding-top:12px !important; padding-bottom:0 !important; }
      /* ì „ì—­ ê°€ìš´ë° ì •ë ¬ ê·œì¹™ì´ ìˆì–´ë„ í”„ë¦¬ì±—ì—ì„  íˆì–´ë¡œë¥¼ 'ìœ„ì—ì„œë¶€í„°' ë°°ì¹˜ */
      .center-hero{ min-height:auto !important; display:block !important; }
    </style>
    <script>
    (function(){
      try{ history.scrollRestoration='manual'; }catch(e){}
      const up=()=>{ window.scrollTo(0,0); if(document.activeElement) document.activeElement.blur(); };
      up(); setTimeout(up,0); setTimeout(up,50);
      document.addEventListener('focusin', up, true);
      new MutationObserver(up).observe(document.body, {subtree:true, childList:true});
    })();
    </script>
    """, unsafe_allow_html=True)

    st.markdown("""
    <style>
      /* ìš°ì¸¡ íŒ¨ë„ë§Œ ìˆ¨ê¹€ */
      #search-flyout{ display:none !important; }

      /* â›³ï¸ í”„ë¦¬ì±—: ìŠ¤í¬ë¡¤ ìƒê¸°ì§€ ì•Šê²Œ ì ê·¸ê³  ìƒë‹¨ ê³ ì • */
      html, body{ height:100%; overflow-y:hidden !important; }
      .main > div:first-child{ height:100vh !important; }              /* Streamlit ë£¨íŠ¸ */
      .block-container{
        min-height:100vh !important;   /* í™”ë©´ë§Œí¼ë§Œ */
        padding-top:12px !important;
        padding-bottom:0 !important;   /* ë°”ë‹¥ ì—¬ë°± ì œê±° */
        margin-left:auto !important; margin-right:auto !important;
      }
    </style>
    <script>
    (function(){
      try{ history.scrollRestoration='manual'; }catch(e){}
      const up=()=>{ window.scrollTo(0,0); if(document.activeElement) document.activeElement.blur(); };
      up(); setTimeout(up,0); setTimeout(up,50);    // ìë™ í¬ì»¤ìŠ¤ ëŒ€ë¹„
      document.addEventListener('focusin', up, true);
      new MutationObserver(up).observe(document.body, {subtree:true, childList:true});
    })();
    </script>            
               
    """, unsafe_allow_html=True)

    render_pre_chat_center()
    st.stop()
    
else:
    st.markdown("""
    <style>
      /* ì±„íŒ… ì‹œì‘ í›„: ìŠ¤í¬ë¡¤ ì •ìƒ ë³µì› */
      html, body{ overflow-y:auto !important; }
      .main > div:first-child{ height:auto !important; }
      .block-container{ min-height:auto !important; }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("""
    <style>
      /* ğŸ“Œ ì±„íŒ… ì‹œì‘ í›„ì—ëŠ” ì •ìƒ ìŠ¤í¬ë¡¤ */
      html, body{ overflow-y:auto !important; }
      .block-container{ min-height:auto !important; }
    </style>
    """, unsafe_allow_html=True)

    # ... ê¸°ì¡´ ë Œë”ë§ ê³„ì†


# ğŸ¯ ëŒ€í™” ì „ì—ëŠ” ìš°ì¸¡ íŒ¨ë„ ìˆ¨ê¸°ê³ , ì—¬ë°±ì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ì™„ì „ ì¤‘ì•™ ì •ë ¬
if not chat_started:
    st.markdown("""
    <style>
      /* hide right rail before first message */
      #search-flyout { display: none !important; }
      /* remove right gutter so hero sits dead-center */
      @media (min-width:1280px) { .block-container { padding-right: 0 !important; } }
      /* bottom padding í¬ê²Œ ì¤„ì—¬ì„œ í™”ë©´ ì •ì¤‘ì•™ì— ì˜¤ë„ë¡ */
      .block-container { padding-bottom: 64px !important; }
      /* hero ë†’ì´ ì‚´ì§ ì¤„ì—¬ ìœ„/ì•„ë˜ ê· í˜• */
      .center-hero { min-height: calc(100vh - 160px) !important; }
    </style>
    """, unsafe_allow_html=True)
    
render_api_diagnostics()   

# 3) í™”ë©´ ë¶„ê¸°
if not chat_started:
    render_pre_chat_center()   # ì¤‘ì•™ íˆì–´ë¡œ + ì¤‘ì•™ ì—…ë¡œë”
    st.stop()
else:
    # ğŸ”§ ëŒ€í™” ì‹œì‘ í›„ì—ëŠ” ì²¨ë¶€íŒŒì¼ ë°•ìŠ¤ë¥¼ ë Œë”ë§í•˜ì§€ ì•ŠìŒ (ì™„ì „íˆ ì œê±°)
    # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ì—…ë¡œë” ìˆ¨ê¹€ (ë Œë” ìì²´ ìƒëµ)
    # if not ANSWERING:
    #     render_bottom_uploader()   # í•˜ë‹¨ ê³ ì • ì—…ë¡œë” - ì£¼ì„ ì²˜ë¦¬
    pass

# === ëŒ€í™” ì‹œì‘ í›„: ìš°ì¸¡ ë ˆì¼ì„ í”¼í•´ì„œ ë°°ì¹˜(ì¹¨ë²” ë°©ì§€) ===
# ----- RIGHT FLYOUT: align once to the question box, stable -----
st.markdown("""
<style>
  :root{
    --flyout-width: 360px;   /* ìš°ì¸¡ íŒ¨ë„ í­ */
    --flyout-gap:   80px;    /* ë³¸ë¬¸(ë‹µë³€ì˜ì—­)ê³¼ì˜ ê°€ë¡œ ê°„ê²© */
  }

  /* ë³¸ë¬¸ì´ ìš°ì¸¡ íŒ¨ë„ì„ í”¼í•´ ë°°ì¹˜ë˜ë„ë¡ ì—¬ë°± í™•ë³´ */
  @media (min-width:1280px){
    .block-container{
      padding-right: calc(var(--flyout-width) + var(--flyout-gap)) !important;
    }
  }

  /* ====== íŒ¨ë„ ë°°ì¹˜ ëª¨ë“œ ======
     (A) í™”ë©´ ê³ ì •(ìŠ¤í¬ë¡¤í•´ë„ í•­ìƒ ë³´ì„) â†’ position: fixed (ê¸°ë³¸)
     (B) ë”°ë¼ì˜¤ì§€ ì•Šê²Œ(ë³¸ë¬¸ê³¼ í•¨ê»˜ ìœ„ë¡œ ì˜¬ë¼ê°€ë„ë¡) â†’ position: sticky ë¡œ êµì²´
     ì›í•˜ëŠ” ìª½ í•œ ì¤„ë§Œ ì“°ì„¸ìš”.
  */
  @media (min-width:1280px){
    #search-flyout{
      position: fixed !important;                 /* â† A) í™”ë©´ ê³ ì • */
      /* position: sticky !important;             /* â† B) ë”°ë¼ì˜¤ì§€ ì•Šê²Œ: ì´ ì¤„ë¡œ êµì²´ */
      top: var(--flyout-top, 120px) !important;   /* JSê°€ í•œ ë²ˆ ê³„ì‚°í•´ ë„£ìŒ */
      right: 24px !important;
      left: auto !important; bottom: auto !important;

      width: var(--flyout-width) !important;
      max-width: 38vw !important;
      max-height: calc(100vh - var(--flyout-top,120px) - 24px) !important;
      overflow: auto !important;
      z-index: 58 !important;                     /* ì—…ë¡œë”(60), ì…ë ¥ì°½(70)ë³´ë‹¤ ë‚®ê²Œ */
    }
  }

  /* ëª¨ë°”ì¼/ì¢ì€ í™”ë©´ì€ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì„œ íë¦„ */
  @media (max-width:1279px){
    #search-flyout{ position: static !important; max-height:none !important; overflow:visible !important; }
    .block-container{ padding-right: 0 !important; }
  }
</style>

<script>
(() => {
  // ì§ˆë¬¸ ì…ë ¥ ìœ„ì¹˜ë¥¼ "í•œ ë²ˆë§Œ" ì½ì–´ì„œ --flyout-top ì„ ì„¤ì •
  const CANDIDATES = [
    '#chatbar-fixed',
    'section[data-testid="stChatInput"]',
    '.block-container textarea'
  ];
  let done = false;

  function alignOnce(){
    if (done) return;
    const fly = document.querySelector('#search-flyout');
    if (!fly) return;

    let target = null;
    for (const sel of CANDIDATES){
      target = document.querySelector(sel);
      if (target) break;
    }
    if (!target) return;

    const r = target.getBoundingClientRect();       // viewport ê¸°ì¤€
    const top = Math.max(12, Math.round(r.top));
    document.documentElement.style.setProperty('--flyout-top', top + 'px');
    done = true;  // í•œ ë²ˆë§Œ
  }

  // 1) ì²« ë Œë” ì§í›„
  window.addEventListener('load', () => setTimeout(alignOnce, 0));

  // 2) ëŒ€ìƒì´ ëŠ¦ê²Œ ìƒê²¨ë„ í•œ ë²ˆë§Œ ì •ë ¬
  const mo = new MutationObserver(() => alignOnce());
  mo.observe(document.body, {childList: true, subtree: true});
  (function stopWhenDone(){ if (done) mo.disconnect(); requestAnimationFrame(stopWhenDone); })();

  // 3) ì°½ í¬ê¸° ë³€ê²½ ì‹œ í•œ ë²ˆ ì¬ì •ë ¬
  window.addEventListener('resize', () => { done = false; alignOnce(); });
})();
</script>
""", unsafe_allow_html=True)




with st.container():
    st.session_state['_prev_assistant_txt'] = ''  # reset per rerun
    for i, m in enumerate(st.session_state.messages):
        # --- UI dedup guard: skip if same assistant content as previous ---
        if isinstance(m, dict) and m.get('role')=='assistant':
            _t = (m.get('content') or '').strip()
            if '_prev_assistant_txt' not in st.session_state:
                st.session_state['_prev_assistant_txt'] = ''
            if _t and _t == st.session_state.get('_prev_assistant_txt',''):
                continue
            st.session_state['_prev_assistant_txt'] = _t
        role = m.get("role")
        content = (m.get("content") or "")
        if role == "assistant" and not content.strip():
            continue  # âœ… ë‚´ìš©ì´ ë¹„ë©´ ë§í’ì„  ìì²´ë¥¼ ë§Œë“¤ì§€ ì•ŠìŒ

        with st.chat_message(role):
            if role == "assistant":
                render_bubble_with_copy(content, key=f"past-{i}")

        # ì•ˆì „í•˜ê²Œ êº¼ë‚´ê¸°
                laws = (m.get("law") or []) if isinstance(m, dict) else []
                if laws:
                    with st.expander("ğŸ“‹ ì´ í„´ì—ì„œ ì°¸ê³ í•œ ë²•ë ¹ ìš”ì•½"):
                        for j, law in enumerate(laws, 1):
                            if not isinstance(law, dict):
                                continue

                            name = law.get('ë²•ë ¹ëª…') or law.get('ë²•ë ¹ëª…í•œê¸€') or law.get('title') or '(ì œëª© ì—†ìŒ)'
                            kind = law.get('ë²•ë ¹êµ¬ë¶„') or law.get('kind') or '-'
                            eff  = law.get('ì‹œí–‰ì¼ì') or law.get('effective_date') or '-'
                            pub  = law.get('ê³µí¬ì¼ì') or law.get('promulgation_date') or '-'
                            st.write(f"**{j}. {name}** ({kind})  | ì‹œí–‰ {eff}  | ê³µí¬ {pub}")

                            link = law.get('ë²•ë ¹ìƒì„¸ë§í¬') or law.get('ìƒì„¸ë§í¬') or law.get('detail_url') or ''
                            if link:
                                st.write(f"- ë§í¬: {link}")
            else:
                st.markdown(content)

# âœ… ë‹µë³€ ë§í’ì„  ë°”ë¡œ ì•„ë˜ì— ì…ë ¥/ì—…ë¡œë” ë¶™ì´ê¸° (ë‹µë³€ ìƒì„± ì¤‘ì´ ì•„ë‹ ë•Œë§Œ)
if chat_started and not st.session_state.get("__answering__", False):
    render_post_chat_simple_ui()

# âœ… ë©”ì‹œì§€ ë£¨í”„ ë°”ë¡œ ì•„ë˜(ì´ë¯¸ _inject_right_rail_css() ë‹¤ìŒ ì¶”ì²œ) â€” í•­ìƒ í˜¸ì¶œ
def _current_q_and_answer():
    msgs = st.session_state.get("messages", [])
    last_q = next((m for m in reversed(msgs) if m.get("role")=="user" and (m.get("content") or "").strip()), None)
    last_a = next((m for m in reversed(msgs) if m.get("role")=="assistant" and (m.get("content") or "").strip()), None)
    return (last_q or {}).get("content",""), (last_a or {}).get("content","")

# ğŸ”½ ëŒ€í™”ê°€ ì‹œì‘ëœ ë’¤ì—ë§Œ ìš°ì¸¡ íŒ¨ë„ ë…¸ì¶œ
# âœ… ë¡œë”©(ìŠ¤íŠ¸ë¦¬ë°) ì¤‘ì—ëŠ” íŒ¨ë„ì„ ë Œë”ë§í•˜ì§€ ì•ŠìŒ
# ğŸ”½ ëŒ€í™”ê°€ ì‹œì‘ëœ ë’¤ì—ë§Œ ìš°ì¸¡ íŒ¨ë„ ë…¸ì¶œ
# âœ… ë¡œë”©(ìŠ¤íŠ¸ë¦¬ë°) ì¤‘ì—ëŠ” íŒ¨ë„ì„ ë Œë”ë§í•˜ì§€ ì•ŠìŒ
if chat_started and not st.session_state.get("__answering__", False):
    q_for_panel, ans_for_panel = _current_q_and_answer()

    # í•¨ìˆ˜ë“¤ì´ íŒŒì¼ì˜ ë” ì•„ë˜ì—ì„œ ì •ì˜ë˜ì–´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „ ê°€ë“œ
    _ext_names = globals().get("extract_law_names_from_answer")
    _ext_arts  = globals().get("extract_article_pairs_from_answer")

    hints = _ext_names(ans_for_panel) if (_ext_names and ans_for_panel) else None
    arts  = _ext_arts(ans_for_panel)  if (_ext_arts  and ans_for_panel) else None

    render_search_flyout(
        q_for_panel or user_q,
        num_rows=8,
        hint_laws=hints,
        hint_articles=arts,   # â† ì¡°ë¬¸ íŒíŠ¸ë„ í•¨ê»˜ ì „ë‹¬
        show_debug=SHOW_SEARCH_DEBUG,
    )


# ===============================
# ì¢Œìš° ë¶„ë¦¬ ë ˆì´ì•„ì›ƒ: ì™¼ìª½(ë‹µë³€) / ì˜¤ë¥¸ìª½(í†µí•©ê²€ìƒ‰)
# ===============================\n
if user_q:
    # --- streaming aggregator v2: keep deltas for preview, but FINAL wins ---
    stream_box = None
    deltas_only = ""
    final_payload = ""
    collected_laws = []

    if client and AZURE:
        stream_box = st.empty()

    try:
        if stream_box is not None:
            stream_box.markdown("_AIê°€ ì§ˆì˜ë¥¼ í•´ì„í•˜ê³ , êµ­ê°€ë²•ë ¹ì •ë³´ DBë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤._")

        for kind, payload, law_list in ask_llm_with_tools(user_q, num_rows=5, stream=True):
            if kind == "delta":
                if payload:
                    deltas_only += payload
                    if SHOW_STREAM_PREVIEW and stream_box is not None:
                        stream_box.markdown(_normalize_text(deltas_only[-1500:]))
            elif kind == "final":
                final_payload  = (payload or "")
                collected_laws = law_list or []
                break

    except Exception as e:
        # ì˜ˆì™¸ ì‹œ í´ë°±
        laws, ep, err, mode = find_law_with_fallback(user_q, num_rows=10)
        collected_laws = laws
        law_ctx = format_law_context(laws)
        title = "ë²•ë¥  ìë¬¸ ë©”ëª¨"
        base_text = f"{title}\n\n{law_ctx}\n\n(ì˜¤ë¥˜: {e})"
    else:
        # ì •ìƒ ê²½ë¡œ: finalì´ ìˆìœ¼ë©´ final, ì—†ìœ¼ë©´ delta ëˆ„ì  ì‚¬ìš©
        base_text = (final_payload.strip() or deltas_only)
        # (ì¶”ê°€) ì‚¬ìš©ìê°€ 'ë³¸ë¬¸/ì›ë¬¸/ìš”ì•½í•˜ì§€ ë§' ìš”ì²­ + 'ì œnì¡°'ê°€ ìˆìœ¼ë©´ DRF ë³¸ë¬¸ì„ ê°•ì œ ì¸ìš©
from modules.law_fetch import fetch_article_block_by_mst  # ì•ˆì „í•˜ê²Œ ì—¬ê¸°ì„œ ì„í¬íŠ¸í•´ë„ OK
import re

if re.search(r'(ë³¸ë¬¸|ì›ë¬¸|ìš”ì•½\s*í•˜ì§€\s*ë§)', user_q or '', re.I):
    m = re.search(r'ì œ\d{1,4}ì¡°(ì˜\d{1,3})?', user_q or '')
    if m and collected_laws:
        want_article = m.group(0)

        # 1) í›„ë³´ ì¤‘ 'ë²•ë ¹ëª…' ë§¤ì¹­ ê°•í™” (ê³µë°± ì œê±°Â·ì–‘ë°©í–¥ contains)
        def _nm(it: dict) -> str:
            return (it.get('ë²•ë ¹ëª…') or it.get('ë²•ë ¹ëª…í•œê¸€') or '').replace(' ', '').strip()

        uq = (user_q or '').replace(' ', '')
        # ì§ˆë¬¸ì—ì„œ '...ë²•' í† í° í•˜ë‚˜ ì¶”ì¶œí•´ íŒíŠ¸ë¡œ ì‚¬ìš©
        m_name = re.search(r'([ê°€-í£0-9Â·\s]+ë²•)', user_q or '')
        hint = (m_name.group(1).replace(' ', '') if m_name else '')

        law_pick = next(
            (it for it in collected_laws
             if (_nm(it) and ((hint and hint in _nm(it)) or (_nm(it) in uq) or (uq in _nm(it))))),
            collected_laws[0]
        )

        # 2) ë²•ë ¹ëª…ìœ¼ë¡œ DRF ë§í¬ â†’ MST ì¶”ì¶œ (ì •í™•ë„ ìš°ì„ )
        mst_from_name = ''
        if hint:
            try:
                from modules.linking import fetch_drf_law_link_by_name
                from urllib.parse import urlsplit, parse_qsl
                drf_url = fetch_drf_law_link_by_name(hint)  # DRF ë©”ì¸ ë§í¬ (ì¿¼ë¦¬ì— MST í¬í•¨)
                if drf_url:
                    qs = dict(parse_qsl(urlsplit(drf_url).query))
                    mst_from_name = (qs.get('MST') or qs.get('mst') or '').strip()
            except Exception:
                mst_from_name = ''

        # 3) ìš°ì„  mst_from_name ì‚¬ìš©, ì—†ìœ¼ë©´ law_pickì—ì„œ í´ë°±
        mst = mst_from_name or (law_pick.get('MST') or law_pick.get('ë²•ë ¹ID') or law_pick.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸') or '').strip()
        if mst:
            eff = (law_pick.get('ì‹œí–‰ì¼ì') or law_pick.get('ê³µí¬ì¼ì') or '').strip().replace('-', '') or None
            body, link = fetch_article_block_by_mst(mst, want_article, prefer='JSON', efYd=eff)
            if body:
                head = f"### ìš”ì²­í•˜ì‹  {want_article}\n\n"
                if link:
                    head += f"[ë²•ì œì²˜ ì›ë¬¸ ë³´ê¸°]({link})\n\n"
                # DRFì—ì„œ ê°€ì ¸ì˜¨ ì›ë¬¸ì„ ë‹µë³€ ë§¨ ìœ„ì— ê·¸ëŒ€ë¡œ ì¸ìš©
                base_text = head + "```\n" + body + "\n```\n\n" + (base_text or "")


    # --- Postprocess & de-dup ---
    final_text = apply_final_postprocess(base_text, collected_laws)
    final_text = _dedupe_repeats(final_text)

    # --- seatbelt: skip if same answer already stored this turn ---
    _ans_hash = _hash_text(final_text)
    if st.session_state.get('_last_ans_hash') == _ans_hash:
        final_text = ""
    else:
        st.session_state['_last_ans_hash'] = _ans_hash

    if final_text.strip():
        # --- per-turn nonce guard: allow only one assistant append per user turn ---
        _nonce = st.session_state.get('current_turn_nonce') or st.session_state.get('_pending_user_nonce')
        _done = st.session_state.get('_nonce_done', {})
        if not (_nonce and _done.get(_nonce)):
            _append_message('assistant', final_text, law=collected_laws)
            if _nonce:
                _done[_nonce] = True
                st.session_state['_nonce_done'] = _done
            st.session_state['last_q'] = user_q
            st.session_state.pop('_pending_user_q', None)
            st.session_state.pop('_pending_user_nonce', None)
            st.rerun()

    # í”„ë¦¬ë·° ì»¨í…Œì´ë„ˆ ë¹„ìš°ê¸°
    if stream_box is not None:
        try:
            stream_box.empty()
        except Exception:
            pass

