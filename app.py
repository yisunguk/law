# app.py
import time
import json
import math
import html
import urllib.parse
import xml.etree.ElementTree as ET
from datetime import datetime

import requests
import streamlit as st
import streamlit.components.v1 as components
from openai import AzureOpenAI

# =============================
# ê¸°ë³¸ ì„¤ì • & ìŠ¤íƒ€ì¼ (ChatGPT ë ˆì´ì•„ì›ƒ)
# =============================
st.set_page_config(page_title="ë²•ì œì²˜ AI ì±—ë´‡", page_icon="âš–ï¸", layout="wide")

st.markdown("""
<style>
  /* ì¤‘ì•™ 900px ì»¨í…Œì´ë„ˆ - ë‹µë³€/ì…ë ¥ ë™ì¼ í­ */
  .block-container {max-width: 900px; margin: 0 auto;}
  .stChatInput {max-width: 900px; margin-left: auto; margin-right: auto;}

  /* ìƒë‹¨ í—¤ë” */
  .header {text-align:center;padding:1.0rem;border-radius:12px;
           background:linear-gradient(135deg,#8b5cf6,#a78bfa);
           color:#fff;margin:0 0 1rem 0}

  /* ë³µì‚¬ ì¹´ë“œ */
  .copy-wrap {background:#fff;color:#222;padding:12px;border-radius:12px;
              box-shadow:0 1px 6px rgba(0,0,0,.06);margin:6px 0}
  .copy-head {display:flex;justify-content:space-between;align-items:center;gap:12px}
  .copy-btn  {display:inline-flex;align-items:center;gap:6px;padding:6px 10px;border:1px solid #ddd;border-radius:8px;
              background:#f8f9fa;cursor:pointer;font-size:12px}
  .copy-body {margin-top:6px;line-height:1.6;white-space:pre-wrap}

  /* íƒ€ì´í•‘ ì¸ë””ì¼€ì´í„° */
  .typing-indicator {display:inline-block;width:16px;height:16px;border:3px solid #eee;border-top:3px solid #8b5cf6;
                     border-radius:50%;animation:spin 1s linear infinite;vertical-align:middle}
  @keyframes spin {0%{transform:rotate(0)}100%{transform:rotate(360deg)}}
</style>
""", unsafe_allow_html=True)

st.markdown(
    '<div class="header"><h2>âš–ï¸ ë²•ì œì²˜ ì¸ê³µì§€ëŠ¥ ë²•ë¥  ìƒë‹´ í”Œë«í¼</h2>'
    '<div>ë²•ì œì²˜ ê³µì‹ ë°ì´í„°ë¥¼ AIê°€ ë¶„ì„í•´ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤</div>'
    '<div>ë‹¹ì‹ ì˜ ë¬¸ì œë¥¼ ì…ë ¥í•˜ë©´ ë²•ë¥  ìë¬¸ì„œë¥¼ ì¶œë ¥í•´ ì¤ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ë¬¸ì œë¥¼ ì…ë ¥í•´ ë³´ì„¸ìš”</div></div>',
    unsafe_allow_html=True,
)

# =============================
# ë³µì‚¬ ë²„íŠ¼ ì¹´ë“œ (ë™ì  ë†’ì´ + ë‚´ë¶€ ìŠ¤í¬ë¡¤)
# =============================
def _estimate_height(text: str, min_h=160, max_h=900, per_line=18):
    # ëŒ€ëµ 60ìë¥¼ í•œ ì¤„ë¡œ ë³´ì•„ ì¤„ ìˆ˜ ì¶”ì •
    lines = text.count("\n") + max(1, math.ceil(len(text) / 60))
    h = min_h + lines * per_line
    return max(min_h, min(h, max_h))

def render_ai_with_copy(message: str, key: str):
    safe_for_clipboard = json.dumps(message)           # í´ë¦½ë³´ë“œìš©(ì›ë¬¸)
    safe_html = html.escape(message)                   # í™”ë©´ ë Œë”ë§ìš©(HTML ì´ìŠ¤ì¼€ì´í”„)
    est_h = _estimate_height(message)                  # ë†’ì´ ì¶”ì •

    html_card = f"""
    <div class="copy-wrap" style="max-height:{est_h}px; overflow:auto;">
      <div class="copy-head">
        <strong>AI ì–´ì‹œìŠ¤í„´íŠ¸</strong>
        <button id="copy-{key}" class="copy-btn" title="í´ë¦½ë³´ë“œë¡œ ë³µì‚¬">
          <svg width="14" height="14" viewBox="0 0 24 24" fill="none">
            <path d="M9 9h9v12H9z" stroke="#444"/>
            <path d="M6 3h9v3" stroke="#444"/>
            <path d="M6 6h3v3" stroke="#444"/>
          </svg>ë³µì‚¬
        </button>
      </div>
      <!-- escapeëœ ë³¸ë¬¸ì„ preë¡œ í‘œê¸°í•´ì„œ ë ˆì´ì•„ì›ƒ ë³´í˜¸ -->
      <pre class="copy-body" style="margin-top:6px;white-space:pre-wrap;word-break:break-word">{safe_html}</pre>
    </div>
    <script>
      (function(){{
        const btn = document.getElementById("copy-{key}");
        if (btn) {{
          btn.addEventListener("click", async () => {{
            try {{
              await navigator.clipboard.writeText({safe_for_clipboard});
              const old = btn.innerHTML;
              btn.innerHTML = "ë³µì‚¬ë¨!";
              setTimeout(()=>btn.innerHTML = old, 1200);
            }} catch(e) {{ alert("ë³µì‚¬ ì‹¤íŒ¨: "+e); }}
          }});
        }}
      }})();
    </script>
    """
    components.html(html_card, height=est_h + 48)

# =============================
# Secrets ë¡œë”©
# =============================
def load_secrets():
    law_key = None; azure = None
    try:
        law_key = st.secrets["LAW_API_KEY"]
    except Exception:
        st.error("`LAW_API_KEY`ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit â†’ App settings â†’ Secretsì— ì¶”ê°€í•˜ì„¸ìš”.")
    try:
        azure = st.secrets["azure_openai"]
        _ = azure["api_key"]; _ = azure["endpoint"]; _ = azure["deployment"]; _ = azure["api_version"]
    except Exception:
        st.error("[azure_openai] ì„¹ì…˜(api_key, endpoint, deployment, api_version) ëˆ„ë½")
        azure = None
    return law_key, azure

LAW_API_KEY, AZURE = load_secrets()

# =============================
# Azure OpenAI í´ë¼ì´ì–¸íŠ¸
# =============================
client = None
if AZURE:
    try:
        client = AzureOpenAI(
            api_key=AZURE["api_key"],
            api_version=AZURE["api_version"],
            azure_endpoint=AZURE["endpoint"],
        )
    except Exception as e:
        st.error(f"Azure OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# =============================
# ì„¸ì…˜ ìƒíƒœ (ChatGPT í˜¸í™˜ êµ¬ì¡°)
# =============================
# messages: [{role: "user"|"assistant", content: str, law: list|None, ts: str}]
if "messages" not in st.session_state:
    st.session_state.messages = []
if "settings" not in st.session_state:
    st.session_state.settings = {"num_rows": 5, "include_search": True}

# =============================
# ë²•ì œì²˜ API
# =============================
@st.cache_data(show_spinner=False, ttl=300)
def search_law_data(query: str, num_rows: int = 5):
    if not LAW_API_KEY:
        return [], None, "LAW_API_KEY ë¯¸ì„¤ì •"
    params = {
        "serviceKey": urllib.parse.quote_plus(LAW_API_KEY),
        "target": "law",
        "query": query,
        "numOfRows": max(1, min(10, int(num_rows))),
        "pageNo": 1,
    }
    endpoints = [
        "https://apis.data.go.kr/1170000/law/lawSearchList.do",
        "http://apis.data.go.kr/1170000/law/lawSearchList.do",
    ]
    last_err = None
    for url in endpoints:
        try:
            res = requests.get(url, params=params, timeout=15)
            res.raise_for_status()
            root = ET.fromstring(res.text)
            laws = []
            for law in root.findall(".//law"):
                laws.append({
                    "ë²•ë ¹ëª…": law.findtext("ë²•ë ¹ëª…í•œê¸€", default=""),
                    "ë²•ë ¹ì•½ì¹­ëª…": law.findtext("ë²•ë ¹ì•½ì¹­ëª…", default=""),
                    "ì†Œê´€ë¶€ì²˜ëª…": law.findtext("ì†Œê´€ë¶€ì²˜ëª…", default=""),
                    "ë²•ë ¹êµ¬ë¶„ëª…": law.findtext("ë²•ë ¹êµ¬ë¶„ëª…", default=""),
                    "ì‹œí–‰ì¼ì": law.findtext("ì‹œí–‰ì¼ì", default=""),
                    "ê³µí¬ì¼ì": law.findtext("ê³µí¬ì¼ì", default=""),
                    "ë²•ë ¹ìƒì„¸ë§í¬": law.findtext("ë²•ë ¹ìƒì„¸ë§í¬", default=""),
                })
            return laws, url, None
        except Exception as e:
            last_err = e
            continue
    return [], None, f"ë²•ì œì²˜ API ì—°ê²° ì‹¤íŒ¨: {last_err}"

def format_law_context(law_data):
    if not law_data: return "ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    rows = []
    for i, law in enumerate(law_data, 1):
        rows.append(
            f"{i}. {law['ë²•ë ¹ëª…']} ({law['ë²•ë ¹êµ¬ë¶„ëª…']})\n"
            f"   - ì†Œê´€ë¶€ì²˜: {law['ì†Œê´€ë¶€ì²˜ëª…']}\n"
            f"   - ì‹œí–‰ì¼ì: {law['ì‹œí–‰ì¼ì']} / ê³µí¬ì¼ì: {law['ê³µí¬ì¼ì']}\n"
            f"   - ë§í¬: {law['ë²•ë ¹ìƒì„¸ë§í¬'] or 'ì—†ìŒ'}"
        )
    return "\n\n".join(rows)

# =============================
# ëª¨ë¸ ë©”ì‹œì§€ êµ¬ì„±/ìŠ¤íŠ¸ë¦¬ë°
# =============================
def build_history_messages(max_turns=10):
    """ìµœê·¼ Ní„´ íˆìŠ¤í† ë¦¬ë¥¼ ëª¨ë¸ì— ì „ë‹¬ (ChatGPTì™€ ë™ì¼ ë§¥ë½ ìœ ì§€)."""
    sys = {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ë²•ë ¹ ì •ë³´ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì•ˆë‚´í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."}
    msgs = [sys]
    history = st.session_state.messages[-max_turns*2:]
    for m in history:
        msgs.append({"role": m["role"], "content": m["content"]})
    return msgs

def stream_chat_completion(messages, temperature=0.7, max_tokens=1000):
    stream = client.chat.completions.create(
        model=AZURE["deployment"],
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=True,
    )
    for chunk in stream:
        try:
            if not hasattr(chunk, "choices") or not chunk.choices:
                continue
            c = chunk.choices[0]
            if getattr(c, "finish_reason", None):
                break
            d = getattr(c, "delta", None)
            txt = getattr(d, "content", None) if d else None
            if txt:
                yield txt
        except Exception:
            continue

# =============================
# ì‚¬ì´ë“œë°” (ì˜µì…˜ & ìƒˆë¡œìš´ ëŒ€í™”)
# =============================
with st.sidebar:
    st.markdown("### âš™ï¸ ì˜µì…˜")
    st.session_state.settings["num_rows"] = st.slider("ì°¸ê³  ê²€ìƒ‰ ê°œìˆ˜(ë²•ì œì²˜)", 1, 10, st.session_state.settings["num_rows"])
    st.session_state.settings["include_search"] = st.checkbox("ë²•ì œì²˜ ê²€ìƒ‰ ë§¥ë½ í¬í•¨", value=st.session_state.settings["include_search"])
    st.divider()
    if st.button("ğŸ†• ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘", use_container_width=True):
        st.session_state.messages.clear()
        st.rerun()
    st.divider()
    st.metric("ì´ ë©”ì‹œì§€ ìˆ˜", len(st.session_state.messages))

# =============================
# ê³¼ê±° ëŒ€í™” ë Œë” (ChatGPT ìŠ¤íƒ€ì¼)
# =============================
for i, m in enumerate(st.session_state.messages):
    with st.chat_message(m["role"]):
        if m["role"] == "assistant":
            render_ai_with_copy(m["content"], key=f"past-{i}")
            if m.get("law"):
                with st.expander("ğŸ“‹ ì´ í„´ì—ì„œ ì°¸ê³ í•œ ë²•ë ¹ ìš”ì•½"):
                    for j, law in enumerate(m["law"], 1):
                        st.write(f"**{j}. {law['ë²•ë ¹ëª…']}** ({law['ë²•ë ¹êµ¬ë¶„ëª…']})  | ì‹œí–‰ {law['ì‹œí–‰ì¼ì']}  | ê³µí¬ {law['ê³µí¬ì¼ì']}")
                        if law.get("ë²•ë ¹ìƒì„¸ë§í¬"):
                            st.write(f"- ë§í¬: {law['ë²•ë ¹ìƒì„¸ë§í¬']}")
        else:
            st.markdown(m["content"])

# =============================
# í•˜ë‹¨ ì…ë ¥ì°½ (ê³ ì •, ë‹µë³€ê³¼ ë™ì¼ í­)
# =============================
user_q = st.chat_input("ë²•ë ¹ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”â€¦ (Enterë¡œ ì „ì†¡)")

if user_q:
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œê¸°/ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_q, "ts": ts})
    with st.chat_message("user"):
        st.markdown(user_q)

    # (ì˜µì…˜) ë²•ì œì²˜ ê²€ìƒ‰
    law_data, used_endpoint, err = ([], None, None)
    if st.session_state.settings["include_search"]:
        with st.spinner("ğŸ” ë²•ì œì²˜ì—ì„œ ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ì¤‘..."):
            law_data, used_endpoint, err = search_law_data(user_q, num_rows=st.session_state.settings["num_rows"])
        if used_endpoint:
            st.caption(f"ë²•ì œì²˜ API endpoint: `{used_endpoint}`")
        if err:
            st.warning(err)
    law_ctx = format_law_context(law_data)

    # ëª¨ë¸ íˆìŠ¤í† ë¦¬ + í˜„ì¬ ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸
    model_messages = build_history_messages(max_turns=10)
    model_messages.append({
        "role": "user",
        "content": f"""ì‚¬ìš©ì ì§ˆë¬¸: {user_q}

ê´€ë ¨ ë²•ë ¹ ì •ë³´(ìš”ì•½):
{law_ctx}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
ë²•ë¥ ìë¬¸ì„œ

ì œëª©: ë‚©í’ˆ ì§€ì—°ì— ë”°ë¥¸ ê³„ì•½ í•´ì œ ê°€ëŠ¥ ì—¬ë¶€ì— ê´€í•œ ë²•ë¥  ê²€í† 
ì‘ì„±: ë²•ì œì²˜ ì¸ê³µì§€ëŠ¥ ë²•ë¥  ìƒë‹´ì‚¬
ì‘ì„±ì¼: ì˜¤ëŠ˜ ì¼ìë¥¼ ì¶œë ¥

â… . ìë¬¸ ì˜ë¢°ì˜ ë²”ìœ„
ë³¸ ìë¬¸ì€ ê·€ì‚¬ê°€ ì²´ê²°í•œ ë‚©í’ˆê³„ì•½ì— ê´€í•œ ì±„ë¬´ë¶ˆì´í–‰ ì‚¬ìœ  ë°œìƒ ì‹œ ê³„ì•½ í•´ì œ ê°€ëŠ¥ ì—¬ë¶€ ë° ê·¸ì— ë”°ë¥¸ ë²•ì  íš¨ê³¼ë¥¼ ê²€í† í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.

â…¡. ì‚¬ì‹¤ê´€ê³„
(ì‚¬ì‹¤ê´€ê³„ ìš”ì•½ì€ ë™ì¼í•˜ë˜, ë¬¸ì¥ì„ ì™„ì „í•˜ê²Œ ì‘ì„±í•˜ê³  ì‹œê°„ ìˆœì„œ ë° ë²•ë¥ ì  í‰ê°€ ê°€ëŠ¥í•˜ë„ë¡ ê¸°ìˆ )

â…¢. ê´€ë ¨ ë²•ë ¹ ë° íŒë¡€

1. ë¯¼ë²• ì œ544ì¡°(ì±„ë¬´ë¶ˆì´í–‰ì— ì˜í•œ í•´ì œ)
   > ë‹¹ì‚¬ì ì¼ë°©ì´ ì±„ë¬´ë¥¼ ì´í–‰í•˜ì§€ ì•„ë‹ˆí•œ ë•Œì—ëŠ” ìƒëŒ€ë°©ì€ ìƒë‹¹í•œ ê¸°ê°„ì„ ì •í•˜ì—¬ ì´í–‰ì„ ìµœê³ í•˜ê³ , ê·¸ ê¸°ê°„ ë‚´ì— ì´í–‰ì´ ì—†ëŠ” ë•Œì—ëŠ” ê³„ì•½ì„ í•´ì œí•  ìˆ˜ ìˆë‹¤.
2. ëŒ€ë²•ì› 2005ë‹¤14285 íŒê²°
   > ë§¤ë§¤ê³„ì•½ì— ë”°ë¥¸ ëª©ì ë¬¼ ì¸ë„ ë˜ëŠ” ë‚©í’ˆì´ ê¸°í•œ ë‚´ ì´ë£¨ì–´ì§€ì§€ ì•Šì€ ê²½ìš°, ìƒë‹¹í•œ ê¸°ê°„ì„ ì •í•˜ì—¬ ìµœê³ í•˜ì˜€ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì´í–‰ì´ ì—†ëŠ” ë•Œì—ëŠ” ê³„ì•½ í•´ì œê°€ ê°€ëŠ¥í•¨ì„ íŒì‹œ.

â…£. ë²•ë¥ ì  ë¶„ì„

1. ì±„ë¬´ë¶ˆì´í–‰ ì—¬ë¶€
   ê³„ì•½ìƒ ë‚©í’ˆ ê¸°ì¼(2025. 7. 15.)ì„ ë„ê³¼í•œ ì´í›„ 30ì¼ ì´ìƒ ì§€ì—°ëœ ì‚¬ì‹¤ì€ ì±„ë¬´ë¶ˆì´í–‰ì— í•´ë‹¹í•¨.
   ì§€ì—° ì‚¬ìœ ì¸ â€˜ì›ìì¬ ìˆ˜ê¸‰ ë¶ˆê°€â€™ê°€ ë¶ˆê°€í•­ë ¥ì— í•´ë‹¹í•˜ëŠ”ì§€ ì—¬ë¶€ê°€ ìŸì ì´ë‚˜, ì¼ë°˜ì ì¸ ì›ìì¬ ìˆ˜ê¸‰ ê³¤ë€ì€ ë¶ˆê°€í•­ë ¥ìœ¼ë¡œ ì¸ì •ë˜ì§€ ì•ŠëŠ” íŒë¡€ ê²½í–¥ ì¡´ì¬.

2. ê³„ì•½ í•´ì œ ìš”ê±´ ì¶©ì¡± ì—¬ë¶€
   ìƒë‹¹í•œ ê¸°ê°„(ì˜ˆ: 7ì¼)ì„ ì •í•œ ìµœê³  í›„ì—ë„ ì´í–‰ì´ ì—†ì„ ê²½ìš°, ë¯¼ë²• ì œ544ì¡°ì— ë”°ë¼ ê³„ì•½ í•´ì œê°€ ê°€ëŠ¥í•¨.
   í•´ì œ ì‹œ ê³„ì•½ê¸ˆ ë°˜í™˜ ë° ì†í•´ë°°ìƒ ì²­êµ¬ ê°€ëŠ¥ì„±ì´ ìˆìŒ.

3. ì†í•´ë°°ìƒ ë²”ìœ„
   ê³„ì•½ í•´ì œì™€ ë³„ë„ë¡œ, ê·€ì‚¬ê°€ ì…ì€ ì†í•´(ëŒ€ì²´ êµ¬ë§¤ ë¹„ìš©, ì§€ì—°ìœ¼ë¡œ ì¸í•œ ìƒì‚° ì°¨ì§ˆ ë“±)ê°€ ì…ì¦ë˜ë©´ ì±„ë¬´ë¶ˆì´í–‰ì— ë”°ë¥¸ ì†í•´ë°°ìƒ ì²­êµ¬ ê°€ëŠ¥.

â…¤. ê²°ë¡ 
ê·€ì‚¬ëŠ” ì„œë©´ ìµœê³ ë¥¼ ê±°ì¹œ í›„ ê³„ì•½ í•´ì œ ê¶Œë¦¬ë¥¼ í–‰ì‚¬í•  ìˆ˜ ìˆìœ¼ë©°, ê³„ì•½ê¸ˆ ë°˜í™˜ê³¼ ë³„ë„ë¡œ ì†í•´ë°°ìƒì„ ì²­êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë‹¤ë§Œ, ì†í•´ì•¡ ì‚°ì • ë° ì…ì¦ì„ ìœ„í•´ ë‚©í’ˆ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ë¹„ìš© ìë£Œë¥¼ ì‚¬ì „ì— í™•ë³´í•˜ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.

í•œêµ­ì–´ë¡œ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”."""
    })

    # ì–´ì‹œìŠ¤í„´íŠ¸ ë§í’ì„ (ìŠ¤íŠ¸ë¦¬ë°)
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_text, buffer = "", ""

        if client is None:
            full_text = "Azure OpenAI ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ ì•ˆë‚´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\n" + law_ctx
            placeholder.markdown(full_text)
        else:
            try:
                # íƒ€ì´í•‘ ì¸ë””ì¼€ì´í„°
                placeholder.markdown('<span class="typing-indicator"></span> ë‹µë³€ ìƒì„± ì¤‘...', unsafe_allow_html=True)
                for piece in stream_chat_completion(model_messages, temperature=0.7, max_tokens=1000):
                    buffer += piece
                    if len(buffer) >= 80:  # ê¹œë¹¡ì„ ì™„í™”
                        full_text += buffer; buffer = ""
                        placeholder.markdown(full_text)
                        time.sleep(0.02)
                if buffer:
                    full_text += buffer
                    placeholder.markdown(full_text)
            except Exception as e:
                full_text = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\n\n{law_ctx}"
                placeholder.markdown(full_text)

        # âœ… ë§í’ì„ ì„ ì§€ìš°ì§€ ì•Šê³ , ê·¸ ì•„ë˜ì— ë³µì‚¬ ì¹´ë“œ 'ì¶”ê°€' ë Œë” (ì‚¬ë¼ì§ ë°©ì§€)
        render_ai_with_copy(full_text, key=f"now-{ts}")

    # ëŒ€í™” ì €ì¥(ë²•ë ¹ ìš”ì•½ í¬í•¨)
    st.session_state.messages.append({
        "role": "assistant", "content": full_text,
        "law": law_data if st.session_state.settings["include_search"] else None,
        "ts": ts
    })
