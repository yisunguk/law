# app.py â€” Single-window chat with bottom streaming + robust dedupe + pinned question
from __future__ import annotations

import streamlit as st


# === Shared hero (title + two paragraphs) used in pre-chat and inside chat ===
HERO_HTML = '''
<h1 style="font-size:38px;font-weight:800;letter-spacing:-.5px;margin-bottom:12px;">âš–ï¸ ë²•ë¥ ìƒë‹´ ì±—ë´‡</h1>
<p style="font-size:15px;line-height:1.8;opacity:.92;margin:0 0 6px;">
  ë²•ì œì²˜ êµ­ê°€ë²•ë ¹ì •ë³´ DBë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì‹  ë²•ë ¹ê³¼ í–‰ì •ê·œì¹™, ìì¹˜ë²•ê·œ, ì¡°ì•½, ë²•ë ¹í•´ì„ë¡€, í—Œì¬ê²°ì •ë¡€, ë²•ë ¹ìš©ì–´ë¥¼ ì‹ ë¢°ì„± ìˆê²Œ ì œê³µí•©ë‹ˆë‹¤.
</p>
<p style="font-size:15px;line-height:1.8;opacity:.92;margin:0 0 24px;">
  ë³¸ ì±—ë´‡ì€ ì‹ ì†í•˜ê³  ì •í™•í•œ ë²•ë ¹ ì •ë³´ë¥¼ ì•ˆë‚´í•˜ì—¬, ì‚¬ìš©ìê°€ ë²•ë¥ ì  ìŸì ì„ ì´í•´í•˜ê³  í•©ë¦¬ì ì¸ íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.
</p>
'''

# --- per-turn nonce ledger (prevents double appends)
st.session_state.setdefault('_nonce_done', {})
# --- cache helpers: suggestions shouldn't jitter on reruns ---
def cached_suggest_for_tab(tab_key: str):
    import streamlit as st
    store = st.session_state.setdefault("__tab_suggest__", {})
    if tab_key not in store:
        from modules import suggest_keywords_for_tab
        store[tab_key] = cached_suggest_for_tab(tab_key)
    return store[tab_key]

def cached_suggest_for_law(law_name: str):
    import streamlit as st
    store = st.session_state.setdefault("__law_suggest__", {})
    if law_name not in store:
        from modules import suggest_keywords_for_law
        store[law_name] = cached_suggest_for_law(law_name)
    return store[law_name]

st.set_page_config(
    page_title="ë²•ì œì²˜ ë²•ë¬´ ìƒë‹´ì‚¬",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ìµœìƒë‹¨ ìŠ¤í¬ë¡¤ ê¸°ì¤€ì 
st.markdown('<div id="__top_anchor__"></div>', unsafe_allow_html=True)

st.markdown("""
<style>
:root{
  --center-col: 980px;   /* ì¤‘ì•™ ì „ì²´ í­ */
  --bubble-max: 760px;   /* ë§í’ì„  ìµœëŒ€ í­ */
  --pad-x: 12px;         /* ì¢Œìš° ì—¬ë°± */
}

/* ë³¸ë¬¸(ì±„íŒ… ì „/í›„ ê³µí†µ) ì¤‘ì•™ í­ ê³ ì • */
.block-container{
  max-width: var(--center-col) !important;
  margin-left: auto !important;
  margin-right: auto !important;
  padding-left: var(--pad-x) !important;
  padding-right: var(--pad-x) !important;
}

/* ì—…ë¡œë”/í¼/ì¹´ë“œë¥˜ë„ ê°™ì€ í­ */
.block-container [data-testid="stFileUploader"],
.block-container form,
.block-container .stForm,
.block-container .stMarkdown>div{
  max-width: var(--center-col) !important;
  margin-left: auto !important;
  margin-right: auto !important;
}

/* ì±„íŒ… ë©”ì‹œì§€ í­(ë‹µë³€ í›„) */
[data-testid="stChatMessage"]{
  max-width: var(--bubble-max) !important;
  width: 100% !important;
  margin-left: auto !important;
  margin-right: auto !important;
}
</style>
""", unsafe_allow_html=True)

st.markdown('''
<style>
.hero-in-chat { margin: 8px 0 2px; }
.hero-in-chat h1 { margin-bottom: 10px !important; }
</style>
''' , unsafe_allow_html=True)

st.markdown("""
<style>
:root{
  --left-rail: 300px;
  --right-rail: calc(var(--flyout-width, 0px) + var(--flyout-gap, 0px));
}
</style>
<script>
(function(){
  function setLeftRail(){
    const sb = window.parent.document.querySelector('[data-testid="stSidebar"]');
    if(!sb) return;
    const w = Math.round(sb.getBoundingClientRect().width || 300);
    document.documentElement.style.setProperty('--left-rail', w + 'px');
  }
  setLeftRail();
  window.addEventListener('resize', setLeftRail);
  new MutationObserver(setLeftRail).observe(window.parent.document.body, {subtree:true, childList:true, attributes:true});
})();
</script>
""", unsafe_allow_html=True)


# === [BOOTSTRAP] session keys (must be first) ===
if "messages" not in st.session_state:
    st.session_state.messages = []
if "_last_user_nonce" not in st.session_state:
    st.session_state["_last_user_nonce"] = None


KEY_PREFIX = "main"

from modules import AdviceEngine, Intent, classify_intent, pick_mode, build_sys_for_mode

# ì§€ì—° ì´ˆê¸°í™”: í•„ìš”í•œ ì „ì—­ë“¤ì´ ì¤€ë¹„ëœ ë’¤ì— í•œ ë²ˆë§Œ ì—”ì§„ ìƒì„±
def _init_engine_lazy():
    import streamlit as st
    if "engine" in st.session_state and st.session_state.engine is not None:
        return st.session_state.engine

    g = globals()
    c      = g.get("client")
    az     = g.get("AZURE")
    tools  = g.get("TOOLS")
    scc    = g.get("safe_chat_completion")
    t_one  = g.get("tool_search_one")
    t_multi= g.get("tool_search_multi")
    pre    = g.get("prefetch_law_context")
    summar = g.get("_summarize_laws_for_primer")

    # í•„ìˆ˜ êµ¬ì„±ìš”ì†Œê°€ ì•„ì§ ì¤€ë¹„ ì•ˆ ë˜ì—ˆìœ¼ë©´ Noneì„ ìºì‹œí•˜ê³  ë¦¬í„´
    if not (c and az and tools and scc and t_one and t_multi):
        st.session_state.engine = None
        return None

    st.session_state.engine = AdviceEngine(
        client=c,
        model=az["deployment"],
        tools=tools,
        safe_chat_completion=scc,
        tool_search_one=t_one,
        tool_search_multi=t_multi,
        prefetch_law_context=pre,             # ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
        summarize_laws_for_primer=summar,     # ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
        temperature=0.2,
    )
    return st.session_state.engine

# ê¸°ì¡´ ask_llm_with_toolsë¥¼ ì–‡ì€ ë˜í¼ë¡œ êµì²´
from modules import AdviceEngine, Intent, classify_intent, pick_mode, build_sys_for_mode

def ask_llm_with_tools(
    user_q: str,
    num_rows: int = 5,
    stream: bool = True,
    forced_mode: str | None = None,  # ìœ ì§€í•´ë„ ë¨: ì•„ë˜ì—ì„œ ì§ì ‘ ì²˜ë¦¬
    brief: bool = False,
):
    """
    UI ì§„ì…ì : ì˜ë„â†’ëª¨ë“œ ê²°ì •, ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í•©ì„±, íˆ´ ì‚¬ìš© ì—¬ë¶€ ê²°ì • í›„
    AdviceEngine.generate()ì— ë§ëŠ” ì¸ì(system_prompt, allow_tools)ë¡œ í˜¸ì¶œ.
    """
    engine = _init_engine_lazy() if "_init_engine_lazy" in globals() else globals().get("engine")
    if engine is None:
        yield ("final", "ì—”ì§„ì´ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (client/AZURE/TOOLS í™•ì¸)", [])
        return

    # 1) ëª¨ë“œ ê²°ì •
    det_intent, conf = classify_intent(user_q)
    try:
        valid = {m.value for m in Intent}
        mode = Intent(forced_mode) if forced_mode in valid else pick_mode(det_intent, conf)
    except Exception:
        mode = pick_mode(det_intent, conf)

    # 2) í”„ë¡¬í”„íŠ¸/íˆ´ ì‚¬ìš© ì—¬ë¶€
    use_tools = mode in (Intent.LAWFINDER, Intent.MEMO)
    sys_prompt = build_sys_for_mode(mode, brief=brief)

    # 3) ì—”ì§„ í˜¸ì¶œ (ìƒˆ ì‹œê·¸ë‹ˆì²˜ì— ë§ê²Œ)
    yield from engine.generate(
        user_q,
        system_prompt=sys_prompt,
        allow_tools=use_tools,
        num_rows=num_rows,
        stream=stream,
        primer_enable=True,
    )

import io, os, re, json, time, html

if "_normalize_text" not in globals():
    def _normalize_text(s: str) -> str:
        """ë¶ˆí•„ìš”í•œ ê³µë°±/ë¹ˆ ì¤„ì„ ì •ëˆí•˜ëŠ” ì•ˆì „í•œ ê¸°ë³¸ ë²„ì „"""
        s = (s or "").replace("\r\n", "\n").replace("\r", "\n")
        # ì•ë’¤ ê³µë°± ì •ë¦¬
        s = s.strip()
        # 3ê°œ ì´ìƒ ì—°ì† ê°œí–‰ â†’ 2ê°œë¡œ
        s = re.sub(r"\n{3,}", "\n\n", s)
        # ë¬¸ì¥ ë ê³µë°± ì œê±°
        s = re.sub(r"[ \t]+\n", "\n", s)
        return s

def _esc(s: str) -> str:
    """HTML escape only"""
    return html.escape("" if s is None else str(s))

def _esc_br(s: str) -> str:
    """HTML escape + ì¤„ë°”ê¿ˆì„ <br>ë¡œ"""
    return _esc(s).replace("\n", "<br>")

from datetime import datetime            # _push_user_from_pending, ì €ì¥ ì‹œê° ë“±ì— í•„ìš”
import urllib.parse as up                # normalize_law_link, quote ë“±ì—ì„œ ì‚¬ìš©
import xml.etree.ElementTree as ET       # _call_moleg_list() XML íŒŒì‹±ì— í•„ìš”
from urllib.parse import quote
import requests
import streamlit.components.v1 as components
from openai import AzureOpenAI
from llm_safety import safe_chat_completion

# TLS 1.2 ê°•ì œìš© ì–´ëŒ‘í„° ì •ì˜
from requests.adapters import HTTPAdapter
from urllib3.util.ssl_ import create_urllib3_context
class TLS12HttpAdapter(HTTPAdapter):
    """TLS1.2 only adapter for requests"""
    def init_poolmanager(self, *args, **kwargs):
        context = create_urllib3_context()
        context.set_ciphers('HIGH:!aNULL:!eNULL:!SSLv2:!SSLv3')
        kwargs['ssl_context'] = context
        return super().init_poolmanager(*args, **kwargs)

from chatbar import chatbar
# (ì²¨ë¶€ íŒŒì‹±ì€ ë‚˜ì¤‘ í™•ì¥ìš©ìœ¼ë¡œ import ìœ ì§€)
from utils_extract import extract_text_from_pdf, extract_text_from_docx, read_txt, sanitize
from external_content import is_url, make_url_context
from external_content import extract_first_url
from typing import Iterable, List

import hashlib


# --- Utilities: de-duplicate repeated paragraphs/halves ---
def _dedupe_repeats(txt: str) -> str:
    if not txt:
        return txt
    n = len(txt)
    # Heuristic 1: if halves overlap (common duplication pattern)
    if n > 600:
        half = n // 2
        a, b = txt[:half].strip(), txt[half:].strip()
        if a and b and (a == b or a.startswith(b[:200]) or b.startswith(a[:200])):
            return a if len(a) >= len(b) else b
    # Heuristic 2: paragraph-level dedupe while preserving order
    parts = re.split(r"\n\s*\n", txt)
    seen = set()
    out_parts = []
    for p in parts:
        key = p.strip()
        norm = re.sub(r"\s+", " ", key).strip().lower()
        if norm and norm in seen:
            continue
        if norm:
            seen.add(norm)
        out_parts.append(p)
    return "\n\n".join(out_parts)


def _hash_text(s: str) -> str:
    return hashlib.md5((s or "").encode("utf-8")).hexdigest()


# í–‰ì •ê·œì¹™ ì†Œê´€ ë¶€ì²˜ ë“œë¡­ë‹¤ìš´ ì˜µì…˜
MINISTRIES = [
    "ë¶€ì²˜ ì„ íƒ(ì„ íƒ)",
    "êµ­ë¬´ì¡°ì •ì‹¤", "ê¸°íšì¬ì •ë¶€", "êµìœ¡ë¶€", "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€",
    "ì™¸êµë¶€", "í†µì¼ë¶€", "ë²•ë¬´ë¶€", "í–‰ì •ì•ˆì „ë¶€", "ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€",
    "ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€", "ì‚°ì—…í†µìƒìì›ë¶€", "ë³´ê±´ë³µì§€ë¶€", "í™˜ê²½ë¶€",
    "ê³ ìš©ë…¸ë™ë¶€", "ì—¬ì„±ê°€ì¡±ë¶€", "êµ­í† êµí†µë¶€", "í•´ì–‘ìˆ˜ì‚°ë¶€",
    "ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€", "ê¸ˆìœµìœ„ì›íšŒ", "ë°©ì†¡í†µì‹ ìœ„ì›íšŒ", "ê³µì •ê±°ë˜ìœ„ì›íšŒ",
    "êµ­ê°€ë³´í›ˆë¶€", "ì¸ì‚¬í˜ì‹ ì²˜", "ì›ìë ¥ì•ˆì „ìœ„ì›íšŒ", "ì§ˆë³‘ê´€ë¦¬ì²­",
]
# === UI/ë™ì‘ ì˜µì…˜ ===
SHOW_SEARCH_DEBUG = False     # â† í†µí•© ê²€ìƒ‰ íŒ¨ë„ì˜ ë””ë²„ê·¸(ì‹œë„/LLM plans/ì—ëŸ¬) ê°ì¶”ê¸°

SHOW_STREAM_PREVIEW = False  # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ê°„ ë¯¸ë¦¬ë³´ê¸° ë„ê¸°

# ==============================
# ì¶”ì²œ í‚¤ì›Œë“œ (íƒ­ë³„) + í—¬í¼
# ==============================

# ë²•ë ¹ëª… ê¸°ë°˜ ì¶”ì²œ(ë²•ë ¹ íƒ­ ì „ìš©)
SUGGESTED_LAW_KEYWORDS = {
    "ë¯¼ë²•": ["ì œ839ì¡°", "ì¬ì‚°ë¶„í• ", "ì´í˜¼", "ì œ840ì¡°", "ì¹œê¶Œ"],
    "í˜•ë²•": ["ì œ307ì¡°", "ëª…ì˜ˆí›¼ì†", "ì‚¬ê¸°", "í­í–‰", "ìƒí•´"],
    "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•": ["ë³´ì¦ê¸ˆ", "ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹", "ëŒ€í•­ë ¥", "ìš°ì„ ë³€ì œê¶Œ"],
    "ìƒê°€ê±´ë¬¼ ì„ëŒ€ì°¨ë³´í˜¸ë²•": ["ë³´ì¦ê¸ˆ", "ê¶Œë¦¬ê¸ˆ", "ê°±ì‹ ìš”êµ¬ê¶Œ", "ëŒ€í•­ë ¥"],
    "ê·¼ë¡œê¸°ì¤€ë²•": ["í•´ê³ ", "ì—°ì°¨", "í‡´ì§ê¸ˆ", "ì„ê¸ˆì²´ë¶ˆ"],
    "ê°œì¸ì •ë³´ ë³´í˜¸ë²•": ["ìˆ˜ì§‘ì´ìš©", "ì œ3ìì œê³µ", "ìœ ì¶œí†µì§€", "ê³¼ì§•ê¸ˆ"],
}
FALLBACK_LAW_KEYWORDS = ["ì •ì˜", "ëª©ì ", "ë²Œì¹™"]

def cached_suggest_for_law(law_name: str) -> list[str]:
    if not law_name:
        return FALLBACK_LAW_KEYWORDS
    if law_name in SUGGESTED_LAW_KEYWORDS:
        return SUGGESTED_LAW_KEYWORDS[law_name]
    for k in SUGGESTED_LAW_KEYWORDS:
        if k in law_name:
            return SUGGESTED_LAW_KEYWORDS[k]
    return FALLBACK_LAW_KEYWORDS

# íƒ­ë³„ ê¸°ë³¸ ì¶”ì²œ(í–‰ì •ê·œì¹™/ìì¹˜ë²•ê·œ/ì¡°ì•½/íŒë¡€/í—Œì¬/í•´ì„ë¡€)
SUGGESTED_TAB_KEYWORDS = {
    "admrul": ["ê³ ì‹œ", "í›ˆë ¹", "ì˜ˆê·œ", "ì§€ì¹¨", "ê°œì •"],
    "ordin":  ["ì¡°ë¡€", "ê·œì¹™", "ê·œì •", "ì‹œí–‰", "ê°œì •"],
    "trty":   ["ë¹„ì¤€", "ë°œíš¨", "ì–‘ì", "ë‹¤ì", "í˜‘ì •"],
    # íŒë¡€/í—Œì¬ëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ìš© ë³´ì¡°(ì •í™• ë§í¬ëŠ” ì‚¬ê±´ë²ˆí˜¸Â·ì‚¬ê±´í‘œì‹œê°€ ë” ì í•©)
    "prec":   ["ì†í•´ë°°ìƒ", "ëŒ€ì—¬ê¸ˆ", "ì‚¬ê¸°", "ì´í˜¼", "ê·¼ë¡œ"],
    "cc":     ["ìœ„í—Œ", "í•©í—Œ", "ê°í•˜", "ì¹¨í•´", "ê¸°ê°"],
    "expc":   ["ìœ ê¶Œí•´ì„", "ì§ˆì˜íšŒì‹ ", "ë²•ë ¹í•´ì„", "ì ìš©ë²”ìœ„"],
}
def cached_suggest_for_tab(tab_kind: str) -> list[str]:
    return SUGGESTED_TAB_KEYWORDS.get(tab_kind, [])

def inject_sticky_layout_css(mode: str = "wide"):
    PRESETS = {
        "wide":   {"center": "1160px", "bubble_max": "760px"},
        "narrow": {"center": "880px",  "bubble_max": "640px"},
    }
    p = PRESETS.get(mode, PRESETS["wide"])

    # ì „ì—­ CSS ë³€ìˆ˜(í•œ êµ°ë°ì—ì„œë§Œ ì„ ì–¸)
    root_vars = (
        ":root {"
        " --center-col: 1160px;"
        " --bubble-max: 760px;"
        " --chatbar-h: 56px;"
        " --chat-gap: 12px;"
        " --rail: 460px;"
        " --hgap: 24px;"
        "}"
    )

    css = f"""
    <style>
      {root_vars}

      /* ë³¸ë¬¸/ì…ë ¥ì°½ ê³µí†µ ì¤‘ì•™ ì •ë ¬ & ë™ì¼ í­ */
      .block-container, .stChatInput {{
        max-width: var(--center-col) !important;
        margin-left: auto !important;
        margin-right: auto !important;
      }}

      /* ì±„íŒ… ë§í’ì„  ìµœëŒ€ í­ */
      [data-testid="stChatMessage"] {{
        max-width: var(--bubble-max) !important;
        width: 100% !important;
      }}
      [data-testid="stChatMessage"] .stMarkdown,
      [data-testid="stChatMessage"] .stMarkdown > div {{
        width: 100% !important;
      }}

      /* ëŒ€í™” ì „ ì¤‘ì•™ íˆì–´ë¡œ */
      .center-hero {{
        min-height: calc(100vh - 220px);
        display: flex; flex-direction: column; align-items: center; justify-content: center;
      }}
      .center-hero .stFileUploader, .center-hero .stTextInput {{
        width: 720px; max-width: 92vw;
      }}

.post-chat-ui .stFileUploader, .post-chat-ui .stTextInput {{ width: 720px; max-width: 92vw; }}
.post-chat-ui {{ margin-top: 8px; }}


      /* ì—…ë¡œë” ê³ ì •: ì•µì»¤ ë‹¤ìŒ í˜•ì œ ì—…ë¡œë” */
      #bu-anchor + div[data-testid='stFileUploader'] {{
        position: fixed;
        left: 50%; transform: translateX(-50%);
        bottom: calc(var(--chatbar-h) + var(--chat-gap) + 12px);
        width: clamp(340px, calc(var(--center-col) - 2*var(--hgap)), calc(100vw - var(--rail) - 2*var(--hgap)));
        max-width: calc(100vw - var(--rail) - 2*var(--hgap));
        z-index: 60;
        background: rgba(0,0,0,0.35);
        padding: 10px 12px; border-radius: 12px;
        backdrop-filter: blur(6px);
      }}
      #bu-anchor + div [data-testid='stFileUploader'] {{
        background: transparent !important; border: none !important;
      }}

      /* ì…ë ¥ì°½ í•˜ë‹¨ ê³ ì • */
      section[data-testid="stChatInput"] {{
        position: fixed; left: 50%; transform: translateX(-50%);
        bottom: 0; z-index: 70;
        width: clamp(340px, calc(var(--center-col) - 2*var(--hgap)), calc(100vw - var(--rail) - 2*var(--hgap)));
        max-width: calc(100vw - var(--rail) - 2*var(--hgap));
      }}

      /* ë³¸ë¬¸ì´ í•˜ë‹¨ ê³ ì • UIì™€ ê²¹ì¹˜ì§€ ì•Šê²Œ */
      .block-container {{
        padding-bottom: calc(var(--chatbar-h) + var(--chat-gap) + 130px) !important;
      }}

      
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

# í˜¸ì¶œ ìœ„ì¹˜: íŒŒì¼ ë§¨ ì•„ë˜, ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ê·¸ë¦° ë’¤
inject_sticky_layout_css("wide")

# ----- FINAL OVERRIDE: ìš°ì¸¡ í†µí•©ê²€ìƒ‰ íŒ¨ë„ ê°„ê²©/ìœ„ì¹˜ í™•ì • -----

# --- Right flyout: ìƒë‹¨ ê³ ì • + í•˜ë‹¨(ì±„íŒ…ì°½)ê³¼ ê²¹ì¹˜ì§€ ì•Šê²Œ ---
# --- Right flyout: í•˜ë‹¨ ë‹µë³€ì°½(ì…ë ¥ì°½) ìœ„ì— ë§ì¶° ê³ ì • ---
import streamlit as st
st.markdown("""
<style>
  :root{
    /* ìˆ«ìë§Œ ë°”ê¾¸ë©´ ë¯¸ì„¸ì¡°ì • ë©ë‹ˆë‹¤ */
    --flyout-width: 360px;     /* ìš°ì¸¡ íŒ¨ë„ í­ */
    --flyout-gap:   80px;      /* ë³¸ë¬¸ê³¼ íŒ¨ë„ ì‚¬ì´ ê°€ë¡œ ê°„ê²© */
    --chatbar-h:    56px;      /* í•˜ë‹¨ ì…ë ¥ì°½ ë†’ì´ */
    --chat-gap:     12px;      /* ì…ë ¥ì°½ ìœ„ ì—¬ë°± */
    /* íŒ¨ë„ í•˜ë‹¨ì´ ë©ˆì¶œ ìœ„ì¹˜(= ì…ë ¥ì°½ ë°”ë¡œ ìœ„) */
    --flyout-bottom: calc(var(--chatbar-h) + var(--chat-gap) + 16px);
  }

  @media (min-width:1280px){
    /* ë³¸ë¬¸ì´ íŒ¨ë„ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ìš°ì¸¡ ì—¬ë°± í™•ë³´ */
    .block-container{
      padding-right: calc(var(--flyout-width) + var(--flyout-gap)) !important;
    }

    /* íŒ¨ë„: í™”ë©´ í•˜ë‹¨ ê¸°ì¤€ìœ¼ë¡œ â€˜ì…ë ¥ì°½ ìœ„â€™ì— ë”± ë¶™ì´ê¸° */
    #search-flyout{
      position: fixed !important;
      bottom: var(--flyout-bottom) !important;  /* â¬… í•µì‹¬: ë‹µë³€ì°½ ìœ„ì— ì •ë ¬ */
      top: auto !important;                     /* ê¸°ì¡´ top ê·œì¹™ ë¬´ë ¥í™” */
      right: 24px !important; left: auto !important;

      width: var(--flyout-width) !important;
      max-width: 38vw !important;

      /* íŒ¨ë„ ë‚´ë¶€ë§Œ ìŠ¤í¬ë¡¤ë˜ê²Œ ìµœëŒ€ ë†’ì´ ì œí•œ */
      max-height: calc(100vh - var(--flyout-bottom) - 24px) !important;
      overflow: auto !important;

      z-index: 58 !important; /* ì…ë ¥ì°½(ë³´í†µ z=70)ë³´ë‹¤ ë‚®ê²Œ */
    }
  }

  /* ëª¨ë°”ì¼/ì¢ì€ í™”ë©´ì€ ìì—° íë¦„ */
  @media (max-width:1279px){
    #search-flyout{ position: static !important; max-height:none !important; overflow:visible !important; }
    .block-container{ padding-right: 0 !important; }
  }
</style>
""", unsafe_allow_html=True)



# --- ê°„ë‹¨ í† í°í™”/ì •ê·œí™”(ì´ë¯¸ ì“°ê³  ìˆë˜ ê²ƒê³¼ í˜¸í™˜) ---
# === Tokenize & Canonicalize (ìœ í‹¸ ìµœìƒë‹¨ì— ë°°ì¹˜) ===
import re
from typing import Iterable, List

TOKEN_RE = re.compile(r"[ê°€-í£A-Za-z0-9]{2,}")

def _tok(s: str) -> List[str]:
    """í•œê¸€/ì˜ë¬¸/ìˆ«ì 2ì ì´ìƒ í† í°ë§Œ ì¶”ì¶œ"""
    return TOKEN_RE.findall(s or "")

_CANON = {
    # ìì£¼ ë‚˜ì˜¤ëŠ” ì¶•ì•½/ë™ì˜ì–´ë§Œ ìµœì†Œí™” (í•„ìš” ì‹œ í™•ì¥)
    "ì†ë°°": "ì†í•´ë°°ìƒ",
    "ì°¨ëŸ‰": "ìë™ì°¨",
    "êµíŠ¹ë²•": "êµí†µì‚¬ê³ ì²˜ë¦¬",
}

def _canonize(tokens: Iterable[str]) -> List[str]:
    """í† í°ì„ í‘œì¤€í˜•ìœ¼ë¡œ ì¹˜í™˜"""
    return [_CANON.get(t, t) for t in tokens]


# --- ë ˆë²¤ìŠˆíƒ€ì¸: 1ê¸€ì ì´ë‚´ ì˜¤íƒˆì êµì •ìš©(ê°€ë²¼ìš´ êµ¬í˜„) ---
def _lev1(a: str, b: str) -> int:
    # ê±°ë¦¬ 0/1/2ë§Œ ë¹ ë¥´ê²Œ íŒë³„
    if a == b: return 0
    if abs(len(a) - len(b)) > 1: return 2
    # ê°™ì€ ê¸¸ì´: ì¹˜í™˜ 1íšŒ ì´ë‚´ ê²€ì‚¬
    if len(a) == len(b):
        diff = sum(1 for x, y in zip(a, b) if x != y)
        return 1 if diff == 1 else 2
    # í•˜ë‚˜ ê¸¸ì´ ì°¨: ì‚½ì…/ì‚­ì œ 1íšŒ ì´ë‚´ ê²€ì‚¬
    if len(a) > len(b): a, b = b, a
    i = j = edits = 0
    while i < len(a) and j < len(b):
        if a[i] == b[j]:
            i += 1; j += 1
        else:
            edits += 1; j += 1
            if edits > 1: return 2
    return 1 if edits <= 1 else 2

def _closest_token_1edit(t: str, U: set[str]) -> str | None:
    best = None; best_d = 2
    for u in U:
        d = _lev1(t, u)
        if d < best_d:
            best, best_d = u, d
            if best_d == 0: break
    return best if best_d <= 1 else None

def _sanitize_plan_q(user_q: str, q: str) -> str:
    """
    í”Œëœ q ì•ˆì˜ í† í° ì¤‘ ì‚¬ìš©ì ì§ˆë¬¸ì— ì—†ëŠ” í† í°ì„
    'í•œ ê¸€ì ì´ë‚´'ë¡œ ê°€ê¹Œìš´ ì‚¬ìš©ì í† í°ìœ¼ë¡œ êµì²´(ì˜ˆ: ì£¼ì°¨ì â†’ ì£¼ì°¨ì¥).
    """
    U = set(_canonize(_tok(user_q)))
    T = _canonize(_tok(q))
    repl = {}
    for t in T:
        if t not in U and len(t) >= 2:
            cand = _closest_token_1edit(t, U)
            if cand:
                repl[t] = cand
    # í•œêµ­ì–´ëŠ” \b ê²½ê³„ê°€ ì•½í•˜ë¯€ë¡œ ë‹¨ìˆœ ì¹˜í™˜(ë¶€ë¶„ì¹˜í™˜ ìœ„í—˜ ë‚®ìŒ)
    for a, b in repl.items():
        q = q.replace(a, b)
    return q

# ---- ì˜¤ë¥¸ìª½ í”Œë¡œíŒ… íŒ¨ë„ ë Œë”ëŸ¬ ----
def render_search_flyout(user_q: str, num_rows: int = 8, hint_laws: list[str] | None = None, show_debug: bool = False):
    results = find_all_law_data(user_q, num_rows=num_rows, hint_laws=hint_laws)

    def _pick(*cands):
        for c in cands:
            if isinstance(c, str) and c.strip():
                return c.strip()
        return ""

    def _build_law_link(it, eff):
        link = _pick(it.get("url"), it.get("link"), it.get("detail_url"), it.get("ìƒì„¸ë§í¬"))
        if link: return link
        mst = _pick(it.get("MST"), it.get("mst"), it.get("LawMST"))
        if mst:
            return f"https://www.law.go.kr/DRF/lawService.do?OC=sapphire_5&target=law&MST={mst}&type=HTML&efYd={eff}"
        return ""

    def _law_item_li(it):
        title = _pick(it.get("ë²•ë ¹ëª…í•œê¸€"), it.get("ë²•ë ¹ëª…"), it.get("title_kr"), it.get("title"), it.get("name_ko"), it.get("name"))
        dept  = _pick(it.get("ì†Œê´€ë¶€ì²˜"), it.get("ë¶€ì²˜ëª…"), it.get("dept"), it.get("department"))
        eff   = _pick(it.get("ì‹œí–‰ì¼ì"), it.get("eff"), it.get("effective_date"))
        pub   = _pick(it.get("ê³µí¬ì¼ì"), it.get("pub"), it.get("promulgation_date"))
        link  = _build_law_link(it, eff)

        parts = [f'<span class="title">{title or "(ì œëª© ì—†ìŒ)"} </span>']
        meta  = []
        if dept: meta.append(f"ì†Œê´€ë¶€ì²˜: {dept}")
        if eff or pub: meta.append(f"ì‹œí–‰ì¼ì: {eff} / ê³µí¬ì¼ì: {pub}")
        if meta: parts.append(f'<div class="meta">{" / ".join(meta)}</div>')
        if link: parts.append(f'<a href="{link}" target="_blank" rel="noreferrer">ë²•ë ¹ ìƒì„¸ë³´ê¸°</a>')
        return "<li>" + "\n".join(parts) + "</li>"

    # í—¤ë”
    html = ['<div id="search-flyout">', '<h3>ğŸ“š í†µí•© ê²€ìƒ‰ ê²°ê³¼</h3>', '<details open><summary>ì—´ê¸°/ì ‘ê¸°</summary>']

    # ë²„í‚· ë Œë”
    for label in ["ë²•ë ¹", "í–‰ì •ê·œì¹™", "ìì¹˜ë²•ê·œ", "ì¡°ì•½"]:
        pack  = results.get(label) or {}
        items = pack.get("items") or []
        html.append(f'<h4>ğŸ” {label}</h4>')
        if not items:
            html.append('<p>ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ</p>')
        else:
            html.append('<ol class="law-list">')
            html += [_law_item_li(it) for it in items]
            html.append('</ol>')

        if show_debug:
            tried = (pack.get("debug") or {}).get("tried") or []
            plans = (pack.get("debug") or {}).get("plans") or []
            err   = pack.get("error")
            dbg = []
            if tried: dbg.append("ì‹œë„: " + " | ".join(tried))
            if plans: dbg.append("LLM plans: " + " | ".join([f"{p.get('target')}:{p.get('q')}" for p in plans]))
            if err:   dbg.append("ì˜¤ë¥˜: " + err)
            if dbg:   html.append("<small class='debug'>" + "<br/>".join(dbg) + "</small>")

    html.append("</details></div>")
    st.markdown("\n".join(html), unsafe_allow_html=True)

  # â¬‡ï¸ ì´ ë¸”ë¡ë§Œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš” (ê¸°ì¡´ header st.markdown(...) ë¸”ë¡ì€ ì‚­ì œ)
# app.py (í•˜ë‹¨)

# =========================================
# ì„¸ì…˜ì— ì„ì‹œë¡œ ë‹´ì•„ ë‘” ì²« ì§ˆë¬¸ì„ messagesë¡œ ì˜®ê¸°ëŠ” ìœ í‹¸
# (ì´ ë¸”ë¡ì„ íŒŒì¼ ìƒë‹¨ â€˜ë ˆì´ì•„ì›ƒ/ìŠ¤íƒ€ì¼ ì£¼ì…â€™ ì§í›„ ì •ë„ë¡œ ì˜¬ë ¤ë‘¡ë‹ˆë‹¤)
# =========================================
from datetime import datetime

has_chat = bool(st.session_state.get("messages")) or bool(st.session_state.get("_pending_user_q"))


# âœ… ì¤‘ìš”: â€˜ìµœì´ˆ í™”ë©´â€™ ë Œë”ë§ ì „ì— ë¨¼ì € í˜¸ì¶œ

from datetime import datetime
import time
import streamlit as st

def _push_user_from_pending() -> str | None:
    """í¼ì—ì„œ ë„£ì–´ë‘” _pending_user_që¥¼ ë©”ì‹œì§€ë¡œ ì˜®ê¹€ (ì¤‘ë³µ ë°©ì§€ í¬í•¨)"""
    q = st.session_state.pop("_pending_user_q", None)
    nonce = st.session_state.pop("_pending_user_nonce", None)
    if not q:
        return None
    if nonce and st.session_state.get("_last_user_nonce") == nonce:
        return None

    # === ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬: ì—…ë¡œë“œëœ íŒŒì¼ í…ìŠ¤íŠ¸ë¥¼ ì§ˆë¬¸ ë’¤ì— ë¶€ì°© ===
    try:
        att_payload = st.session_state.pop("_pending_user_files", None)
    except Exception:
        att_payload = None

    # ìš°ì„ ìˆœìœ„: ëª…ì‹œ payload > í¬ìŠ¤íŠ¸-ì±— ì—…ë¡œë” > í”„ë¦¬ì±— ì—…ë¡œë” > í•˜ë‹¨ ì—…ë¡œë”
    files_to_read = []
    try:
        if att_payload:
            for it in att_payload:
                name = it.get("name") or "uploaded"
                data = it.get("data", b"")
                mime = it.get("type") or ""
                files_to_read.append(("__bytes__", name, data, mime))
    except Exception:
        pass
    # ìŠ¤íŠ¸ë¦¼ë¦¿ ì—…ë¡œë”ì—ì„œ ì§ì ‘ ì½ê¸° (fallback)
    for key in ("post_files", "first_files", "bottom_files"):
        try:
            for f in (st.session_state.get(key) or []):
                files_to_read.append(("__widget__", getattr(f, "name", "uploaded"), f, getattr(f, "type", "")))
        except Exception:
            pass

    def _try_extract(name, src, mime):
        txt = ""
        try:
            # utils_extract ì‚¬ìš© ìš°ì„ 
            if name.lower().endswith(".pdf"):
                try:
                    txt = extract_text_from_pdf(src)
                except Exception:
                    import io
                    try:
                        data = src if isinstance(src, (bytes, bytearray)) else src.read()
                        txt = extract_text_from_pdf(io.BytesIO(data))
                    except Exception:
                        txt = ""
            elif name.lower().endswith(".docx"):
                try:
                    txt = extract_text_from_docx(src)
                except Exception:
                    import io
                    try:
                        data = src if isinstance(src, (bytes, bytearray)) else src.read()
                        txt = extract_text_from_docx(io.BytesIO(data))
                    except Exception:
                        txt = ""
            elif name.lower().endswith(".txt"):
                try:
                    if hasattr(src, "read"):
                        data = src.read()
                        try: src.seek(0)
                        except Exception: pass
                    else:
                        data = src if isinstance(src, (bytes, bytearray)) else b""
                    txt = read_txt(data)
                except Exception:
                    try:
                        txt = data.decode("utf-8", errors="ignore")
                    except Exception:
                        txt = ""
        except Exception:
            txt = ""
        return sanitize(txt) if "sanitize" in globals() else txt

    ATTACH_LIMIT_PER_FILE = 6000   # chars
    ATTACH_TOTAL_LIMIT    = 16000  # chars

    pieces = []
    total = 0
    for kind, name, src, mime in files_to_read[:6]:
        try:
            t = _try_extract(name, src if kind=="__widget__" else src, mime) or ""
        except Exception:
            t = ""
        if not t:
            continue
        t = t.strip()
        if not t:
            continue
        t = t[:ATTACH_LIMIT_PER_FILE]
        if total + len(t) > ATTACH_TOTAL_LIMIT:
            t = t[: max(0, ATTACH_TOTAL_LIMIT - total) ]
        if not t:
            break
        pieces.append(f"### {name}\\n{t}")
        total += len(t)
        if total >= ATTACH_TOTAL_LIMIT:
            break

    attach_block = "\\n\\n".join(pieces) if pieces else ""

    # === ìµœì¢… ì½˜í…ì¸  í•©ì„± ===
    content_final = q.strip()
    if attach_block:
        content_final += "\\n\\n[ì²¨ë¶€ ë¬¸ì„œ ë°œì·Œ]\\n" + attach_block + "\\n"
    else:
        content_final = q.strip()
    st.session_state.messages.append({
        "role": "user",
        "content": q.strip(),
        "ts": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    })
    st.session_state["_last_user_nonce"] = nonce
    st.session_state["current_turn_nonce"] = nonce  # âœ… ì´ í„´ì˜ nonce í™•ì •
    # reset duplicate-answer guard for a NEW user turn
    st.session_state.pop('_last_ans_hash', None)

    return q

def render_pre_chat_center():
    """ëŒ€í™” ì „: ì¤‘ì•™ íˆì–´ë¡œ + ì¤‘ì•™ ì—…ë¡œë”(í‚¤: first_files) + ì „ì†¡ í¼"""
    st.markdown('<section class="center-hero">', unsafe_allow_html=True)
    st.markdown(HERO_HTML, unsafe_allow_html=True)

    # ì¤‘ì•™ ì—…ë¡œë” (ëŒ€í™” ì „ ì „ìš©)
    st.file_uploader(
        "Drag and drop files here",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="first_files",
    )

    # ì…ë ¥ í¼ (ì „ì†¡ ì‹œ pendingì— ì €ì¥ í›„ rerun)
    with st.form("first_ask", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”...", key="first_input")
        sent = st.form_submit_button("ì „ì†¡", use_container_width=True)

    st.markdown("</section>", unsafe_allow_html=True)

    if sent and (q or "").strip():
        st.session_state["_pending_user_q"] = q.strip()
        st.session_state["_pending_user_nonce"] = time.time_ns()
        st.rerun()

# ê¸°ì¡´ render_bottom_uploader() ì „ë¶€ êµì²´

# [ADD] ë‹µë³€ ì™„ë£Œ í›„ì—ë„ í”„ë¦¬ì±—ê³¼ ë™ì¼í•œ UI ì‚¬ìš©
def render_post_chat_simple_ui():
    import time, io
    st.markdown('<section class="post-chat-ui">', unsafe_allow_html=True)

    # ì—…ë¡œë” (í”„ë¦¬ì±—ê³¼ ë™ì¼)
    post_files = st.file_uploader(
        "Drag and drop files here",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="post_files",
    )

    # í…ìŠ¤íŠ¸ ì…ë ¥ + ì „ì†¡ ë²„íŠ¼ (í”„ë¦¬ì±—ê³¼ ë™ì¼)
    with st.form("next_ask", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”...", key="next_input")
        sent = st.form_submit_button("ì „ì†¡", use_container_width=True)

    st.markdown("</section>", unsafe_allow_html=True)

    if sent and (q or "").strip():
        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì„¸ì…˜ì— ë³´ê´€ (ë°”ë¡œ reruní•  ê²ƒì´ë¯€ë¡œ ë°”ì´íŠ¸ë¡œ ì €ì¥)
        safe_payload = []
        try:
            for f in (post_files or []):
                try:
                    data = f.read()
                    f.seek(0)
                except Exception:
                    data = None
                safe_payload.append({
                    "name": getattr(f, "name", "uploaded"),
                    "type": getattr(f, "type", ""),
                    "data": data,
                })
        except Exception:
            pass
        st.session_state["_pending_user_q"] = (q or "").strip()
        st.session_state["_pending_user_nonce"] = time.time_ns()
        st.session_state["_pending_user_files"] = safe_payload
        st.rerun()
def render_bottom_uploader():
    # ì—…ë¡œë” ë°”ë¡œ ì•ì— 'ì•µì»¤'ë§Œ ì¶œë ¥
    st.markdown('<div id="bu-anchor"></div>', unsafe_allow_html=True)

    # ì´ ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ì—…ë¡œë”ë¥¼ CSSì—ì„œ #bu-anchor + div[...] ë¡œ ê³ ì • ë°°ì¹˜
    st.file_uploader(
        "Drag and drop files here",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="bottom_files",
        help="ëŒ€í™” ì¤‘ì—ëŠ” ì—…ë¡œë“œ ë°•ìŠ¤ê°€ í•˜ë‹¨ì— ê³ ì •ë©ë‹ˆë‹¤.",
    )

# --- ì‘ë™ í‚¤ì›Œë“œ ëª©ë¡(í•„ìš”ì‹œ ë³´ê°•/ìˆ˜ì •) ---
LINKGEN_KEYWORDS = {
    "ë²•ë ¹": ["ì œì •", "ì „ë¶€ê°œì •", "ê°œì •", "íì§€", "ë¶€ì¹™", "ì •ì •", "ì‹œí–‰", "ë³„í‘œ", "ë³„ì§€ì„œì‹"],
    "í–‰ì •ê·œì¹™": ["í›ˆë ¹", "ì˜ˆê·œ", "ê³ ì‹œ", "ì§€ì¹¨", "ê³µê³ ", "ì „ë¶€ê°œì •", "ê°œì •", "ì •ì •", "íì§€"],
    "ìì¹˜ë²•ê·œ": ["ì¡°ë¡€", "ê·œì¹™", "í›ˆë ¹", "ì˜ˆê·œ", "ì „ë¶€ê°œì •", "ê°œì •", "ì •ì •", "íì§€"],
    "ì¡°ì•½": ["ì„œëª…", "ë¹„ì¤€", "ë°œíš¨", "ê³µí¬", "íê¸°"],
    "íŒë¡€": ["ëŒ€ë²•ì›", "ì „ì›í•©ì˜ì²´", "í•˜ê¸‰ì‹¬", "ì†í•´ë°°ìƒ", "ë¶ˆë²•í–‰ìœ„"],
    "í—Œì¬": ["ìœ„í—Œ", "í•©í—Œ", "í•œì •ìœ„í—Œ", "í•œì •í•©í—Œ", "í—Œë²•ë¶ˆí•©ì¹˜"],
    "í•´ì„ë¡€": ["ìœ ê¶Œí•´ì„", "ë²•ë ¹í•´ì„", "ì§ˆì˜íšŒì‹ "],
    "ìš©ì–´/ë³„í‘œ": ["ìš©ì–´", "ì •ì˜", "ë³„í‘œ", "ì„œì‹"],
}

# --- í‚¤ì›Œë“œ ìœ„ì ¯ í—¬í¼: st_tagsê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ multiselectë¡œ ëŒ€ì²´ ---
try:
    from streamlit_tags import st_tags
    def kw_input(label, options, key):
        return st_tags(
            label=label,
            text="ì‰¼í‘œ(,) ë˜ëŠ” Enterë¡œ ì¶”ê°€/ì‚­ì œ",
            value=options,           # âœ… ê¸°ë³¸ê°’: ì „ë¶€ ì±„ì›€
            suggestions=options,
            maxtags=len(options),
            key=key,
        )
except Exception:
    def kw_input(label, options, key):
        return st.multiselect(
            label, options=options, default=options,  # âœ… ê¸°ë³¸ê°’: ì „ë¶€ ì„ íƒ
            key=key, help="í•„ìš” ì—†ëŠ” í‚¤ì›Œë“œëŠ” ì„ íƒ í•´ì œí•˜ì„¸ìš”."
        )



# =============================
# Utilities
# =============================
_CASE_NO_RE = re.compile(r'(19|20)\d{2}[ê°€-í£]{1,3}\d{1,6}')
_HBASE = "https://www.law.go.kr"
LAW_PORTAL_BASE = "https://www.law.go.kr/"

def _chat_started() -> bool:
    msgs = st.session_state.get("messages", [])
    # ì‹¤ì œ ì‚¬ìš©ì ë©”ì‹œì§€ê°€ í•˜ë‚˜ë¼ë„ ìˆì–´ì•¼ 'ëŒ€í™” ì‹œì‘'ìœ¼ë¡œ ê°„ì£¼
    return any(
        (m.get("role") == "user") and (m.get("content") or "").strip()
        for m in msgs
    ) or bool(st.session_state.get("_pending_user_q"))

# --- ìµœì¢… í›„ì²˜ë¦¬ ìœ í‹¸: ë‹µë³€ ë³¸ë¬¸ì„ ì •ë¦¬í•˜ê³  ì¡°ë¬¸ì— ì¸ë¼ì¸ ë§í¬ë¥¼ ë¶™ì¸ë‹¤ ---
def apply_final_postprocess(full_text: str, collected_laws: list) -> str:
    # 1) normalize (fallback í¬í•¨)
    try:
        ft = _normalize_text(full_text)
    except NameError:
        import re as _re
        def _normalize_text(s: str) -> str:
            s = (s or "").replace("\r\n", "\n").replace("\r", "\n").strip()
            s = _re.sub(r"\n{3,}", "\n\n", s)
            s = _re.sub(r"[ \t]+\n", "\n", s)
            return s
        ft = _normalize_text(full_text)

    # 2) ë¶ˆë¦¿ ë¬¸ì í†µì¼: â€¢, * â†’ -  (ì¸ë¼ì¸ ë§í¬ ì¹˜í™˜ ëˆ„ë½ ë°©ì§€)
    ft = (
        ft.replace("\u2022 ", "- ")  # ìœ ë‹ˆì½”ë“œ ë¶ˆë¦¿
          .replace("â€¢ ", "- ")
          .replace("* ", "- ")
    )

    # 3) ì¡°ë¬¸ ì¸ë¼ì¸ ë§í¬ ë³€í™˜:  - ë¯¼ë²• ì œ839ì¡°ì˜2 â†’ [ë¯¼ë²• ì œ839ì¡°ì˜2](...)
    ft = link_inline_articles_in_bullets(ft)

    # 4) ë³¸ë¬¸ ë‚´ [ë²•ë ¹ëª…](URL) êµì •(ë²•ì œì²˜ ê³µì‹ ë§í¬ë¡œ)
    ft = fix_links_with_lawdata(ft, collected_laws)

    # 5) ë§¨ ì•„ë˜ 'ì°¸ê³  ë§í¬(ì¡°ë¬¸)' ì„¹ì…˜ ì œê±°(ì¤‘ë³µ ë°©ì§€)
    ft = strip_reference_links_block(ft)

    # 6) ì¤‘ë³µ/ë¹ˆ ì¤„ ì •ë¦¬
    ft = _dedupe_blocks(ft)

    return ft



# --- ë‹µë³€(ë§ˆí¬ë‹¤ìš´)ì—ì„œ 'ë²•ë ¹ëª…'ë“¤ì„ ì¶”ì¶œ(ë³µìˆ˜) ---

# [ë¯¼ë²• ì œ839ì¡°ì˜2](...), [ê°€ì‚¬ì†Œì†¡ë²• ì œ2ì¡°](...) ë“±
_LAW_IN_LINK = re.compile(r'\[([^\]\n]+?)\s+ì œ\d+ì¡°(ì˜\d+)?\]')
# ë¶ˆë¦¿/ì¼ë°˜ ë¬¸ì¥ ë‚´: "OOë²•/ë ¹/ê·œì¹™/ì¡°ë¡€" (+ì„ íƒì  'ì œnì¡°')
_LAW_INLINE  = re.compile(r'([ê°€-í£A-Za-z0-9Â·\s]{2,40}?(?:ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€))(?:\s*ì œ\d+ì¡°(ì˜\d+)?)?')

def extract_law_names_from_answer(md: str) -> list[str]:
    if not md:
        return []
    names = set()

    # 1) ë§í¬ í…ìŠ¤íŠ¸ ì•ˆì˜ ë²•ë ¹ëª…
    for m in _LAW_IN_LINK.finditer(md):
        nm = (m.group(1) or "").strip()
        if nm:
            names.add(nm)

    # 2) ì¼ë°˜ í…ìŠ¤íŠ¸/ë¶ˆë¦¿ì—ì„œ ë²•ë ¹ëª… íŒ¨í„´
    for m in _LAW_INLINE.finditer(md):
        nm = (m.group(1) or "").strip()
        # ê³¼ì í•© ë°©ì§€: ë„ˆë¬´ ì§§ì€/ê¸´ ê²ƒ ì œì™¸
        if 2 <= len(nm) <= 40:
            names.add(nm)

    # ì •ë¦¬(ì¤‘ë³µ ì œê±° + ê¸¸ì´ ì»· + ìƒìœ„ 6ê°œ)
    out, seen = [], set()
    for n in names:
        n2 = n[:40]
        if n2 and n2 not in seen:
            seen.add(n2)
            out.append(n2)
    return out[:6]


def normalize_law_link(u: str) -> str:
    """ìƒëŒ€/ìŠ¤í‚´ëˆ„ë½ ë§í¬ë¥¼ www.law.go.kr ì ˆëŒ€ URLë¡œ êµì •"""
    if not u: return ""
    u = u.strip()
    if u.startswith("http://") or u.startswith("https://"): return u
    if u.startswith("//"): return "https:" + u
    if u.startswith("/"):  return up.urljoin(LAW_PORTAL_BASE, u.lstrip("/"))
    return up.urljoin(LAW_PORTAL_BASE, u)

def _normalize_text(s: str) -> str:
    s = (s or "").replace("\r\n", "\n").replace("\r", "\n")
    lines = [ln.rstrip() for ln in s.split("\n")]
    while lines and not lines[0].strip():
        lines.pop(0)
    while lines and not lines[-1].strip():
        lines.pop()
    merged, i = [], 0
    num_pat = re.compile(r'^\s*((\d+)|([IVXLC]+)|([ivxlc]+))\s*[\.\)]\s*$')
    while i < len(lines):
        cur = lines[i]; m = num_pat.match(cur)
        if m:
            j = i + 1
            while j < len(lines) and not lines[j].strip(): j += 1
            if j < len(lines):
                number = (m.group(2) or m.group(3) or m.group(4)).upper()
                title = lines[j].lstrip()
                merged.append(f"{number}. {title}")
                i = j + 1; continue
        merged.append(cur); i += 1
    out, prev_blank = [], False
    for ln in merged:
        if ln.strip() == "":
            if not prev_blank: out.append("")
            prev_blank = True
        else:
            prev_blank = False; out.append(ln)
    return "\n".join(out)

# === [PATCH A] ì¡°ë¬¸ ì§ë§í¬(ì¸ë¼ì¸) + í•˜ë‹¨ 'ì°¸ê³  ë§í¬' ì„¹ì…˜ ì œê±° ===
import re
from urllib.parse import quote

# ì¡°ë¬¸ íŒ¨í„´: ë¯¼ë²• ì œ839ì¡°ì˜2, ë¯¼ì‚¬ì†Œì†¡ë²• ì œ163ì¡° ë“±
_ART_PAT_BULLET = re.compile(
    r'(?m)^(?P<prefix>\s*[-*â€¢]\s*)(?P<law>[ê°€-í£A-Za-z0-9Â·()\s]{2,40})\s*ì œ(?P<num>\d{1,4})ì¡°(?P<ui>(ì˜\d{1,3}){0,2})(?P<tail>[^\n]*)$'
)

# í•˜ë‹¨ 'ì°¸ê³  ë§í¬' ì œëª©(ëª¨ë¸ì´ 7. ë˜ëŠ” 7) ë“±ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ì¼€ì´ìŠ¤ í¬í•¨)
_REF_BLOCK_PAT = re.compile(
    r'(?ms)^\s*\d+\s*[\.\)]\s*ì°¸ê³ \s*ë§í¬\s*[:ï¼š]?\s*\n(?:\s*[-*â€¢].*\n?)+'
)
# ì•ì— ê³µë°±ì´ ìˆì–´ë„ ë§¤ì¹­ë˜ë„ë¡ ë³´ê°•
_REF_BLOCK2_PAT = re.compile(r'\n[ \t]*###\s*ì°¸ê³ \s*ë§í¬\(ì¡°ë¬¸\)[\s\S]*$', re.M)


def _deep_article_url(law: str, art_label: str) -> str:
    return f"https://www.law.go.kr/ë²•ë ¹/{quote((law or '').strip())}/{quote(art_label)}"

def link_inline_articles_in_bullets(markdown: str) -> str:
    """ë¶ˆë¦¿ ë¼ì¸ ì¤‘ 'ë²•ë ¹ëª… ì œNì¡°(ì˜M)'ë¥¼ [í…ìŠ¤íŠ¸](ì¡°ë¬¸URL)ë¡œ êµì²´"""
    def repl(m: re.Match) -> str:
        law = m.group("law").strip()
        art = f"ì œ{m.group('num')}ì¡°{m.group('ui') or ''}"
        url = _deep_article_url(law, art)
        tail = (m.group("tail") or "")
        # tailì´ " (ì¬ì‚°ë¶„í• )" ê°™ì€ ë¶€ê°€ì„¤ëª…ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³´ì¡´
        linked = f"{m.group('prefix')}[{law} {art}]({url}){tail}"
        return linked
    return _ART_PAT_BULLET.sub(repl, markdown or "")

def strip_reference_links_block(markdown: str) -> str:
    """ë§¨ ì•„ë˜ 'ì°¸ê³  ë§í¬' ì„¹ì…˜ì„ ì œê±°(ëª¨ë¸/ëª¨ë“ˆì´ ìƒì„±í•œ ë¸”ë¡ ëª¨ë‘ ì»¤ë²„)"""
    if not markdown:
        return markdown
    txt = _REF_BLOCK_PAT.sub("", markdown)
    txt = _REF_BLOCK2_PAT.sub("", txt)
    return txt


# === ìƒˆë¡œ ì¶”ê°€: ì¤‘ë³µ ì œê±° ìœ í‹¸ ===
def _dedupe_blocks(text: str) -> str:
    s = _normalize_text(text or "")

    # 1) ì™„ì „ ë™ì¼ ë¬¸ë‹¨ì˜ ì—°ì† ì¤‘ë³µ ì œê±°
    lines, out, prev = s.split("\n"), [], None
    for ln in lines:
        if ln.strip() and ln == prev:
            continue
        out.append(ln); prev = ln
    s = "\n".join(out)

    # 2) "ë²•ë¥  ìë¬¸ ë©”ëª¨"ë¡œ ì‹œì‘í•˜ëŠ” ë™ì¼ ë³¸ë¬¸ 2ì¤‘ ì¶œë ¥ ë°©ì§€
    pat = re.compile(r'(ë²•ë¥ \s*ìë¬¸\s*ë©”ëª¨[\s\S]{50,}?)(?:\n+)\1', re.I)
    s = pat.sub(r'\1', s)

    # 3) ë‚´ë¶€ ì ˆì°¨ ë¬¸êµ¬ ë…¸ì¶œ ì‹œ ì œê±°(ì˜ë„ ë¶„ì„/ì¶”ê°€ ê²€ìƒ‰/ì¬ê²€ìƒ‰)
    s = re.sub(
        r'^\s*\d+\.\s*\*\*?(ì‚¬ìš©ìì˜ ì˜ë„ ë¶„ì„|ì¶”ê°€ ê²€ìƒ‰|ì¬ê²€ìƒ‰)\*\*?.*?(?=\n\d+\.|\Z)',
        '',
        s,
        flags=re.M | re.S
    )

    # ë¹ˆ ì¤„ ì •ë¦¬
    s = re.sub(r'\n{3,}', '\n\n', s)
    return s

# === add: ì—¬ëŸ¬ ë²•ë ¹ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ìš”ì•½í•´ì„œ LLMì— ë¨¹ì¼ í”„ë¼ì´ë¨¸ ===
def _summarize_laws_for_primer(law_items: list[dict], max_items: int = 6) -> str:
    """
    ì—¬ëŸ¬ ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§§ê²Œ ìš”ì•½í•´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì£¼ì….
    - ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ ì¼ë¶€ë§Œ (max_items)
    - í˜•ì‹: "ê´€ë ¨ ë²•ë ¹ í›„ë³´: 1) ë²•ë ¹ëª…(êµ¬ë¶„, ì†Œê´€ë¶€ì²˜, ì‹œí–‰/ê³µí¬)"
    """
    if not law_items:
        return ""
    rows = []
    for i, d in enumerate(law_items[:max_items], 1):
        nm = d.get("ë²•ë ¹ëª…","").strip()
        kind = d.get("ë²•ë ¹êµ¬ë¶„","").strip()
        dept = d.get("ì†Œê´€ë¶€ì²˜ëª…","").strip()
        eff = d.get("ì‹œí–‰ì¼ì","").strip()
        pub = d.get("ê³µí¬ì¼ì","").strip()
        rows.append(f"{i}) {nm} ({kind}; {dept}; ì‹œí–‰ {eff}, ê³µí¬ {pub})")
    body = "\n".join(rows)
    return (
        "ì•„ë˜ëŠ” ì‚¬ìš©ì ì‚¬ê±´ê³¼ ê´€ë ¨ë„ê°€ ë†’ì€ ë²•ë ¹ í›„ë³´ ëª©ë¡ì´ë‹¤. "
        "ë‹µë³€ì„ ì‘ì„±í•  ë•Œ ê°ê°ì˜ ì ìš© ë²”ìœ„ì™€ ì±…ì„ì£¼ì²´, êµ¬ì„±ìš”ê±´Â·ì˜ë¬´Â·ì œì¬ë¥¼ êµì°¨ ê²€í† í•˜ë¼.\n"
        f"{body}\n"
        "ê°€ëŠ¥í•˜ë©´ ê° ë²•ë ¹ì„ ë¶„ë¦¬ëœ ì†Œì œëª©ìœ¼ë¡œ ì •ë¦¬í•˜ê³ , í•µì‹¬ ì¡°ë¬¸(1~2ê°œ)ë§Œ ê°„ë‹¨ ì¸ìš©í•˜ë¼."
    )

# === add: LLM-ìš°ì„  í›„ë³´ â†’ ê° í›„ë³´ë¡œ MOLEG API ë‹¤ê±´ ì¡°íšŒ/ëˆ„ì  ===
def prefetch_law_context(user_q: str, num_rows_per_law: int = 3) -> list[dict]:
    """
    1) LLMì´ ë²•ë ¹ í›„ë³´ë¥¼ ë½‘ëŠ”ë‹¤ (extract_law_candidates_llm)  # :contentReference[oaicite:4]{index=4}
    2) í›„ë³´ë“¤ ê°ê°ì— ëŒ€í•´ _call_moleg_list("law", ...) í˜¸ì¶œ    # :contentReference[oaicite:5]{index=5}
    3) ê²°ê³¼ë¥¼ ì „ë¶€ í•©ì³ì„œ ë°˜í™˜ (ì¤‘ë³µì€ ê°„ë‹¨ ì œê±°)
    """
    seen = set()
    merged: list[dict] = []

    # 1) í›„ë³´
    law_names = extract_law_candidates_llm(user_q) or []

    # í›„ë³´ê°€ 0ê°œë©´ _clean_query_for_api()ë¡œ ë§ˆì§€ë§‰ í´ë°±
    if not law_names:
        law_names = [_clean_query_for_api(user_q)]  # :contentReference[oaicite:6]{index=6}

    # 2) ê° í›„ë³´ë¡œ ë‹¤ê±´ ì¡°íšŒ
    for name in law_names:
        if not name:
            continue
        items, _, _ = _call_moleg_list("law", name, num_rows=num_rows_per_law)  # :contentReference[oaicite:7]{index=7}
        for it in (items or []):
            key = (it.get("ë²•ë ¹ëª…",""), it.get("ë²•ë ¹êµ¬ë¶„",""), it.get("ì‹œí–‰ì¼ì",""))
            if key not in seen:
                seen.add(key)
                merged.append(it)

    return merged

# === add: LLM-ìš°ì„  ì§ˆì˜ì–´ ì„ íƒ í—¬í¼ ===
# === fix: LLM-ìš°ì„  ì§ˆì˜ì–´ ì„ íƒ (í´ë°±ì€ í›„ë³´ê°€ ì—†ì„ ë•Œë§Œ) ===
# ============================================
# [PATCH B] í†µí•© ê²€ìƒ‰ ê²°ê³¼ì— 'ê°€ì‚¬ì†Œì†¡ë²•'ë„ í•­ìƒ í›„ë³´ì— í¬í•¨
# - LLMì´ 'ë¯¼ë²•'ë§Œ ê³¨ë¼ë„, ì§ˆë¬¸ì´ ì´í˜¼/ì¬ì‚°ë¶„í• /ì–‘ìœ¡ ë“± ê°€ì‚¬ í‚¤ì›Œë“œë¥¼
#   í¬í•¨í•˜ë©´ 'ê°€ì‚¬ì†Œì†¡ë²•'ì„ í›„ë³´ì— ì¶”ê°€í•˜ì—¬ ìš°ì¸¡ íŒ¨ë„ì— ë…¸ì¶œë˜ë„ë¡ ë³´ê°•
# - ê·¸ëŒ€ë¡œ ë¶™ì—¬ ë„£ì–´ ê¸°ì¡´ choose_law_queries_llm_first ë¥¼ êµì²´í•˜ì„¸ìš”.
# ============================================

from typing import List

# 1) í‚¤ì›Œë“œ â†’ ëŒ€í‘œ ë²•ë ¹ ë§µ: ì—†ìœ¼ë©´ ë§Œë“¤ê³ , ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
try:
    KEYWORD_TO_LAW  # noqa: F821  # ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
except NameError:   # ì—†ì–´ë„ ì•ˆì „í•˜ê²Œ ìƒì„±
    KEYWORD_TO_LAW = {}

KEYWORD_TO_LAW.update({
    # ê°€ì‚¬ ì‚¬ê±´ í•µì‹¬ í‚¤ì›Œë“œ â†’ ê°€ì‚¬ì†Œì†¡ë²•
    "ì´í˜¼": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì¬ì‚°ë¶„í• ": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì–‘ìœ¡": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì–‘ìœ¡ë¹„": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì¹œê¶Œ": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ë©´ì ‘êµì„­": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ê°€ì‚¬": "ê°€ì‚¬ì†Œì†¡ë²•",
    "í˜‘ì˜ì´í˜¼": "ê°€ì‚¬ì†Œì†¡ë²•",
    "ì¬íŒìƒ ì´í˜¼": "ê°€ì‚¬ì†Œì†¡ë²•",
})


def choose_law_queries_llm_first(user_q: str) -> List[str]:
    """
    1) LLMì´ ì œì•ˆí•œ ë²•ë ¹ í›„ë³´ë¥¼ ìš°ì„  ì±„íƒ
    2) í›„ë³´ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì •ê·œí™” ì§ˆì˜ í´ë°± ì¶”ê°€
    3) â˜…í•­ìƒâ˜… í‚¤ì›Œë“œ ë§¤í•‘ìœ¼ë¡œ ë³´ê°•(ê°€ì‚¬ì†Œì†¡ë²• ë“±) â€” ì¤‘ë³µì€ ì œê±°
    """
    ordered: List[str] = []
    text = (user_q or "")

    # 1) LLM í›„ë³´ ìš°ì„ 
    try:
        llm_candidates = extract_law_candidates_llm(user_q) or []  # ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
    except NameError:
        llm_candidates = []
    for nm in llm_candidates:
        nm = (nm or "").strip()
        if nm and nm not in ordered:
            ordered.append(nm)

    # 2) í›„ë³´ê°€ ì—†ìœ¼ë©´ í´ë¦° ì§ˆì˜ í´ë°±
    if not ordered:
        try:
            cleaned = _clean_query_for_api(user_q)  # ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©
        except NameError:
            cleaned = None
        if cleaned:
            ordered.append(cleaned)

    # 3) í‚¤ì›Œë“œ íŒíŠ¸ë¡œ í•­ìƒ ë³´ê°• (ê°€ì‚¬ í‚¤ì›Œë“œ â†’ ê°€ì‚¬ì†Œì†¡ë²• ë“±)
    for kw, mapped in KEYWORD_TO_LAW.items():
        if kw and (kw in text) and mapped not in ordered:
            ordered.append(mapped)

    return ordered

def render_bubble_with_copy(message: str, key: str):
    """ì–´ì‹œìŠ¤í„´íŠ¸ ë§í’ì„  ì „ìš© ë³µì‚¬ ë²„íŠ¼"""
    message = _normalize_text(message or "")
    st.markdown(message)
    safe_raw_json = json.dumps(message)
    html_tpl = '''
    <div class="copy-row" style="margin-bottom:8px">
      <button id="copy-__KEY__" class="copy-btn">
        <svg width="14" height="14" viewBox="0 0 24 24" fill="none">
          <path d="M9 9h9v12H9z" stroke="currentColor"/>
          <path d="M6 3h9v3" stroke="currentColor"/>
          <path d="M6 6h3v3" stroke="currentColor"/>
        </svg>
        ë³µì‚¬
      </button>
    </div>
    <script>
    (function(){
      const btn = document.getElementById("copy-__KEY__");
      if (!btn) return;
      btn.addEventListener("click", async () => {
        try {
          await navigator.clipboard.writeText(__SAFE__);
          const old = btn.innerHTML; btn.innerHTML = "ë³µì‚¬ë¨!";
          setTimeout(()=>btn.innerHTML = old, 1200);
        } catch(e) { alert("ë³µì‚¬ ì‹¤íŒ¨: " + e); }
      });
    })();
    </script>
    '''
    html_out = html_tpl.replace("__KEY__", str(key)).replace("__SAFE__", safe_raw_json)
    components.html(html_out, height=40)

def copy_url_button(url: str, key: str, label: str = "ë§í¬ ë³µì‚¬"):
    if not url: return
    safe = json.dumps(url)
    html_tpl = '''
      <div style="display:flex;gap:8px;align-items:center;margin-top:6px">
        <button id="copy-url-__KEY__" style="padding:6px 10px;border:1px solid #ddd;border-radius:8px;cursor:pointer">
          __LABEL__
        </button>
        <span id="copied-__KEY__" style="font-size:12px;color:var(--text-color,#888)"></span>
      </div>
      <script>
        (function(){
          const btn = document.getElementById("copy-url-__KEY__");
          const msg = document.getElementById("copied-__KEY__");
          if(!btn) return;
          btn.addEventListener("click", async () => {
            try {
              await navigator.clipboard.writeText(__SAFE__);
              msg.textContent = "ë³µì‚¬ë¨!";
              setTimeout(()=>msg.textContent="", 1200);
            } catch(e) {
              msg.textContent = "ë³µì‚¬ ì‹¤íŒ¨";
            }
          });
        })();
      </script>
    '''
    html_out = (html_tpl
                .replace("__KEY__", str(key))
                .replace("__SAFE__", safe)
                .replace("__LABEL__", html.escape(label)))
    components.html(html_out, height=40)

def load_secrets():
    try:
        law_key = st.secrets["LAW_API_KEY"]
    except Exception:
        law_key = None
        st.error("`LAW_API_KEY`ê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit â†’ App settings â†’ Secretsì— ì¶”ê°€í•˜ì„¸ìš”.")
    try:
        az = st.secrets["azure_openai"]
        _ = (az["api_key"], az["endpoint"], az["deployment"], az["api_version"])
    except Exception:
        az = None
        st.warning("Azure OpenAI ì„¤ì •ì´ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ ì•ˆë‚´ë§Œ ì œê³µí•©ë‹ˆë‹¤.")
    return law_key, az

def _henc(s: str) -> str: return up.quote((s or "").strip())
def hangul_by_name(domain: str, name: str) -> str: return f"{_HBASE}/{_henc(domain)}/{_henc(name)}"

# "ì œ839ì¡°" ê°™ì€ íŒ¨í„´ ì¸ì‹ìš©
_ARTICLE_RE = re.compile(r"^ì œ?\d+ì¡°(ì˜\d+)?$")

def resolve_article_from_keywords(keys):
    ARTICLE_SYNONYMS = {
        "ì¬ì‚°ë¶„í• ": "ì œ839ì¡°ì˜2",
        "ì´í˜¼": "ì œ834ì¡°",
    }
    keys = [k.strip() for k in (keys or []) if k]
    for k in keys:
        if k in ARTICLE_SYNONYMS:
            return ARTICLE_SYNONYMS[k]
    for k in keys:
        if _ARTICLE_RE.match(k):
            return k
    return None

def hangul_law_article(name: str, subpath: str) -> str: return f"{_HBASE}/ë²•ë ¹/{_henc(name)}/{_henc(subpath)}"

def hangul_law_with_keys(name: str, keys) -> str:
    """í‚¤ì›Œë“œê°€ ì¡°ë¬¸ì„ ê°€ë¦¬í‚¤ë©´ ì¡°ë¬¸ìœ¼ë¡œ, ì•„ë‹ˆë©´ ê²€ìƒ‰ìœ¼ë¡œ."""
    art = resolve_article_from_keywords(keys)
    if art:
        return hangul_law_article(name, art)
    q = " ".join([name] + [k for k in (keys or []) if k]) if keys else name
    return build_fallback_search("law", q)

def hangul_admrul_with_keys(name: str, issue_no: str, issue_date: str) -> str: return f"{_HBASE}/í–‰ì •ê·œì¹™/{_henc(name)}/({_henc(issue_no)},{_henc(issue_date)})"
def hangul_ordin_with_keys(name: str, no: str, date: str) -> str: return f"{_HBASE}/ìì¹˜ë²•ê·œ/{_henc(name)}/({_henc(no)},{_henc(date)})"
def hangul_trty_with_keys(no: str, eff_date: str) -> str: return f"{_HBASE}/ì¡°ì•½/({_henc(no)},{_henc(eff_date)})"
def expc_public_by_id(expc_id: str) -> str: return f"https://www.law.go.kr/LSW/expcInfoP.do?expcSeq={up.quote(expc_id)}"
def lstrm_public_by_id(trm_seqs: str) -> str: return f"https://www.law.go.kr/LSW/lsTrmInfoR.do?trmSeqs={up.quote(trm_seqs)}"
def licbyl_file_download(fl_seq: str) -> str: return f"https://www.law.go.kr/LSW/flDownload.do?flSeq={up.quote(fl_seq)}"

def extract_case_no(text: str) -> str | None:
    if not text: return None
    m = _CASE_NO_RE.search(text.replace(" ", ""))
    return m.group(0) if m else None

def validate_case_no(case_no: str) -> bool:
    case_no = (case_no or "").replace(" ", "")
    return bool(_CASE_NO_RE.fullmatch(case_no))

def build_case_name_from_no(case_no: str, court: str = "ëŒ€ë²•ì›", disposition: str = "íŒê²°") -> str | None:
    case_no = (case_no or "").replace(" ", "")
    if not validate_case_no(case_no): return None
    return f"{court} {case_no} {disposition}"

def build_scourt_link(case_no: str) -> str:
    return f"https://glaw.scourt.go.kr/wsjo/panre/sjo050.do?saNo={up.quote(case_no)}"

def is_reachable(url: str) -> bool:
    try:
        r = requests.get(url, timeout=8, allow_redirects=True)
        if not (200 <= r.status_code < 400):
            return False
        text = r.text[:4000]
        bad_signals = [
            "í•´ë‹¹ í•œê¸€ì£¼ì†Œëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            "í•œê¸€ ë²•ë ¹ì£¼ì†Œë¥¼ í™•ì¸í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤",
        ]
        return not any(sig in text for sig in bad_signals)
    except Exception:
        return False

def build_fallback_search(kind: str, q: str) -> str:
    qq = up.quote((q or "").strip())
    if kind in ("law", "admrul", "ordin", "trty"):
        return f"https://www.law.go.kr/LSW/lsSc.do?query={qq}"
    if kind == "prec":
        return f"https://glaw.scourt.go.kr/wsjo/panre/sjo050.do?saNo={qq}"
    if kind == "cc":
        return f"https://www.law.go.kr/LSW/lsSc.do?query={qq}"
    return f"https://www.law.go.kr/LSW/lsSc.do?query={qq}"

def present_url_with_fallback(main_url: str, kind: str, q: str, label_main="ìƒˆ íƒ­ì—ì„œ ì—´ê¸°"):
    if main_url and is_reachable(main_url):
        st.code(main_url, language="text")
        st.link_button(label_main, main_url, use_container_width=True)
        copy_url_button(main_url, key=str(abs(hash(main_url))))
    else:
        fb = build_fallback_search(kind, q)
        st.warning("ì§ì ‘ ë§í¬ê°€ ì—´ë¦¬ì§€ ì•Šì•„ **ëŒ€ì²´ ê²€ìƒ‰ ë§í¬**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        st.code(fb, language="text")
        st.link_button("ëŒ€ì²´ ê²€ìƒ‰ ë§í¬ ì—´ê¸°", fb, use_container_width=True)
        copy_url_button(fb, key=str(abs(hash(fb))))

def render_pinned_question():
    last_q = (st.session_state.get("last_q") or "").strip()
    if not last_q:
        return

    st.markdown(
        f"""
        <div class="pinned-q">
          <div class="label">ìµœê·¼ ì§ˆë¬¸</div>
          <div class="text">{_esc_br(last_q)}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

# ë‹µë³€ ë‚´ ë§í¬ë¥¼ ìˆ˜ì§‘ëœ ë²•ë ¹ ìƒì„¸ë§í¬ë¡œ êµì •
def fix_links_with_lawdata(markdown: str, law_data: list[dict]) -> str:
    import re
    if not markdown or not law_data:
        return markdown
    name_to_url = {
        d["ë²•ë ¹ëª…"]: (d["ë²•ë ¹ìƒì„¸ë§í¬"] or f"https://www.law.go.kr/ë²•ë ¹/{_henc(d['ë²•ë ¹ëª…'])}")
        for d in law_data if d.get("ë²•ë ¹ëª…")
    }
    pat = re.compile(r'\[([^\]]+)\]\((https?://www\.law\.go\.kr/[^\)]+)\)')
    def repl(m):
        text, url = m.group(1), m.group(2)
        if text in name_to_url:
            return f'[{text}]({name_to_url[text]})'
        return m.group(0)
    return pat.sub(repl, markdown)

# =============================
# Secrets / Clients / Session
# =============================
LAW_API_KEY, AZURE = load_secrets()
client = None
if AZURE:
    try:
        client = AzureOpenAI(
            api_key=AZURE["api_key"],
            api_version=AZURE["api_version"],
            azure_endpoint=AZURE["endpoint"],
        )
    except Exception as e:
        st.error(f"Azure OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# =============================
# MOLEG API (Law Search) â€” unified
# =============================
import ssl
from urllib3.poolmanager import PoolManager

MOLEG_BASES = [
    "https://apis.data.go.kr/1170000",
    "http://apis.data.go.kr/1170000",
]

class TLS12HttpAdapter2(HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs):
        ctx = ssl.create_default_context()
        ctx.minimum_version = ssl.TLSVersion.TLSv1_2
        ctx.maximum_version = ssl.TLSVersion.TLSv1_2
        self.poolmanager = PoolManager(*args, ssl_context=ctx, **kwargs)

def _call_moleg_list(target: str, query: str, num_rows: int = 10, page_no: int = 1):
    """
    target: law | admrul | ordin | trty | expc | detc | licbyl | lstrm
    """
    if not LAW_API_KEY:
        return [], None, "LAW_API_KEY ë¯¸ì„¤ì •"

    api_key = (LAW_API_KEY or "").strip().strip("'").strip('"')
    if "%" in api_key and any(t in api_key.upper() for t in ("%2B", "%2F", "%3D")):
        try:
            api_key = up.unquote(api_key)
        except Exception:
            pass

    # === ì¶”ê°€: ë¹ˆ ì§ˆì˜ì–´(ì™€ì¼ë“œì¹´ë“œ) í˜¸ì¶œ ì°¨ë‹¨ ===
    q = (query or "").strip()
    if not q:
        return [], None, "ë¹ˆ ì§ˆì˜ì–´ë¡œ í˜¸ì¶œë˜ì–´ ë¬´ì‹œí•¨"

    params = {
        "serviceKey": api_key,
        "target": target,
        "query": q,  # <-- ê¸°ì¡´ì˜ (query or "*") ë¥¼ q ë¡œ êµì²´
        "numOfRows": max(1, min(10, int(num_rows))),
        "pageNo": max(1, int(page_no)),
    }
    # ... ì´í•˜ ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ ...

    last_err = None
    resp = None
    last_endpoint = None

    for base in MOLEG_BASES:
        endpoint = f"{base}/{target}/{target}SearchList.do"
        last_endpoint = endpoint
        try:
            sess = requests.Session()
            if base.startswith("https://"):
                sess.mount("https://", TLS12HttpAdapter2())
            resp = sess.get(
                endpoint, params=params, timeout=15,
                headers={"User-Agent":"Mozilla/5.0"}, allow_redirects=True
            )
            resp.raise_for_status()
            break
        except requests.exceptions.SSLError as e:
            last_err = e; continue
        except Exception as e:
            last_err = e; continue

    if resp is None:
        return [], last_endpoint, f"ë²•ì œì²˜ API ì—°ê²° ì‹¤íŒ¨: {last_err}"

    try:
        root = ET.fromstring(resp.text)
        result_code = (root.findtext(".//resultCode") or "").strip()
        result_msg  = (root.findtext(".//resultMsg")  or "").strip()
        if result_code and result_code != "00":
            return [], last_endpoint, f"ë²•ì œì²˜ API ì˜¤ë¥˜ [{result_code}]: {result_msg or 'fail'}"

        item_tags = {
            "law": ["law"], "admrul": ["admrul"], "ordin": ["ordin"],
            "trty": ["Trty","trty"], "expc":["expc"], "detc":["Detc","detc"],
            "licbyl":["licbyl"], "lstrm":["lstrm"],
        }.get(target, ["law"])

        items = []
        for tag in item_tags: items.extend(root.findall(f".//{tag}"))

        normalized = []
        for el in items:
            normalized.append({
                "ë²•ë ¹ëª…": (el.findtext("ë²•ë ¹ëª…í•œê¸€") or el.findtext("ìì¹˜ë²•ê·œëª…") or el.findtext("ì¡°ì•½ëª…") or "").strip(),
                "ë²•ë ¹ëª…ì¹­ID": (el.findtext("ë²•ë ¹ëª…ì¹­ID") or "").strip(),
                "ì†Œê´€ë¶€ì²˜ëª…": (el.findtext("ì†Œê´€ë¶€ì²˜ëª…") or "").strip(),
                "ë²•ë ¹êµ¬ë¶„": (el.findtext("ë²•ë ¹êµ¬ë¶„") or el.findtext("ìì¹˜ë²•ê·œì¢…ë¥˜") or el.findtext("ì¡°ì•½êµ¬ë¶„ëª…") or "").strip(),
                "ì‹œí–‰ì¼ì": (el.findtext("ì‹œí–‰ì¼ì") or "").strip(),
                "ê³µí¬ì¼ì": (el.findtext("ê³µí¬ì¼ì") or "").strip(),
                "MST": (el.findtext("MST") or el.findtext("ë²•ë ¹ID") or el.findtext("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or "").strip(),
                "ë²•ë ¹ìƒì„¸ë§í¬": normalize_law_link(
                    (el.findtext("ë²•ë ¹ìƒì„¸ë§í¬") or el.findtext("ìì¹˜ë²•ê·œìƒì„¸ë§í¬") or el.findtext("ì¡°ì•½ìƒì„¸ë§í¬") or "").strip()
                ),
            })

        return normalized, last_endpoint, None
    except Exception as e:
        return [], last_endpoint, f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}"

# í†µí•© ë¯¸ë¦¬ë³´ê¸° ì „ìš©: ê³¼í•œ ë¬¸ì¥ë¶€í˜¸/ë”°ì˜´í‘œ ì œê±° + 'ë²•ë ¹ëª… (ì œnì¡°)'ë§Œ ì¶”ì¶œ
def _clean_query_for_api(q: str) -> str:
    q = (q or "").strip()
    q = re.sub(r'[â€œâ€"\'â€˜â€™.,!?()<>\\[\\]{}:;~â€¦]', ' ', q)
    q = re.sub(r'\\s+', ' ', q).strip()
    # ë²•ë ¹ëª…(OOë²•/ë ¹/ê·œì¹™/ì¡°ë¡€) + (ì œnì¡°) íŒ¨í„´
    name = re.search(r'([ê°€-í£A-Za-z0-9Â·\\s]{1,40}?(ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€))', q)
    article = re.search(r'ì œ\\d+ì¡°(ì˜\\d+)?', q)
    if name and article: return f"{name.group(0).strip()} {article.group(0)}"
    if name: return name.group(0).strip()
    return q

# === add: LLM ë¦¬ë­ì»¤(ë§¥ë½ í•„í„°) ===
def rerank_laws_with_llm(user_q: str, law_items: list[dict], top_k: int = 8) -> list[dict]:
    if not law_items or client is None:
        return law_items
    names = [d.get("ë²•ë ¹ëª…","").strip() for d in law_items if d.get("ë²•ë ¹ëª…")]
    names_txt = "\n".join(f"- {n}" for n in names[:25])

    SYS = (
        "ë„ˆëŠ” ì‚¬ê±´ê³¼ ê´€ë ¨ëœ 'ë²•ë ¹ëª…'ë§Œ ë‚¨ê¸°ëŠ” í•„í„°ì•¼. ì§ˆë¬¸ ë§¥ë½ê³¼ ë¬´ê´€í•˜ë©´ ì œì™¸í•˜ê³ , JSONë§Œ ë°˜í™˜í•´.\n"
        'í˜•ì‹: {"pick":["í˜•ë²•","ì‚°ì—…ì•ˆì „ë³´ê±´ë²•"]}'
    )
    prompt = (
        "ì‚¬ìš©ì ì§ˆë¬¸:\n" + (user_q or "") + "\n\n"
        "í›„ë³´ ë²•ë ¹ ëª©ë¡:\n" + names_txt + "\n\n"
        "ì‚¬ê±´ì— ì§ì ‘ ê´€ë ¨ëœ ê²ƒë§Œ 3~8ê°œ ê³ ë¥´ê³  ë‚˜ë¨¸ì§€ëŠ” ì œì™¸í•´."
    )

    try:
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYS},
                      {"role":"user","content": prompt}],
            temperature=0.0, max_tokens=96,
        )
        txt = (resp.choices[0].message.content or "").strip()
        import re, json as _json
        if "```" in txt:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", txt); 
            if m: txt = m.group(1).strip()
        if not txt.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", txt); 
            if m: txt = m.group(0)
        data = _json.loads(txt)
        picks = [s.strip() for s in data.get("pick", []) if s.strip()]
        if not picks:
            return law_items
        name_to_item = {}
        for d in law_items:
            nm = d.get("ë²•ë ¹ëª…","").strip()
            if nm and nm not in name_to_item:
                name_to_item[nm] = d
        return [name_to_item[n] for n in picks if n in name_to_item][:top_k]
    except Exception:
        return law_items

def _filter_plans(user_q: str, plans: list[dict]) -> list[dict]:
    U = set(_canonize(_tok(user_q)))
    seen=set(); out=[]
    for p in plans or []:
        t = (p.get("target") or "").strip()
        q = (p.get("q") or "").strip()
        if not t or not q:
            continue
        T = set(_canonize(_tok(q)))
        if (U & T) or (p.get("must")):   # ì‚¬ìš©ìì™€ 1í† í° ì´ìƒ ê²¹ì¹˜ê±°ë‚˜, mustê°€ ìˆìœ¼ë©´ í†µê³¼
            key=(t,q)
            if key not in seen:
                seen.add(key)
                out.append(p)          # â† must/must_not ë³´ì¡´!
    return out[:10]


# === add/replace: ë²•ë ¹ëª… í›„ë³´ ì¶”ì¶œê¸° (LLM, ê²¬ê³  ë²„ì „) ===
@st.cache_data(show_spinner=False, ttl=300)
def extract_law_candidates_llm(q: str) -> list[str]:
    """
    ì‚¬ìš©ì ì„œìˆ ì—ì„œ ê´€ë ¨ 'ë²•ë ¹ëª…'ë§Œ 1~3ê°œ ì¶”ì¶œ.
    - JSON ì™¸ í…ìŠ¤íŠ¸/ì½”ë“œíœìŠ¤ê°€ ì„ì—¬ë„ íŒŒì‹±
    - 1ì°¨ ì‹¤íŒ¨ ì‹œ ì—„ê²© í”„ë¡¬í”„íŠ¸ë¡œ 1íšŒ ì¬ì‹œë„
    """
    if not q or (client is None):
        return []

    def _parse_json_laws(txt: str) -> list[str]:
        import re, json as _json
        t = (txt or "").strip()
        # ```json ... ``` ë˜ëŠ” ``` ... ``` ì œê±°
        if "```" in t:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", t)
            if m:
                t = m.group(1).strip()
        # ë³¸ë¬¸ ì¤‘ JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
        if not t.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", t)
            if m:
                t = m.group(0)
        data = _json.loads(t)
        laws = [s.strip() for s in (data.get("laws", []) or []) if s and s.strip()]
        # ì¤‘ë³µ/ê¸¸ì´ ì •ë¦¬
        seen, out = set(), []
        for name in laws:
            nm = name[:40]
            if nm and nm not in seen:
                seen.add(nm); out.append(nm)
        return out

    # 1) ì¼ë°˜ í”„ë¡¬í”„íŠ¸
    try:
        SYSTEM_EXTRACT1 = (
            "ë„ˆëŠ” í•œêµ­ ì‚¬ê±´ ì„¤ëª…ì—ì„œ 'ê´€ë ¨ ë²•ë ¹ëª…'ë§Œ 1~3ê°œ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ë‹¤. "
            "ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•˜ë¼.\n"
            'í˜•ì‹: {"laws":["í˜•ë²•","ì‚°ì—…ì•ˆì „ë³´ê±´ë²•"]}'
        )
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_EXTRACT1},
                      {"role":"user","content": q.strip()}],
            temperature=0.0,
            max_tokens=128,
        )
        laws = _parse_json_laws(resp.choices[0].message.content)
        if laws:
            return laws[:3]
    except Exception:
        pass

    # 2) ì—„ê²© í”„ë¡¬í”„íŠ¸ë¡œ 1íšŒ ì¬ì‹œë„
    try:
        SYSTEM_EXTRACT2 = (
            "JSON ONLY. No code fences. No commentary. "
            'Return exactly: {"laws":["ë²•ë ¹ëª…1","ë²•ë ¹ëª…2"]}'
        )
        resp2 = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_EXTRACT2},
                      {"role":"user","content": q.strip()}],
            temperature=0.0,
            max_tokens=96,
        )
        laws2 = _parse_json_laws(resp2.choices[0].message.content)
        if laws2:
            return laws2[:3]
    except Exception:
        pass

    # ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
    return []

# === LLM í”Œë˜ë„ˆ & í”Œëœ í•„í„° ===
import re, json

# === LLM í”Œë˜ë„ˆ & í”Œëœ í•„í„° ===
def _filter_items_by_plan(user_q: str, items: list[dict], plan: dict) -> list[dict]:
    name_get = lambda d: (d.get("ë²•ë ¹ëª…") or "")
    must = set(_canonize(plan.get("must") or []))
    must_not = set(_canonize(plan.get("must_not") or []))
    qtok = set(_canonize(_tok(plan.get("q",""))))
    target = (plan.get("target") or "").strip()

    kept = []
    for it in (items or []):
        nm = name_get(it)
        N = set(_canonize(_tok(nm)))

        # 1) q í† í°ì€ í•˜ë“œ í•„í„° (ìµœì†Œí•œì˜ ì •í•©ì„± í™•ë³´)
        if qtok and not (N & qtok):
            continue

        # 2) ì œì™¸ í† í°ì€ ê³„ì† í•˜ë“œ í•„í„°
        if must_not and (N & must_not):
            continue

        # 3) mustëŠ” 'ë­í‚¹ìš©'ìœ¼ë¡œë§Œ ì‚¬ìš© (í•˜ë“œ í•„í„° ì œê±°)
        kept.append((it, N))

    # ë­í‚¹: ì‚¬ìš©ì/í”Œëœ ê´€ë ¨ë„ + must ë§¤ì¹­ ë³´ë„ˆìŠ¤(-3ì”©)
    def score(pair):
        it, N = pair
        base = _rel_score(user_q, name_get(it), plan.get("q",""))
        bonus = -3 * len(N & must)
        return base + bonus

    kept.sort(key=score)
    return [it for it, _ in kept]

@st.cache_data(show_spinner=False, ttl=180)
def propose_api_queries_llm(user_q: str) -> list[dict]:
    if not user_q or client is None:
        return []

    SYS = (
        "ë„ˆëŠ” í•œêµ­ ë²•ì œì²˜(Open API) ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì„¤ê³„í•œë‹¤. JSON ONLY.\n"
        'í˜•ì‹: {"queries":[{"target":"law|admrul|ordin|trty","q":"ê²€ìƒ‰ì–´",'
        '"must":["ë°˜ë“œì‹œ í¬í•¨"], "must_not":["ì œì™¸í•  ë‹¨ì–´"]}, ...]}\n'
        # â˜… í•µì‹¬ ì§€ì‹œ
        "- **ë°˜ë“œì‹œ `ë²•ë ¹ëª…`(ì˜ˆ: í˜•ë²•, ë¯¼ë²•, ë„ë¡œêµí†µë²•, êµí†µì‚¬ê³ ì²˜ë¦¬ íŠ¹ë¡€ë²•) ë˜ëŠ” "
        "'ë²•ë ¹ëª… + í•µì‹¬ì–´(ì˜ˆ: í˜•ë²• ê³¼ì‹¤ì¹˜ìƒ)` í˜•íƒœë¡œ ì§ˆì˜ë¥¼ ë§Œë“¤ ê²ƒ.**\n"
        "- **ì‚¬ê±´ ì„œìˆ (ì˜ˆ: ì§€í•˜ ì£¼ì°¨ì¥ì—ì„œ ê³¼ì†â€¦) ìì²´ë¥¼ ì§ˆì˜ë¡œ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ.**\n"
        "- mustëŠ” 1~3ê°œë¡œ ê°„ê²°í•˜ê²Œ, must_notì€ ë¶„ëª…íˆ ë‹¤ë¥¸ ì¶•ì¼ ë•Œë§Œ."
          # === ê·œì¹™(ì¤‘ìš”) ===
        "- target=law ì¸ ê²½ìš°, qì—ëŠ” **í•­ìƒ ë²•ë ¹ëª…ë§Œ** ì ëŠ”ë‹¤. ì˜ˆ: ë¯¼ë²•, í˜•ë²•, ë„ë¡œêµí†µë²•.\n"
        "- í‚¤ì›Œë“œ(ì˜ˆ: ì†í•´ë°°ìƒ, ê³¼ì‹¤ì¹˜ìƒ, ê³¼ì† ë“±)ëŠ” qì— ë¶™ì´ì§€ ë§ê³  **must**ì—ë§Œ ë„£ëŠ”ë‹¤.\n"
        "- ì‚¬ê±´ ì„œìˆ (ì˜ˆ: ì£¼ì°¨ì¥ì—ì„œ ì‚¬ê³ â€¦)ì„ që¡œ ì“°ì§€ ë§ê³  ë°˜ë“œì‹œ ë²•ë ¹ëª…/í–‰ì •ê·œì¹™ëª…/ì¡°ë¡€ëª… ë“±ë§Œ ì‚¬ìš©í•œë‹¤.\n"
        "- ì˜ˆì‹œ1: 'ë¯¼ë²• ì†í•´ë°°ìƒ' â†’ {\"target\":\"law\",\"q\":\"ë¯¼ë²•\",\"must\":[\"ì†í•´ë°°ìƒ\"]}\n"
        "- ì˜ˆì‹œ2: 'í˜•ë²• ê³¼ì‹¤ì¹˜ìƒ' â†’ {\"target\":\"law\",\"q\":\"í˜•ë²•\",\"must\":[\"ê³¼ì‹¤ì¹˜ìƒ\"]}\n"
        "- ì˜ˆì‹œ3: 'ì£¼ì°¨ì¥ì—ì„œ ì‚¬ê³ ' â†’ {\"target\":\"law\",\"q\":\"ë„ë¡œêµí†µë²•\",\"must\":[\"ì£¼ì°¨ì¥\",\"ì‚¬ê³ \"]}\n"
    )
   
    try:
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYS},
                      {"role":"user","content": user_q.strip()}],
            temperature=0.0, max_tokens=220,
        )
        txt = (resp.choices[0].message.content or "").strip()
        if "```" in txt:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", txt); 
            if m: txt = m.group(1).strip()
        if not txt.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", txt); 
            if m: txt = m.group(0)

        data = json.loads(txt) if txt else {}
        out=[]
        for it in (data.get("queries") or []):
            t = (it.get("target") or "").strip()
            q = (it.get("q") or "").strip()
            must = [x.strip() for x in (it.get("must") or []) if x.strip()]
            must_not = [x.strip() for x in (it.get("must_not") or []) if x.strip()]
            if t in {"law","admrul","ordin","trty"} and q:
                out.append({"target":t,"q":q[:60],"must":must[:4],"must_not":must_not[:6]})
        return out[:10]
    except Exception:
        return []

# --- ê´€ë ¨ë„ ìŠ¤ì½”ì–´(ì‘ì„ìˆ˜ë¡ ê´€ë ¨)
def _rel_score(user_q: str, item_name: str, plan_q: str) -> int:
    U = set(_canonize(_tok(user_q)))
    I = set(_canonize(_tok(item_name)))
    P = set(_canonize(_tok(plan_q)))
    if not I:
        return 999
    # êµì§‘í•©ì´ ë§ê³ , ì‚¬ìš©ìÂ·í”Œëœ í† í°ê³¼ ê²¹ì¹ ìˆ˜ë¡ ê°€ì 
    inter_ui = len(U & I)
    inter_pi = len(P & I)
    score = 100 - 10*inter_ui - 5*inter_pi
    # ì™„ì „ ë¬´ê´€(êµì§‘í•© 0)ì´ë¼ë©´ í° íŒ¨ë„í‹°
    if inter_ui == 0 and inter_pi == 0:
        score += 100
    return max(score, 0)

# íŒŒì¼ ìƒë‹¨ ì•„ë¬´ ê³³(ìœ í‹¸ ê·¼ì²˜)ì— ì¶”ê°€
_LAWISH_RE = re.compile(r"(ë²•|ë ¹|ê·œì¹™|ì¡°ë¡€|ë²•ë¥ )|ì œ\d+ì¡°")
def _lawish(q: str) -> bool:
    return bool(_LAWISH_RE.search(q or ""))

def find_all_law_data(query: str, num_rows: int = 3, hint_laws: list[str] | None = None):
    results = {}

    # 0) LLM í”Œëœ ìƒì„±
    plans = propose_api_queries_llm(query)  # ê¸°ì¡´ LLM í”Œë˜ë„ˆ ì‚¬ìš©:contentReference[oaicite:1]{index=1}

    # âœ… 0-0) ë‹µë³€/ì§ˆë¬¸ì—ì„œ ì–»ì€ 'íŒíŠ¸ ë²•ë ¹ë“¤'ì„ ìµœìš°ì„  ì‹œë“œë¡œ ì£¼ì…
    if hint_laws:
        seed = [{"target":"law","q":nm, "must":[nm], "must_not": []}
                for nm in hint_laws if nm]
        # ì•ì— ë°°ì¹˜ + (target,q) ì¤‘ë³µ ì œê±°
        seen=set(); merged = seed + (plans or [])
        plans = []
        for p in merged:
            key=(p.get("target"), p.get("q"))
            if key not in seen and p.get("target") and p.get("q"):
                seen.add(key); plans.append(p)

    # ì˜¤íƒˆì ë³´ì •/ì •í•©ì„± í•„í„°/ë²•ë ¹í˜• ìš°ì„  íë¦„(ê¸°ì¡´) ìœ ì§€:contentReference[oaicite:2]{index=2}
    for p in plans or []:
        p["q"] = _sanitize_plan_q(query, p.get("q",""))
    plans = _filter_plans(query, plans)                      # ì‚¬ìš©ìì™€ í† í° êµì§‘í•© or must ìˆìœ¼ë©´ í†µê³¼:contentReference[oaicite:3]{index=3}

    good = [p for p in (plans or []) if _lawish(p.get("q",""))]  # ë²•/ë ¹/ê·œì¹™/ì¡°ë¡€/ì œnì¡° í¬í•¨:contentReference[oaicite:4]{index=4}
    if good:
        plans = good[:10]
    else:
        # LLM í›„ë³´(ì§ˆë¬¸ ê¸°ì¤€) â†’ ê·œì¹™ í´ë°±(ìµœì†Œí™”) ìˆœìœ¼ë¡œ êµ¬ì œ
        names = extract_law_candidates_llm(query) or []      # LLM ê¸°ë°˜ í›„ë³´ ì¶”ì¶œê¸°:contentReference[oaicite:5]{index=5}
        if not names:
            # ê·œì¹™ ë§µì€ í´ë°±ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
            names = [v for k, v in KEYWORD_TO_LAW.items() if k in (query or "")]
        if names:
            plans = [{"target":"law","q":n,"must":[n],"must_not":[]} for n in names][:6]
        else:
            kw = (extract_keywords_llm(query) or [])[:5]     # í‚¤ì›Œë“œ ë¹…ë¨ í´ë°±:contentReference[oaicite:6]{index=6}
            tmp=[]
            for i in range(len(kw)):
                for j in range(i+1, len(kw)):
                    tmp.append({"target":"law","q":f"{kw[i]} {kw[j]}","must":[kw[i],kw[j]],"must_not":[]})
            plans = tmp[:8]

    # (ì´í•˜ ì‹¤í–‰/ë¦¬ë­í¬/íŒ¨í‚¹ì€ ê¸°ì¡´ê³¼ ë™ì¼):contentReference[oaicite:7]{index=7}
    tried, err = [], []
    buckets = {"ë²•ë ¹":("law",[]), "í–‰ì •ê·œì¹™":("admrul",[]), "ìì¹˜ë²•ê·œ":("ordin",[]), "ì¡°ì•½":("trty",[])}
    for plan in plans:
        t, qx = plan["target"], plan["q"]
        tried.append(f"{t}:{qx}")
        if not qx.strip():
            err.append(f"{t}:(blank) dropped"); continue
        try:
            items, endpoint, e = _call_moleg_list(t, qx, num_rows=num_rows)  # MOLEG API í˜¸ì¶œ:contentReference[oaicite:8]{index=8}
            items = _filter_items_by_plan(query, items, plan)                # ì •í•©ì„± í•„í„° + ì •ë ¬:contentReference[oaicite:9]{index=9}
            if items:
                for label,(tt,arr) in buckets.items():
                    if t==tt: arr.extend(items)
            if e: err.append(f"{t}:{qx} â†’ {e}")
        except Exception as ex:
            err.append(f"{t}:{qx} â†’ {ex}")

    for label,(tt,arr) in buckets.items():
        if arr and tt=="law" and len(arr)>=2:
            arr = rerank_laws_with_llm(query, arr, top_k=8)  # LLM ë¦¬ë­ì»¤(ë§¥ë½ í•„í„°):contentReference[oaicite:10]{index=10}
        results[label] = {
            "items": arr, "endpoint": None,
            "error": "; ".join(err) if err else None,
            "debug": {"plans": plans, "tried": tried},
        }
    return results


# ìºì‹œëœ ë‹¨ì¼ ë²•ë ¹ ê²€ìƒ‰
@st.cache_data(show_spinner=False, ttl=300)
def search_law_data(query: str, num_rows: int = 10):
    return _call_moleg_list("law", query, num_rows=num_rows)

# ğŸ”½ ì—¬ê¸°ì— ì¶”ê°€ (search_law_data ì•„ë˜)

# ìì—°ì–´ â†’ ëŒ€í‘œ ë²•ë ¹ëª… í´ë°±ìš© ë§µ
KEYWORD_TO_LAW = {
    "ê°œì¸ì •ë³´": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
    "ëª…í•¨": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
    "ê³ ê°ì •ë³´": "ê°œì¸ì •ë³´ ë³´í˜¸ë²•",
    # === êµí†µì‚¬ê³  ê³„ì—´(ì¶”ê°€) ===
    "êµí†µì‚¬ê³ ": "êµí†µì‚¬ê³ ì²˜ë¦¬ íŠ¹ë¡€ë²•",
    "ê³¼ì‹¤ì¹˜ìƒ": "í˜•ë²•",          # LLMì´ 'í˜•ë²• ê³¼ì‹¤ì¹˜ìƒ'ìœ¼ë¡œ í™•ì¥
    "ê³¼ì†": "ë„ë¡œêµí†µë²•",
    "ìŒì£¼ìš´ì „": "ë„ë¡œêµí†µë²•",
    "ì£¼ì°¨ì¥": "ë„ë¡œêµí†µë²•",
}


SYSTEM_EXTRACT = """ë„ˆëŠ” í•œêµ­ ë²•ë ¹ëª…ì„ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ì•¼.
ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê´€ë ¨ 'ë²•ë ¹ëª…(ê³µì‹ëª…)' í›„ë³´ë¥¼ 1~3ê°œ ë½‘ì•„ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•´.
í˜•ì‹: {"laws":["ê°œì¸ì •ë³´ ë³´í˜¸ë²•","ê°œì¸ì •ë³´ ë³´í˜¸ë²• ì‹œí–‰ë ¹"]} ë‹¤ë¥¸ ë§ ê¸ˆì§€.
ë²•ë ¹ëª…ì´ ì• ë§¤í•˜ë©´ ê°€ì¥ ìœ ë ¥í•œ ê²ƒ 1ê°œë§Œ.
"""

# ===== ê°•ê±´í•œ í‚¤ì›Œë“œ ì¶”ì¶œê¸° (êµì²´) =====
@st.cache_data(show_spinner=False, ttl=300)
def extract_keywords_llm(q: str) -> list[str]:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 2~6ê°œë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì¶œí•œë‹¤.
    íŒŒì´í”„ë¼ì¸: LLM(í‘œì¤€) -> LLM(ì—„ê²© ì¬ì‹œë„) -> ê·œì¹™ ê¸°ë°˜ í´ë°±.
    """
    if not q or (client is None):
        return []

    def _parse_json_keywords(txt: str) -> list[str]:
        # ì½”ë“œíœìŠ¤/ì¡í…ìŠ¤íŠ¸ ì œê±° + JSON ë¸”ëŸ­ë§Œ ì¶”ì¶œ
        import re, json as _json
        t = (txt or "").strip()
        if "```" in t:
            m = re.search(r"```(?:json)?\s*([\s\S]*?)```", t)
            if m:
                t = m.group(1).strip()
        if not t.startswith("{"):
            m = re.search(r"\{[\s\S]*\}", t)
            if m:
                t = m.group(0)
        data = _json.loads(t)
        kws = [s.strip() for s in (data.get("keywords", []) or []) if s and s.strip()]
        # ê°„ë‹¨ ì •ê·œí™”/ì¤‘ë³µì œê±°
        seen, out = set(), []
        for k in kws:
            k2 = k[:20]  # ê³¼ë„í•œ ê¸¸ì´ ì»·
            if len(k2) >= 2 and k2 not in seen:
                seen.add(k2); out.append(k2)
        return out

    # 1) LLM 1ì°¨
    try:
        SYSTEM_KW = (
            "ë„ˆëŠ” í•œêµ­ ë²•ë¥  ì§ˆì˜ì˜ í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ì•¼. "
            "ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ê³ , ì„¤ëª…/ì½”ë“œë¸”ë¡/ì£¼ì„ì€ ê¸ˆì§€.\n"
            'í˜•ì‹: {"keywords":["í­í–‰","ìœ„í˜‘","ì •ë‹¹ë°©ìœ„","ê³¼ì‰ë°©ìœ„","ë³‘ì› ì´ì†¡"]}'
        )
        resp = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_KW},
                      {"role":"user","content": q.strip()}],
            temperature=0.0, max_tokens=96,
        )
        kws = _parse_json_keywords(resp.choices[0].message.content)
        if kws:
            return kws[:6]
    except Exception as e:
        st.session_state["_kw_extract_err1"] = str(e)

    # 2) LLM 2ì°¨(ì—„ê²© ì¬ì‹œë„)
    try:
        SYSTEM_KW_STRICT = (
            "JSON ONLY. No code fences, no commentary. "
            'Format: {"keywords":["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3"]} '
            "í‚¤ì›Œë“œëŠ” 2~6ê°œ, ëª…ì‚¬/ì§§ì€ êµ¬ ì¤‘ì‹¬."
        )
        resp2 = client.chat.completions.create(
            model=AZURE["deployment"],
            messages=[{"role":"system","content": SYSTEM_KW_STRICT},
                      {"role":"user","content": q.strip()}],
            temperature=0.0, max_tokens=96,
        )
        kws2 = _parse_json_keywords(resp2.choices[0].message.content)
        if kws2:
            return kws2[:6]
    except Exception as e:
        st.session_state["_kw_extract_err2"] = str(e)

    # 3) ê·œì¹™ ê¸°ë°˜ í´ë°±(LLM ì‹¤íŒ¨/ì°¨ë‹¨/ë„¤íŠ¸ì›Œí¬ ì˜ˆì™¸ ëŒ€ë¹„)
    def _rule_based_kw(text: str) -> list[str]:
        t = (text or "")
        # ë„ë©”ì¸ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë§¤ì¹­(ë“±ì¥í•˜ëŠ” ê²ƒë§Œ ì±„íƒ)
        WL = [
            "í­í–‰", "ìƒí•´", "í˜‘ë°•", "ìœ„í˜‘", "ì œì§€", "ì •ë‹¹ë°©ìœ„", "ê³¼ì‰ë°©ìœ„",
            "ì‚´ì¸", "ì‚¬ë§", "ë¶€ìƒ", "ì‘ê¸‰", "ë³‘ì›", "ì´ì†¡", "ê²½ì°°", "ì‹ ê³ ",
            "ê±´ì„¤í˜„ì¥", "í˜„ì¥ì†Œì¥", "ê·¼ë¡œì", "ì‚°ì—…ì•ˆì „", "ì¤‘ëŒ€ì¬í•´",
        ]
        hits = [w for w in WL if w in t]
        # ì¶”ê°€: ê°„ë‹¨ í•œê¸€ í† í°(2~6ì) ì¶”ì¶œë¡œ ë¹ˆì¹¸ ë§‰ê¸°
        import re
        tokens = re.findall(r"[ê°€-í£]{2,6}", t)
        # ê¸°ëŠ¥ì–´/ë¶ˆìš©ì–´(ê°„ë‹¨) ì œê±°
        STOP = {"ê·¸ë¦¬ê³ ","í•˜ì§€ë§Œ","ê·¸ëŸ¬ë‚˜","ë•Œë¬¸","ê²½ìš°","ê´€ë ¨","ë¬¸ì œ","ì–´ë–¤","ì–´ë–»ê²Œ","ìˆëŠ”ì§€"}
        tokens = [x for x in tokens if x not in STOP]
        # í•©ì¹˜ê³  ì¤‘ë³µ ì œê±°
        combined = hits + tokens
        seen, out = set(), []
        for k in combined:
            if k not in seen:
                seen.add(k); out.append(k)
        return out[:6]

    kws3 = _rule_based_kw(q)
    if kws3:
        # ë¹ˆ ê²°ê³¼ë¥¼ ìºì‹œì— ë‚¨ê¸°ì§€ ì•Šë„ë¡: ë¹ˆ ë¦¬ìŠ¤íŠ¸ë©´ ë°”ë¡œ ë°˜í™˜ ë§ê³  ì˜ˆì™¸ë¡œ í˜ë¦¬ê¸°
        return kws3

    # ìµœì¢…ì ìœ¼ë¡œë„ ë¹„ë©´ ìºì‹œ ë°©ì§€ìš© ë””ë²„ê·¸ íŒíŠ¸ë§Œ ë‚¨ê¸°ê³  ë¹ˆ ë¦¬ìŠ¤íŠ¸
    st.session_state["_kw_extract_debug"] = "all_stages_failed"
    return []


# ê°„ë‹¨ í´ë°±(ì˜ˆë¹„ â€” ë„êµ¬ ëª¨ë“œ ê¸°ë³¸ì´ë¯€ë¡œ ìµœì†Œí™”)
def find_law_with_fallback(user_query: str, num_rows: int = 10):
    laws, endpoint, err = search_law_data(user_query, num_rows=num_rows)
    if laws: return laws, endpoint, err, "primary"
    keyword_map = {"ì •ë‹¹ë°©ìœ„":"í˜•ë²•","ì „ì„¸":"ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•","ìƒê°€ì„ëŒ€ì°¨":"ìƒê°€ê±´ë¬¼ ì„ëŒ€ì°¨ë³´í˜¸ë²•","ê·¼ë¡œê³„ì•½":"ê·¼ë¡œê¸°ì¤€ë²•","í•´ê³ ":"ê·¼ë¡œê¸°ì¤€ë²•","ê°œì¸ì •ë³´":"ê°œì¸ì •ë³´ ë³´í˜¸ë²•","ì‚°ì¬":"ì‚°ì—…ì¬í•´ë³´ìƒë³´í—˜ë²•","ì´í˜¼":"ë¯¼ë²•"}
    text = (user_query or "")
    for k, law_name in keyword_map.items():
        if k in text:
            laws2, ep2, err2 = search_law_data(law_name, num_rows=num_rows)
            if laws2: return laws2, ep2, err2, f"fallback:{law_name}"
    return [], endpoint, err, "none"

def _append_message(role: str, content: str, **extra):
    
    txt = (content or "").strip()
    is_code_only = (txt.startswith("```") and txt.endswith("```"))
    if not txt or is_code_only:
        return
    msgs = st.session_state.get("messages", [])
    if msgs and isinstance(msgs[-1], dict) and msgs[-1].get("role")==role and (msgs[-1].get("content") or "").strip()==txt:
        # skip exact duplicate of the last message (role+content)
        return
    st.session_state.messages.append({"role": role, "content": txt, **extra})



def format_law_context(law_data: list[dict]) -> str:
    if not law_data: return "ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    rows = []
    for i, law in enumerate(law_data, 1):
        rows.append(
            f"{i}. {law['ë²•ë ¹ëª…']} ({law['ë²•ë ¹êµ¬ë¶„']})\n"
            f"   - ì†Œê´€ë¶€ì²˜: {law['ì†Œê´€ë¶€ì²˜ëª…']}\n"
            f"   - ì‹œí–‰ì¼ì: {law['ì‹œí–‰ì¼ì']} / ê³µí¬ì¼ì: {law['ê³µí¬ì¼ì']}\n"
            f"   - ë§í¬: {law['ë²•ë ¹ìƒì„¸ë§í¬'] or 'ì—†ìŒ'}"
        )
    return "\n\n".join(rows)

def animate_law_results(law_data: list[dict], delay: float = 1.0):
    if not law_data:
        st.info("ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    n = len(law_data)
    prog = st.progress(0.0, text="ê´€ë ¨ ë²•ë ¹ ë¯¸ë¦¬ë³´ê¸°")
    placeholder = st.empty()
    for i, law in enumerate(law_data, 1):
        with placeholder.container():
            st.markdown(
                f"""
                <div class='law-slide'>
                    <div style='font-weight:700'>ğŸ” {i}. {law['ë²•ë ¹ëª…']} <span style='opacity:.7'>({law['ë²•ë ¹êµ¬ë¶„']})</span></div>
                    <div style='margin-top:6px'>ì†Œê´€ë¶€ì²˜: {law['ì†Œê´€ë¶€ì²˜ëª…']}</div>
                    <div>ì‹œí–‰ì¼ì: {law['ì‹œí–‰ì¼ì']} / ê³µí¬ì¼ì: {law['ê³µí¬ì¼ì']}</div>
                    {f"<div style='margin-top:6px'><a href='{law['ë²•ë ¹ìƒì„¸ë§í¬']}' target='_blank'>ë²•ë ¹ ìƒì„¸ë³´ê¸°</a></div>" if law.get('ë²•ë ¹ìƒì„¸ë§í¬') else ''}
                </div>
                """,
                unsafe_allow_html=True,
            )
        prog.progress(i / n, text=f"ê´€ë ¨ ë²•ë ¹ ë¯¸ë¦¬ë³´ê¸° {i}/{n}")
        time.sleep(max(0.0, delay))
    prog.empty()

# =============================
# Azure í•¨ìˆ˜ì½œ(íˆ´) â€” ë˜í¼ & ìŠ¤í‚¤ë§ˆ & ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
# =============================
SUPPORTED_TARGETS = ["law", "admrul", "ordin", "trty"]

def tool_search_one(target: str, query: str, num_rows: int = 5):
    if target not in SUPPORTED_TARGETS:
        return {"error": f"unsupported target: {target}"}
    items, endpoint, err = _call_moleg_list(target, query, num_rows=num_rows)
    return {"target": target, "query": query, "endpoint": endpoint, "error": err, "items": items}

def tool_search_multi(queries: list, num_rows: int = 5):
    out = []
    for q in queries:
        t = q.get("target","law"); s = q.get("query","")
        out.append(tool_search_one(t, s, num_rows=num_rows))
    return out

TOOLS = [
    {
        "type":"function",
        "function":{
            "name":"search_one",
            "description":"MOLEG ëª©ë¡ APIì—ì„œ ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ë¥¼ ê²€ìƒ‰í•œë‹¤.",
            "parameters":{
                "type":"object",
                "properties":{
                    "target":{"type":"string","enum":SUPPORTED_TARGETS},
                    "query":{"type":"string"},
                    "num_rows":{"type":"integer","minimum":1,"maximum":10,"default":5}
                },
                "required":["target","query"]
            }
        }
    },
    {
        "type":"function",
        "function":{
            "name":"search_multi",
            "description":"ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬/ì§ˆì˜ì–´ë¥¼ í•œ ë²ˆì— ê²€ìƒ‰í•œë‹¤.",
            "parameters":{
                "type":"object",
                "properties":{
                    "queries":{
                        "type":"array",
                        "items":{
                            "type":"object",
                            "properties":{
                                "target":{"type":"string","enum":SUPPORTED_TARGETS},
                                "query":{"type":"string"}
                            },
                            "required":["target","query"]
                        }
                    },
                    "num_rows":{"type":"integer","minimum":1,"maximum":10,"default":5}
                },
                "required":["queries"]
            }
        }
    }
]

# ============================
# [GPT PATCH] app.py ì—°ê²°ë¶€
# ë¶™ì—¬ë„£ëŠ” ìœ„ì¹˜: client/AZURE/TOOLS ë“± ì¤€ë¹„ê°€ ëë‚œ "ì•„ë˜",
#               ì‚¬ì´ë“œë°”/ë ˆì´ì•„ì›ƒ ë Œë”ë§ì´ ì‹œì‘ë˜ê¸° "ìœ„"
# ============================

# 1) imports
from modules import AdviceEngine, Intent, classify_intent, pick_mode, build_sys_for_mode  # noqa: F401

# 2) ì—”ì§„ ìƒì„± (í•œ ë²ˆë§Œ)
engine = None
try:
    # ì•„ë˜ ê°ì²´ë“¤ì€ app.py ìƒë‹¨ì—ì„œ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # - client, AZURE, TOOLS
    # - safe_chat_completion
    # - tool_search_one, tool_search_multi
    # - prefetch_law_context, _summarize_laws_for_primer
    if client and AZURE and TOOLS:
        engine = AdviceEngine(
            client=client,
            model=AZURE["deployment"],
            tools=TOOLS,
            safe_chat_completion=safe_chat_completion,
            tool_search_one=tool_search_one,
            tool_search_multi=tool_search_multi,
            prefetch_law_context=prefetch_law_context,            # ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
            summarize_laws_for_primer=_summarize_laws_for_primer, # ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ
            temperature=0.2,
        )
except NameError:
    # ë§Œì•½ ìœ„ ê°ì²´ë“¤ì´ ì•„ì§ ì •ì˜ë˜ê¸° ì „ ìœ„ì¹˜ë¼ë©´,
    # ì´ íŒ¨ì¹˜ë¥¼ í•´ë‹¹ ì •ì˜ 'ì•„ë˜'ë¡œ ì˜®ê²¨ ë¶™ì´ì„¸ìš”.
    pass

# =============================
# í‚¤ì›Œë“œ ê¸°ë³¸ê°’/ìœ„ì ¯ í—¬í¼ (with st.sidebar: ìœ„ì— ë°°ì¹˜)
# =============================

# íƒ­ë³„ ê¸°ë³¸ í‚¤ì›Œë“œ 1ê°œ(ì—†ìœ¼ë©´ ì²« í•­ëª© ì‚¬ìš©)
DEFAULT_KEYWORD = {
    "ë²•ë ¹": "ê°œì •",
    "í–‰ì •ê·œì¹™": "ê°œì •",
    "ìì¹˜ë²•ê·œ": "ê°œì •",
    "ì¡°ì•½": "ë¹„ì¤€",
    "íŒë¡€": "ëŒ€ë²•ì›",
    "í—Œì¬": "ìœ„í—Œ",
    "í•´ì„ë¡€": "ìœ ê¶Œí•´ì„",
    "ìš©ì–´/ë³„í‘œ": "ì •ì˜",   # â† 'ìš©ì–´' ëŒ€ì‹  'ì •ì˜'ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ê¶Œì¥
}

def one_default(options, prefer=None):
    """ì˜µì…˜ ëª©ë¡ì—ì„œ ê¸°ë³¸ìœ¼ë¡œ 1ê°œë§Œ ì„ íƒí•´ ë°˜í™˜"""
    if not options:
        return []
    if prefer and prefer in options:
        return [prefer]
    return [options[0]]

# st_tagsê°€ ìˆìœ¼ë©´ íƒœê·¸ ìœ„ì ¯, ì—†ìœ¼ë©´ multiselectë¡œ ë™ì‘
try:
    from streamlit_tags import st_tags
    def kw_input(label, options, key, tab_name=None):
        prefer = DEFAULT_KEYWORD.get(tab_name)
        return st_tags(
            label=label,
            text="ì‰¼í‘œ(,) ë˜ëŠ” Enterë¡œ ì¶”ê°€/ì‚­ì œ",
            value=one_default(options, prefer),   # âœ… ê¸°ë³¸ 1ê°œë§Œ
            suggestions=options,
            maxtags=len(options),
            key=key,
        )
except Exception:
    def kw_input(label, options, key, tab_name=None):
        prefer = DEFAULT_KEYWORD.get(tab_name)
        return st.multiselect(
            label=label,
            options=options,
            default=one_default(options, prefer), # âœ… ê¸°ë³¸ 1ê°œë§Œ
            key=key,
            help="í•„ìš”í•œ í‚¤ì›Œë“œë§Œ ì¶”ê°€ë¡œ ì„ íƒí•˜ì„¸ìš”.",
        )

# =============================
# Sidebar: ë§í¬ ìƒì„±ê¸° (ë¬´ì¸ì¦)
# =============================
with st.sidebar:
    # --- ì‚¬ì´ë“œë°”: ìƒˆ ëŒ€í™” ë²„íŠ¼(ë§í¬ ìƒì„±ê¸° ìœ„) ---
    if st.button("ğŸ†• ìƒˆ ëŒ€í™”", type="primary", use_container_width=True, key="__btn_new_chat__"):
        for k in ("messages", "_last_user_nonce", "_pending_user_q", "_pending_user_nonce", "_last_ans_hash"):
            st.session_state.pop(k, None)
        st.session_state["_clear_input"] = True
        st.rerun()

    st.header("ğŸ”— ë§í¬ ìƒì„±ê¸° (ë¬´ì¸ì¦)")
    tabs = st.tabs(["ë²•ë ¹", "í–‰ì •ê·œì¹™", "ìì¹˜ë²•ê·œ", "ì¡°ì•½", "íŒë¡€", "í—Œì¬", "í•´ì„ë¡€", "ìš©ì–´/ë³„í‘œ"])

    # persist/restore active sidebar tab across reruns
    st.markdown("""
<script>
(function(){
  const KEY = "left_sidebar_active_tab";
  function labelOf(btn){ return (btn?.innerText || btn?.textContent || "").trim(); }
  function restore(){
    const want = sessionStorage.getItem(KEY);
    if(!want) return false;
    const btns = Array.from(window.parent.document.querySelectorAll('[data-testid="stSidebar"] [role="tablist"] button[role="tab"]'));
    if(btns.length === 0) return false;
    const match = btns.find(b => labelOf(b) === want);
    if(!match) return false;
    if(match.getAttribute('aria-selected') !== 'true'){ match.click(); }
    return true;
  }
  function bind(){
    const root = window.parent.document.querySelector('[data-testid="stSidebar"]');
    if(!root) return;
    // Save when user clicks a tab
    root.addEventListener('click', (e)=>{
      const b = e.target.closest('button[role="tab"]');
      if(b){ sessionStorage.setItem(KEY, labelOf(b)); }
    }, true);
    // Keep trying to restore selection until ready
    const tid = setInterval(()=>{ if(restore()) clearInterval(tid); }, 100);
    setTimeout(()=>clearInterval(tid), 4000);
    // Also restore when DOM changes (e.g., reruns)
    new MutationObserver(()=>restore()).observe(root, {subtree:true, childList:true, attributes:true});
  }
  window.addEventListener('load', bind, {once:true});
  setTimeout(bind, 0);
})();
</script>
""", unsafe_allow_html=True)

    # ê³µí†µ ì¶”ì²œ í”„ë¦¬ì…‹(ëª¨ë‘ 1ê°œë§Œ ê¸°ë³¸ ì„ íƒë˜ë„ë¡ kw_input + DEFAULT_KEYWORD í™œìš©)
    adm_suggest    = cached_suggest_for_tab("admrul")
    ordin_suggest  = cached_suggest_for_tab("ordin")
    trty_suggest   = cached_suggest_for_tab("trty")
    case_suggest   = cached_suggest_for_tab("prec")
    cc_suggest     = cached_suggest_for_tab("cc")
    interp_suggest = cached_suggest_for_tab("expc")
    term_suggest   = ["ì •ì˜", "ìš©ì–´", "ë³„í‘œ", "ì„œì‹"]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë²•ë ¹
    with tabs[0]:
        law_name = st.text_input("ë²•ë ¹ëª…", value="ë¯¼ë²•", key="sb_law_name")
        # ë²•ë ¹ëª… ê¸°ë°˜ ì¶”ì²œ
        law_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)",
                            cached_suggest_for_law(law_name),
                            key="sb_law_keys",
                            tab_name="ë²•ë ¹")

        if st.button("ë²•ë ¹ ìƒì„¸ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_law"):
            url = hangul_law_with_keys(law_name, law_keys) if law_keys else hangul_by_name("ë²•ë ¹", law_name)
            st.session_state["gen_law"] = {"url": url, "kind": "law", "q": law_name}

        if "gen_law" in st.session_state:
            d = st.session_state["gen_law"]
            present_url_with_fallback(d["url"], d["kind"], d["q"], label_main="ìƒˆ íƒ­ì—ì„œ ì—´ê¸°")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í–‰ì •ê·œì¹™
    with tabs[1]:
        adm_name = st.text_input("í–‰ì •ê·œì¹™ëª…", value="ìˆ˜ì…í†µê´€ì‚¬ë¬´ì²˜ë¦¬ì—ê´€í•œê³ ì‹œ", key="sb_adm_name")
        dept     = st.selectbox("ì†Œê´€ ë¶€ì²˜(ì„ íƒ)", MINISTRIES, index=0, key="sb_adm_dept")
        adm_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", adm_suggest, key="sb_adm_keys", tab_name="í–‰ì •ê·œì¹™")

        colA, colB = st.columns(2)
        with colA: issue_no = st.text_input("ê³µí¬ë²ˆí˜¸(ì„ íƒ)", value="", key="sb_adm_no")
        with colB: issue_dt = st.text_input("ê³µí¬ì¼ì(YYYYMMDD, ì„ íƒ)", value="", key="sb_adm_dt")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("í–‰ì •ê·œì¹™ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_adm"):
                url = hangul_admrul_with_keys(adm_name, issue_no, issue_dt) if (issue_no and issue_dt) else hangul_by_name("í–‰ì •ê·œì¹™", adm_name)
                st.session_state["gen_adm"] = {"url": url, "kind": "admrul", "q": adm_name}
        with col2:
            if st.button("í–‰ì •ê·œì¹™(ë¶€ì²˜/í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_adm_dept"):
                keys = " ".join(adm_keys) if adm_keys else ""
                q = " ".join([x for x in [adm_name,
                                          (dept if dept and dept != MINISTRIES[0] else ""),
                                          keys] if x])
                url = build_fallback_search("admrul", q)
                st.session_state["gen_adm_dept"] = {"url": url, "kind": "admrul", "q": q}

        if "gen_adm" in st.session_state:
            d = st.session_state["gen_adm"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_adm_dept" in st.session_state:
            d = st.session_state["gen_adm_dept"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìì¹˜ë²•ê·œ
    with tabs[2]:
        ordin_name = st.text_input("ìì¹˜ë²•ê·œëª…", value="ì„œìš¸íŠ¹ë³„ì‹œê²½ê´€ì¡°ë¡€", key="sb_ordin_name")
        local_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", ordin_suggest, key="sb_local_keys", tab_name="ìì¹˜ë²•ê·œ")

        colA, colB = st.columns(2)
        with colA: ordin_no = st.text_input("ê³µí¬ë²ˆí˜¸(ì„ íƒ)", value="", key="sb_ordin_no")
        with colB: ordin_dt = st.text_input("ê³µí¬ì¼ì(YYYYMMDD, ì„ íƒ)", value="", key="sb_ordin_dt")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ìì¹˜ë²•ê·œ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_ordin"):
                url = hangul_ordin_with_keys(ordin_name, ordin_no, ordin_dt) if (ordin_no and ordin_dt) else hangul_by_name("ìì¹˜ë²•ê·œ", ordin_name)
                st.session_state["gen_ordin"] = {"url": url, "kind": "ordin", "q": ordin_name}
        with col2:
            if st.button("ìì¹˜ë²•ê·œ(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_ordin_kw"):
                q = " ".join([ordin_name] + (local_keys or []))
                url = build_fallback_search("ordin", q)
                st.session_state["gen_ordin_kw"] = {"url": url, "kind": "ordin", "q": q}

        if "gen_ordin" in st.session_state:
            d = st.session_state["gen_ordin"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_ordin_kw" in st.session_state:
            d = st.session_state["gen_ordin_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¡°ì•½
    with tabs[3]:
        trty_no = st.text_input("ì¡°ì•½ ë²ˆí˜¸", value="2193", key="sb_trty_no")
        eff_dt  = st.text_input("ë°œíš¨ì¼ì(YYYYMMDD)", value="20140701", key="sb_trty_eff")
        trty_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", trty_suggest, key="sb_trty_keys", tab_name="ì¡°ì•½")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ì¡°ì•½ ìƒì„¸ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_trty"):
                url = hangul_trty_with_keys(trty_no, eff_dt)
                st.session_state["gen_trty"] = {"url": url, "kind": "trty", "q": trty_no}
        with col2:
            if st.button("ì¡°ì•½(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_trty_kw"):
                q = " ".join([trty_no] + (trty_keys or [])) if trty_no else " ".join(trty_keys or [])
                url = build_fallback_search("trty", q)
                st.session_state["gen_trty_kw"] = {"url": url, "kind": "trty", "q": q}

        if "gen_trty" in st.session_state:
            d = st.session_state["gen_trty"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_trty_kw" in st.session_state:
            d = st.session_state["gen_trty_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íŒë¡€
    with tabs[4]:
        case_no = st.text_input("ì‚¬ê±´ë²ˆí˜¸(ì˜ˆ: 2010ë‹¤52349)", value="2010ë‹¤52349", key="sb_case_no")
        case_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", case_suggest, key="sb_case_keys", tab_name="íŒë¡€")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ëŒ€ë²•ì› íŒë¡€ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_prec"):
                url = build_scourt_link(case_no)
                st.session_state["gen_prec"] = {"url": url, "kind": "prec", "q": case_no}
        with col2:
            if st.button("íŒë¡€(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_prec_kw"):
                q = " ".join([case_no] + (case_keys or [])) if case_no else " ".join(case_keys or [])
                url = build_fallback_search("prec", q)
                st.session_state["gen_prec_kw"] = {"url": url, "kind": "prec", "q": q}

        if "gen_prec" in st.session_state:
            d = st.session_state["gen_prec"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_prec_kw" in st.session_state:
            d = st.session_state["gen_prec_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—Œì¬
    with tabs[5]:
        cc_q = st.text_input("í—Œì¬ ì‚¬ê±´/í‚¤ì›Œë“œ", value="2022í—Œë§ˆ1312", key="sb_cc_q")
        cc_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", cc_suggest, key="sb_cc_keys", tab_name="í—Œì¬")

        if st.button("í—Œì¬ ê²€ìƒ‰ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_cc"):
            q = " ".join([cc_q] + (cc_keys or [])) if cc_q else " ".join(cc_keys or [])
            url = build_fallback_search("cc", q)
            st.session_state["gen_cc"] = {"url": url, "kind": "cc", "q": q}

        if "gen_cc" in st.session_state:
            d = st.session_state["gen_cc"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•´ì„ë¡€
    with tabs[6]:
        colA, colB = st.columns(2)
        with colA:
            expc_id = st.text_input("í•´ì„ë¡€ ID", value="313107", key="sb_expc_id")
            if st.button("í•´ì„ë¡€ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_expc"):
                url = expc_public_by_id(expc_id)
                st.session_state["gen_expc"] = {"url": url, "kind": "expc", "q": expc_id}
        with colB:
            interp_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", interp_suggest, key="sb_interp_keys", tab_name="í•´ì„ë¡€")
            if st.button("í•´ì„ë¡€(í‚¤ì›Œë“œ) ê²€ìƒ‰ ë§í¬", key="sb_btn_expc_kw"):
                q = " ".join([expc_id] + (interp_keys or [])) if expc_id else " ".join(interp_keys or [])
                url = build_fallback_search("expc", q)
                st.session_state["gen_expc_kw"] = {"url": url, "kind": "expc", "q": q}

        if "gen_expc" in st.session_state:
            d = st.session_state["gen_expc"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_expc_kw" in st.session_state:
            d = st.session_state["gen_expc_kw"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìš©ì–´/ë³„í‘œ
    with tabs[7]:
        col1, col2 = st.columns(2)
        with col1:
            term_id   = st.text_input("ìš©ì–´ ID", value="100034", key="sb_term_id")
            term_keys = kw_input("í‚¤ì›Œë“œ(ìë™ ì¶”ì²œ)", term_suggest, key="sb_term_keys", tab_name="ìš©ì–´/ë³„í‘œ")
            if st.button("ìš©ì–´ì‚¬ì „ ë§í¬ ë§Œë“¤ê¸°", key="sb_btn_term"):
                url = f"https://www.law.go.kr/LSW/termInfoR.do?termSeq={up.quote(term_id)}"
                st.session_state["gen_term"] = {"url": url, "kind": "term", "q": term_id}
        with col2:
            flseq = st.text_input("ë³„í‘œÂ·ì„œì‹ íŒŒì¼ ID", value="110728887", key="sb_flseq")
            if st.button("ë³„í‘œ/ì„œì‹ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", key="sb_btn_file"):
                url = licbyl_file_download(flseq)
                st.session_state["gen_file"] = {"url": url, "kind": "file", "q": flseq}

        if "gen_term" in st.session_state:
            d = st.session_state["gen_term"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])
        if "gen_file" in st.session_state:
            d = st.session_state["gen_file"]
            present_url_with_fallback(d["url"], d["kind"], d["q"])

# 1) pending â†’ messages ë¨¼ì € ì˜®ê¹€
user_q = _push_user_from_pending()

# capture the nonce associated with this pending input (if any)
# === ì§€ê¸ˆ í„´ì´ 'ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ëŸ°'ì¸ì§€ ì—¬ë¶€ (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ í‘œì‹œ/ìˆ¨ê¹€ì— ì‚¬ìš©)
ANSWERING = bool(user_q)
st.session_state["__answering__"] = ANSWERING

# 2) ëŒ€í™” ì‹œì‘ ì—¬ë¶€ ê³„ì‚° (êµì²´ëœ í•¨ìˆ˜)
chat_started = _chat_started()

# chat_started ê³„ì‚° ì§í›„ì— ì¶”ê°€
st.markdown(f"""
<script>
document.body.classList.toggle('chat-started', {str(chat_started).lower()});
document.body.classList.toggle('answering', {str(ANSWERING).lower()});
</script>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* âœ… í¬ìŠ¤íŠ¸-ì±— UI(ì—…ë¡œë”+ì…ë ¥í¼)ëŠ” 'ë‹µë³€ ìƒì„± ì¤‘'ì—ë§Œ ìˆ¨ê¹€ */
body.answering .post-chat-ui{ margin-top: 8px; }

/* âœ… ê¸°ì¡´ chatbar ì»´í¬ë„ŒíŠ¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì™„ì „ ìˆ¨ê¹€ */
#chatbar-fixed { display: none !important; }
/* ë‹µë³€ ì¤‘ì¼ ë•Œë§Œ í•˜ë‹¨ ì—¬ë°± ì¶•ì†Œ */
body.answering .block-container { 
    padding-bottom: calc(var(--chat-gap) + 24px) !important; 
}
</style>
""", unsafe_allow_html=True)

# âœ… PRE-CHAT: ì™„ì „ ì¤‘ì•™(ë·°í¬íŠ¸ ê¸°ì¤€) + ì—¬ë°± ì œê±°
if not chat_started:
    st.markdown("""
    <style>
      /* í”„ë¦¬ì±—: ìš°ì¸¡ íŒ¨ë„ë§Œ ìˆ¨ê¸°ê³ , ìŠ¤í¬ë¡¤ì„ ì ê°€ ìƒë‹¨ ê³ ì • */
      #search-flyout{ display:none !important; }
      html, body{ height:100%; overflow-y:hidden !important; }
      .main > div:first-child{ height:100vh !important; }
      .block-container{ min-height:100vh !important; padding-top:12px !important; padding-bottom:0 !important; }
      /* ì „ì—­ ê°€ìš´ë° ì •ë ¬ ê·œì¹™ì´ ìˆì–´ë„ í”„ë¦¬ì±—ì—ì„  íˆì–´ë¡œë¥¼ 'ìœ„ì—ì„œë¶€í„°' ë°°ì¹˜ */
      .center-hero{ min-height:auto !important; display:block !important; }
    </style>
    <script>
    (function(){
      try{ history.scrollRestoration='manual'; }catch(e){}
      const up=()=>{ window.scrollTo(0,0); if(document.activeElement) document.activeElement.blur(); };
      up(); setTimeout(up,0); setTimeout(up,50);
      document.addEventListener('focusin', up, true);
      new MutationObserver(up).observe(document.body, {subtree:true, childList:true});
    })();
    </script>
    """, unsafe_allow_html=True)

    st.markdown("""
    <style>
      /* ìš°ì¸¡ íŒ¨ë„ë§Œ ìˆ¨ê¹€ */
      #search-flyout{ display:none !important; }

      /* â›³ï¸ í”„ë¦¬ì±—: ìŠ¤í¬ë¡¤ ìƒê¸°ì§€ ì•Šê²Œ ì ê·¸ê³  ìƒë‹¨ ê³ ì • */
      html, body{ height:100%; overflow-y:hidden !important; }
      .main > div:first-child{ height:100vh !important; }              /* Streamlit ë£¨íŠ¸ */
      .block-container{
        min-height:100vh !important;   /* í™”ë©´ë§Œí¼ë§Œ */
        padding-top:12px !important;
        padding-bottom:0 !important;   /* ë°”ë‹¥ ì—¬ë°± ì œê±° */
        margin-left:auto !important; margin-right:auto !important;
      }
    </style>
    <script>
    (function(){
      try{ history.scrollRestoration='manual'; }catch(e){}
      const up=()=>{ window.scrollTo(0,0); if(document.activeElement) document.activeElement.blur(); };
      up(); setTimeout(up,0); setTimeout(up,50);    // ìë™ í¬ì»¤ìŠ¤ ëŒ€ë¹„
      document.addEventListener('focusin', up, true);
      new MutationObserver(up).observe(document.body, {subtree:true, childList:true});
    })();
    </script>            
               
    """, unsafe_allow_html=True)

    render_pre_chat_center()
    st.stop()
    
else:
    st.markdown("""
    <style>
      /* ì±„íŒ… ì‹œì‘ í›„: ìŠ¤í¬ë¡¤ ì •ìƒ ë³µì› */
      html, body{ overflow-y:auto !important; }
      .main > div:first-child{ height:auto !important; }
      .block-container{ min-height:auto !important; }
    </style>
    """, unsafe_allow_html=True)

    st.markdown("""
    <style>
      /* ğŸ“Œ ì±„íŒ… ì‹œì‘ í›„ì—ëŠ” ì •ìƒ ìŠ¤í¬ë¡¤ */
      html, body{ overflow-y:auto !important; }
      .block-container{ min-height:auto !important; }
    </style>
    """, unsafe_allow_html=True)

    # ... ê¸°ì¡´ ë Œë”ë§ ê³„ì†


# ğŸ¯ ëŒ€í™” ì „ì—ëŠ” ìš°ì¸¡ íŒ¨ë„ ìˆ¨ê¸°ê³ , ì—¬ë°±ì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ì™„ì „ ì¤‘ì•™ ì •ë ¬
if not chat_started:
    st.markdown("""
    <style>
      /* hide right rail before first message */
      #search-flyout { display: none !important; }
      /* remove right gutter so hero sits dead-center */
      @media (min-width:1280px) { .block-container { padding-right: 0 !important; } }
      /* bottom padding í¬ê²Œ ì¤„ì—¬ì„œ í™”ë©´ ì •ì¤‘ì•™ì— ì˜¤ë„ë¡ */
      .block-container { padding-bottom: 64px !important; }
      /* hero ë†’ì´ ì‚´ì§ ì¤„ì—¬ ìœ„/ì•„ë˜ ê· í˜• */
      .center-hero { min-height: calc(100vh - 160px) !important; }
    </style>
    """, unsafe_allow_html=True)

# 3) í™”ë©´ ë¶„ê¸°
if not chat_started:
    render_pre_chat_center()   # ì¤‘ì•™ íˆì–´ë¡œ + ì¤‘ì•™ ì—…ë¡œë”
    st.stop()
else:
    # ğŸ”§ ëŒ€í™” ì‹œì‘ í›„ì—ëŠ” ì²¨ë¶€íŒŒì¼ ë°•ìŠ¤ë¥¼ ë Œë”ë§í•˜ì§€ ì•ŠìŒ (ì™„ì „íˆ ì œê±°)
    # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ì—…ë¡œë” ìˆ¨ê¹€ (ë Œë” ìì²´ ìƒëµ)
    # if not ANSWERING:
    #     render_bottom_uploader()   # í•˜ë‹¨ ê³ ì • ì—…ë¡œë” - ì£¼ì„ ì²˜ë¦¬
    pass

# === ëŒ€í™” ì‹œì‘ í›„: ìš°ì¸¡ ë ˆì¼ì„ í”¼í•´ì„œ ë°°ì¹˜(ì¹¨ë²” ë°©ì§€) ===
# ----- RIGHT FLYOUT: align once to the question box, stable -----
st.markdown("""
<style>
  :root{
    --flyout-width: 360px;   /* ìš°ì¸¡ íŒ¨ë„ í­ */
    --flyout-gap:   80px;    /* ë³¸ë¬¸(ë‹µë³€ì˜ì—­)ê³¼ì˜ ê°€ë¡œ ê°„ê²© */
  }

  /* ë³¸ë¬¸ì´ ìš°ì¸¡ íŒ¨ë„ì„ í”¼í•´ ë°°ì¹˜ë˜ë„ë¡ ì—¬ë°± í™•ë³´ */
  @media (min-width:1280px){
    .block-container{
      padding-right: calc(var(--flyout-width) + var(--flyout-gap)) !important;
    }
  }

  /* ====== íŒ¨ë„ ë°°ì¹˜ ëª¨ë“œ ======
     (A) í™”ë©´ ê³ ì •(ìŠ¤í¬ë¡¤í•´ë„ í•­ìƒ ë³´ì„) â†’ position: fixed (ê¸°ë³¸)
     (B) ë”°ë¼ì˜¤ì§€ ì•Šê²Œ(ë³¸ë¬¸ê³¼ í•¨ê»˜ ìœ„ë¡œ ì˜¬ë¼ê°€ë„ë¡) â†’ position: sticky ë¡œ êµì²´
     ì›í•˜ëŠ” ìª½ í•œ ì¤„ë§Œ ì“°ì„¸ìš”.
  */
  @media (min-width:1280px){
    #search-flyout{
      position: fixed !important;                 /* â† A) í™”ë©´ ê³ ì • */
      /* position: sticky !important;             /* â† B) ë”°ë¼ì˜¤ì§€ ì•Šê²Œ: ì´ ì¤„ë¡œ êµì²´ */
      top: var(--flyout-top, 120px) !important;   /* JSê°€ í•œ ë²ˆ ê³„ì‚°í•´ ë„£ìŒ */
      right: 24px !important;
      left: auto !important; bottom: auto !important;

      width: var(--flyout-width) !important;
      max-width: 38vw !important;
      max-height: calc(100vh - var(--flyout-top,120px) - 24px) !important;
      overflow: auto !important;
      z-index: 58 !important;                     /* ì—…ë¡œë”(60), ì…ë ¥ì°½(70)ë³´ë‹¤ ë‚®ê²Œ */
    }
  }

  /* ëª¨ë°”ì¼/ì¢ì€ í™”ë©´ì€ ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì„œ íë¦„ */
  @media (max-width:1279px){
    #search-flyout{ position: static !important; max-height:none !important; overflow:visible !important; }
    .block-container{ padding-right: 0 !important; }
  }
</style>

<script>
(() => {
  // ì§ˆë¬¸ ì…ë ¥ ìœ„ì¹˜ë¥¼ "í•œ ë²ˆë§Œ" ì½ì–´ì„œ --flyout-top ì„ ì„¤ì •
  const CANDIDATES = [
    '#chatbar-fixed',
    'section[data-testid="stChatInput"]',
    '.block-container textarea'
  ];
  let done = false;

  function alignOnce(){
    if (done) return;
    const fly = document.querySelector('#search-flyout');
    if (!fly) return;

    let target = null;
    for (const sel of CANDIDATES){
      target = document.querySelector(sel);
      if (target) break;
    }
    if (!target) return;

    const r = target.getBoundingClientRect();       // viewport ê¸°ì¤€
    const top = Math.max(12, Math.round(r.top));
    document.documentElement.style.setProperty('--flyout-top', top + 'px');
    done = true;  // í•œ ë²ˆë§Œ
  }

  // 1) ì²« ë Œë” ì§í›„
  window.addEventListener('load', () => setTimeout(alignOnce, 0));

  // 2) ëŒ€ìƒì´ ëŠ¦ê²Œ ìƒê²¨ë„ í•œ ë²ˆë§Œ ì •ë ¬
  const mo = new MutationObserver(() => alignOnce());
  mo.observe(document.body, {childList: true, subtree: true});
  (function stopWhenDone(){ if (done) mo.disconnect(); requestAnimationFrame(stopWhenDone); })();

  // 3) ì°½ í¬ê¸° ë³€ê²½ ì‹œ í•œ ë²ˆ ì¬ì •ë ¬
  window.addEventListener('resize', () => { done = false; alignOnce(); });
})();
</script>
""", unsafe_allow_html=True)




with st.container():
    st.session_state['_prev_assistant_txt'] = ''  # reset per rerun
    for i, m in enumerate(st.session_state.messages):
        # --- Hero above the most recent user question (shows during loading & after) ---
        if '_latest_user_index' not in st.session_state:
            _msgs = st.session_state.get('messages', [])
            _latest = None
            for _idx in range(len(_msgs)-1, -1, -1):
                _mm = _msgs[_idx]
                if isinstance(_mm, dict) and _mm.get('role') == 'user' and (_mm.get('content') or '').strip():
                    _latest = _idx
                    break
            st.session_state['_latest_user_index'] = _latest


        # --- UI dedup guard: skip if same assistant content as previous ---
        if isinstance(m, dict) and m.get('role')=='assistant':
            _t = (m.get('content') or '').strip()
            if '_prev_assistant_txt' not in st.session_state:
                st.session_state['_prev_assistant_txt'] = ''
            if _t and _t == st.session_state.get('_prev_assistant_txt',''):
                continue
            st.session_state['_prev_assistant_txt'] = _t
        role = m.get("role")
        content = (m.get("content") or "")
        if role == "assistant" and not content.strip():
            continue  # âœ… ë‚´ìš©ì´ ë¹„ë©´ ë§í’ì„  ìì²´ë¥¼ ë§Œë“¤ì§€ ì•ŠìŒ
        # If this is the latest user bubble, show the shared hero just above it
        if (role == "user") and (st.session_state.get('_latest_user_index') == i):
            st.markdown('<div class="hero-in-chat">' + HERO_HTML + '</div>', unsafe_allow_html=True)


        with st.chat_message(role):
            if role == "assistant":
                render_bubble_with_copy(content, key=f"past-{i}")
                if m.get("law"):
                    with st.expander("ğŸ“‹ ì´ í„´ì—ì„œ ì°¸ê³ í•œ ë²•ë ¹ ìš”ì•½"):
                        for j, law in enumerate(m["law"], 1):
                            st.write(f"**{j}. {law['ë²•ë ¹ëª…']}** ({law['ë²•ë ¹êµ¬ë¶„']})  | ì‹œí–‰ {law['ì‹œí–‰ì¼ì']}  | ê³µí¬ {law['ê³µí¬ì¼ì']}")
                            if law.get("ë²•ë ¹ìƒì„¸ë§í¬"):
                                st.write(f"- ë§í¬: {law['ë²•ë ¹ìƒì„¸ë§í¬']}")
            else:
                st.markdown(content)


# âœ… ë‹µë³€ ë§í’ì„  ë°”ë¡œ ì•„ë˜ì— ì…ë ¥/ì—…ë¡œë” ë¶™ì´ê¸° (ë‹µë³€ ìƒì„± ì¤‘ì´ ì•„ë‹ ë•Œë§Œ)
if chat_started and not st.session_state.get("__answering__", False):
    render_post_chat_simple_ui()

# âœ… ë©”ì‹œì§€ ë£¨í”„ ë°”ë¡œ ì•„ë˜(ì´ë¯¸ _inject_right_rail_css() ë‹¤ìŒ ì¶”ì²œ) â€” í•­ìƒ í˜¸ì¶œ
def _current_q_and_answer():
    msgs = st.session_state.get("messages", [])
    last_q = next((m for m in reversed(msgs) if m.get("role")=="user" and (m.get("content") or "").strip()), None)
    last_a = next((m for m in reversed(msgs) if m.get("role")=="assistant" and (m.get("content") or "").strip()), None)
    return (last_q or {}).get("content",""), (last_a or {}).get("content","")

# ğŸ”½ ëŒ€í™”ê°€ ì‹œì‘ëœ ë’¤ì—ë§Œ ìš°ì¸¡ íŒ¨ë„ ë…¸ì¶œ
# âœ… ë¡œë”©(ìŠ¤íŠ¸ë¦¬ë°) ì¤‘ì—ëŠ” íŒ¨ë„ì„ ë Œë”ë§í•˜ì§€ ì•ŠìŒ
if chat_started and not st.session_state.get("__answering__", False):
    q_for_panel, ans_for_panel = _current_q_and_answer()
    hints = extract_law_names_from_answer(ans_for_panel) if ans_for_panel else None
    render_search_flyout(q_for_panel or user_q, num_rows=8, hint_laws=hints, show_debug=SHOW_SEARCH_DEBUG)

# ===============================
# ì¢Œìš° ë¶„ë¦¬ ë ˆì´ì•„ì›ƒ: ì™¼ìª½(ë‹µë³€) / ì˜¤ë¥¸ìª½(í†µí•©ê²€ìƒ‰)
# ===============================\n
if user_q:
    # --- streaming aggregator v2: keep deltas for preview, but FINAL wins ---
    stream_box = None
    deltas_only = ""
    final_payload = ""
    collected_laws = []

    if client and AZURE:
        stream_box = st.empty()

    try:
        if stream_box is not None:
            stream_box.markdown("_AIê°€ ì§ˆì˜ë¥¼ í•´ì„í•˜ê³ , ë²•ì œì²˜ DBë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤._")

        for kind, payload, law_list in ask_llm_with_tools(user_q, num_rows=5, stream=True):
            if kind == "delta":
                if payload:
                    deltas_only += payload
                    if SHOW_STREAM_PREVIEW and stream_box is not None:
                        stream_box.markdown(_normalize_text(deltas_only[-1500:]))
            elif kind == "final":
                final_payload  = (payload or "")
                collected_laws = law_list or []
                break

    except Exception as e:
        # ì˜ˆì™¸ ì‹œ í´ë°±
        laws, ep, err, mode = find_law_with_fallback(user_q, num_rows=10)
        collected_laws = laws
        law_ctx = format_law_context(laws)
        title = "ë²•ë¥  ìë¬¸ ë©”ëª¨"
        base_text = f"{title}\n\n{law_ctx}\n\n(ì˜¤ë¥˜: {e})"
    else:
        # ì •ìƒ ê²½ë¡œ: finalì´ ìˆìœ¼ë©´ final, ì—†ìœ¼ë©´ delta ëˆ„ì  ì‚¬ìš©
        base_text = (final_payload.strip() or deltas_only)

    # --- Postprocess & de-dup ---
    final_text = apply_final_postprocess(base_text, collected_laws)
    final_text = _dedupe_repeats(final_text)

    # --- seatbelt: skip if same answer already stored this turn ---
    _ans_hash = _hash_text(final_text)
    if st.session_state.get('_last_ans_hash') == _ans_hash:
        final_text = ""
    else:
        st.session_state['_last_ans_hash'] = _ans_hash

    if final_text.strip():
        # --- per-turn nonce guard: allow only one assistant append per user turn ---
        _nonce = st.session_state.get('current_turn_nonce') or st.session_state.get('_pending_user_nonce')
        _done = st.session_state.get('_nonce_done', {})
        if not (_nonce and _done.get(_nonce)):
            _append_message('assistant', final_text, law=collected_laws)
            if _nonce:
                _done[_nonce] = True
                st.session_state['_nonce_done'] = _done
            st.session_state['last_q'] = user_q
            st.session_state.pop('_pending_user_q', None)
            st.session_state.pop('_pending_user_nonce', None)
            st.rerun()

    # í”„ë¦¬ë·° ì»¨í…Œì´ë„ˆ ë¹„ìš°ê¸°
    if stream_box is not None:
        try:
            stream_box.empty()
        except Exception:
            pass

# (moved) post-chat UI is now rendered inline under the last assistant message.
