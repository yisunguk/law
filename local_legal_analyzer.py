
# local_legal_analyzer.py
# -*- coding: utf-8 -*-
import os, io, re, time
from typing import List, Tuple
import streamlit as st
from utils_extract import extract_text_from_pdf, extract_text_from_docx, read_txt, sanitize
import requests
from bs4 import BeautifulSoup

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")
AZURE_OPENAI_ENDPOINT = os.environ.get("AZURE_OPENAI_ENDPOINT", "")
AZURE_OPENAI_API_KEY = os.environ.get("AZURE_OPENAI_API_KEY", "")
AZURE_OPENAI_DEPLOYMENT = os.environ.get("AZURE_OPENAI_DEPLOYMENT", "")

try:
    from openai import OpenAI, AzureOpenAI
except Exception:
    OpenAI = None
    AzureOpenAI = None

def get_llm_client():
    if AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY and AZURE_OPENAI_DEPLOYMENT and AzureOpenAI is not None:
        client = AzureOpenAI(api_key=AZURE_OPENAI_API_KEY, api_version="2024-02-01", azure_endpoint=AZURE_OPENAI_ENDPOINT)
        return ("azure", client)
    elif OPENAI_API_KEY and OpenAI is not None:
        client = OpenAI(api_key=OPENAI_API_KEY)
        return ("openai", client)
    else:
        return (None, None)

def fetch_url_text(url: str) -> str:
    try:
        r = requests.get(url, timeout=12, headers={"User-Agent": "Mozilla/5.0"})
        if not (200 <= r.status_code < 400):
            return ""
    except Exception:
        return ""
    soup = BeautifulSoup(r.text, "html.parser")
    node = soup.select_one("main") or soup.select_one("article") or soup.select_one("body")
    text = node.get_text("\\n", strip=True) if node else soup.get_text("\\n", strip=True)
    return sanitize(text)

def combine_contexts(report_texts: List[Tuple[str, str]], law_texts: List[Tuple[str, str]]) -> str:
    blocks = []
    for name, txt in report_texts:
        blocks.append(f"# [ì‚¬ê³ ë³´ê³ ì„œ] {name}\\n{sanitize(txt)[:12000]}")
    for name, txt in law_texts:
        blocks.append(f"# [ë²•ë ¹/ìë£Œ] {name}\\n{sanitize(txt)[:12000]}")
    return "\\n\\n".join(blocks)

SYSTEM_PROMPT = "ë‹¹ì‹ ì€ ì‚°ì—…ì•ˆì „Â·ê±´ì„¤ ì•ˆì „ ë¶„ì•¼ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ê³ ë³´ê³ ì„œì™€ ë²•ë ¹/ìë£Œë¥¼ í•¨ê»˜ ê²€í† í•´ ìš”ì•½, ì˜ë¬´/ìœ„ë°˜, ì›ì¸, ê°œì„ , ì¶”ê°€í™•ì¸ì„ ê°„ê²°íˆ ì œì‹œí•˜ì„¸ìš”."

USER_PROMPT_TEMPLATE = """ì•„ë˜ ìë£Œë¥¼ ì¢…í•© ë¶„ì„í•´ ì£¼ì„¸ìš”.

[ë¶„ì„ ëª©í‘œ]
{goal}

[ì°¸ì¡° ìë£Œ]
{contexts}
"""

def run_llm(kind, client, model_or_deploy, prompt, temperature=0.2, max_tokens=1500):
    if kind == "azure":
        resp = client.chat.completions.create(
            model=model_or_deploy,
            messages=[{"role":"system","content":SYSTEM_PROMPT},{"role":"user","content":prompt}],
            temperature=temperature, max_tokens=max_tokens,
        )
        return resp.choices[0].message.content
    else:
        resp = client.chat.completions.create(
            model=model_or_deploy,
            messages=[{"role":"system","content":SYSTEM_PROMPT},{"role":"user","content":prompt}],
            temperature=temperature, max_tokens=max_tokens,
        )
        return resp.choices[0].message.content

st.set_page_config(page_title="ë¡œì»¬ ì‚¬ê³ ë³´ê³ ì„œ + ë²•ë ¹ GPT ë¶„ì„ê¸°", page_icon="âš–ï¸", layout="wide")
st.title("âš–ï¸ ë¡œì»¬ ì‚¬ê³ ë³´ê³ ì„œ + ë²•ë ¹ GPT ë¶„ì„ê¸° (DB ì—†ì´ ë¡œì»¬)")

with st.sidebar:
    st.header("API ì„¤ì •")
    mode = st.radio("LLM ì„ íƒ", ["Azure OpenAI", "OpenAI", "ì˜¤í”„ë¼ì¸(LLM ì‚¬ìš© ì•ˆ í•¨)"], index=0)

st.subheader("1) ì‚¬ê³ ë³´ê³ ì„œ ì—…ë¡œë“œ")
ups = st.file_uploader("PDF / DOCX / TXT (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["pdf","docx","txt"], accept_multiple_files=True)
reports: List[Tuple[str,str]] = []
if ups:
    for f in ups:
        name = f.name; data = f.read()
        ext = os.path.splitext(name)[1].lower()
        if ext == ".pdf":
            txt = extract_text_from_pdf(io.BytesIO(data))
        elif ext == ".docx":
            txt = extract_text_from_docx(io.BytesIO(data))
        else:
            txt = read_txt(io.BytesIO(data))
        reports.append((name, txt))
    st.success(f"{len(reports)}ê°œ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")

st.subheader("2) ë²•ë ¹/ê¸°ì¤€ ì…ë ¥")
tab1, tab2 = st.tabs(["ë¶™ì—¬ë„£ê¸°", "URL"])
law_texts: List[Tuple[str,str]] = []
with tab1:
    pasted = st.text_area("ë²•ë ¹Â·ê¸°ì¤€ ì›ë¬¸ (ì—¬ëŸ¬ ê±´ì€ --- ë¡œ êµ¬ë¶„)", height=200)
    if pasted.strip():
        for i, block in enumerate([p.strip() for p in pasted.split("\\n---\\n") if p.strip()], 1):
            law_texts.append((f"ë¶™ì—¬ë„£ê¸°_{i}", block))
with tab2:
    urls = st.text_area("ë²•ë ¹/íŒë¡€/ê¸°ì¤€ URL (í•œ ì¤„ë‹¹ 1ê°œ)", height=140)
    if st.button("URLì—ì„œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"):
        ok = 0
        for line in urls.splitlines():
            u = line.strip()
            if not u: continue
            t = fetch_url_text(u)
            if t:
                ok += 1; law_texts.append((u, t))
        st.success(f"{ok}ê°œ URLì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ") if ok else st.warning("ê°€ì ¸ì˜¨ í…ìŠ¤íŠ¸ ì—†ìŒ")

goal = st.text_area("3) ë¶„ì„ ëª©í‘œ(ì„ íƒ)", value="ì‚¬ê³  ì›ì¸, ê´€ë ¨ ë²•ë ¹ ìœ„ë°˜ ì—¬ë¶€, ì¬ë°œ ë°©ì§€ ì¡°ì¹˜ ì œì•ˆ", height=80)
temperature = st.slider("ì°½ì˜ì„±(temperature)", 0.0, 1.0, 0.2, 0.1)
max_tokens = st.slider("ì‘ë‹µ ìµœëŒ€ í† í°", 500, 4000, 1500, 100)
run = st.button("ğŸ” GPTë¡œ ë¶„ì„í•˜ê¸°", type="primary", use_container_width=True)

if run:
    if not reports:
        st.error("ì‚¬ê³ ë³´ê³ ì„œë¥¼ í•œ ê°œ ì´ìƒ ì—…ë¡œë“œí•˜ì„¸ìš”."); st.stop()
    contexts = combine_contexts(reports, law_texts)
    prompt = USER_PROMPT_TEMPLATE.format(goal=goal, contexts=contexts)

    if mode == "ì˜¤í”„ë¼ì¸(LLM ì‚¬ìš© ì•ˆ í•¨)":
        st.warning("LLM API ë¯¸ì„¤ì • â€“ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.text_area("í”„ë¡¬í”„íŠ¸", value=prompt[:10000], height=300); st.stop()

    kind, client = get_llm_client()
    model_or_deploy = os.environ.get("AZURE_OPENAI_DEPLOYMENT","gpt-4o-mini") if kind=="azure" else os.environ.get("OPENAI_MODEL","gpt-4o-mini")
    with st.spinner("ë¶„ì„ ì¤‘..."):
        try:
            result = run_llm(kind, client, model_or_deploy, prompt, temperature=temperature, max_tokens=max_tokens)
        except Exception as e:
            st.exception(e); st.stop()
    st.success("ë¶„ì„ ì™„ë£Œ"); st.markdown(result)
    ts = time.strftime("%Y%m%d_%H%M%S")
    st.download_button("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ(.md)", data=result.encode("utf-8"), file_name=f"ë¶„ì„ê²°ê³¼_{ts}.md", mime="text/markdown")
