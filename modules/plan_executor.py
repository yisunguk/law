# === [REPLACE] modules/plan_executor.py : execute_plan ì „ì²´ + ìŠ¤í¬ë© ìœ í‹¸ ì¶”ê°€ ===
from __future__ import annotations
from typing import Any, Dict, Optional, Tuple

try:
    from .law_fetch import (
        fetch_article_block_by_mst,
        jo_from_art_label as _jo_from_label,
        extract_article_block as _slice_article,
        find_mst_by_law_name,
    )
except Exception:
    from law_fetch import (
        fetch_article_block_by_mst,
        jo_from_art_label as _jo_from_label,
        extract_article_block as _slice_article,
        find_mst_by_law_name,
    )

# í‘œì‹œ/ìŠ¤í¬ë©ìš© ë”¥ë§í¬ ìƒì„±ê¸°
try:
    from .linking import make_pretty_article_url
except Exception:
    try:
        from linking import make_pretty_article_url
    except Exception:
        make_pretty_article_url = None  # type: ignore

def _scrape_deeplink(law_name: str, article_label: str, timeout: float = 6.0) -> Tuple[str, str]:
    """
    í•œê¸€ ì¡°ë¬¸ ë”¥ë§í¬ í˜ì´ì§€ë¥¼ ìŠ¤í¬ë©í•´ 'ìš”ì²­ ì¡°ë¬¸'ë§Œ ì˜ë¼ë‚¸ë‹¤.
    ë°˜í™˜: (ì¡°ë¬¸í…ìŠ¤íŠ¸, í‘œì‹œë§í¬)
    """
    if not (law_name and article_label and make_pretty_article_url):
        return "", ""
    try:
        import requests
        from bs4 import BeautifulSoup
        url = make_pretty_article_url(law_name, article_label)
        r = requests.get(
            url, timeout=timeout, allow_redirects=True,
            headers={"User-Agent":"Mozilla/5.0","Accept":"text/html,application/xhtml+xml","Accept-Language":"ko-KR,ko;q=0.9"}
        )
        if not (200 <= r.status_code < 400):
            return "", url
        html = r.text or ""
        if any(bad in html[:4000] for bad in ("ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°ë¬¸","í•´ë‹¹ í•œê¸€ì£¼ì†Œëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤","ì ‘ê·¼ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤")):
            return "", url
        soup = BeautifulSoup(html, "lxml")
        main = (soup.select_one("#contentBody") or soup.select_one("#conBody")
                or soup.select_one("#conScroll") or soup.select_one(".conScroll")
                or soup.select_one("#content") or soup)
        full_text = (main.get_text("\n", strip=True) or "").strip()

        # ì¡°ë¬¸ ë¸”ë¡ë§Œ ìŠ¬ë¼ì´ìŠ¤ (law_fetch.extract_article_block ì‚¬ìš©)
        piece = _slice_article(full_text, article_label) or ""
        if not piece:
            import re
            num = re.sub(r"\D","", article_label)
            m = re.search(rf"(ì œ{num}ì¡°(?:ì˜\d+)?[\s\S]*?)(?=\nì œ\d+ì¡°|\në¶€ì¹™|\Z)", full_text)
            piece = (m.group(1) if m else "").strip()

        return (piece[:4000] if piece else ""), url
    except Exception:
        return "", ""

def execute_plan(plan: Dict[str, Any]) -> Dict[str, Any]:
    """
    GET_ARTICLE:
      1) DRF(JSONâ†’HTML) ìš°ì„ 
      2) DRF ì‹¤íŒ¨/ì°¨ë‹¨ or MST ì—†ìŒ â†’ í•œê¸€ ì¡°ë¬¸ ë”¥ë§í¬ ìŠ¤í¬ë© í´ë°±
    """
    action = ((plan or {}).get("action") or "").upper()
    if action != "GET_ARTICLE":
        return {"type":"noop","action":action or "QUICK","message":"execute_plan: GET_ARTICLE ì™¸ ì•¡ì…˜ì€ ì™¸ë¶€ ê²½ë¡œì—ì„œ ì²˜ë¦¬í•˜ì„¸ìš”."}

    law_name  = (plan.get("law_name") or "").strip()
    art_label = (plan.get("article_label") or "").strip()
    mst       = (plan.get("mst") or "").strip()
    jo        = (plan.get("jo") or "").strip()
    efYd_raw  = (plan.get("efYd") or plan.get("eff_date") or "").strip()
    efYd      = "".join(ch for ch in efYd_raw if ch.isdigit())

    if (not jo) and art_label:
        try: jo = _jo_from_label(art_label) or ""
        except Exception: jo = ""

    # (ê°€ëŠ¥í•˜ë©´) MST ë³´ê°• â†’ DRF ë³¸ë¬¸ ì‹œë„
    if (not mst) and law_name:
        try: mst = find_mst_by_law_name(law_name, efYd=efYd) or ""
        except Exception: mst = ""

    text, link = "", ""

    # 1) DRF(JSONâ†’HTML)
    if mst:
        t1, l1 = fetch_article_block_by_mst(mst, art_label, prefer="JSON", efYd=efYd)
        if not (t1 and t1.strip()):
            t1b, l1b = fetch_article_block_by_mst(mst, art_label, prefer="HTML", efYd=efYd)
            if t1b and t1b.strip():
                t1, l1 = t1b.strip(), l1b
        text, link = (t1 or "").strip(), (l1 or "")

    # 2) ğŸ”´ ìµœí›„ í´ë°± â€” MSTê°€ ì—†ê±°ë‚˜ DRFê°€ ë¹„ì—ˆìœ¼ë©´ ì¡°ë¬¸ ë”¥ë§í¬ ìŠ¤í¬ë©
    if not (text and text.strip()):
        t2, l2 = _scrape_deeplink(law_name, art_label)
        if t2:
            text, link = t2, l2
        elif not link and make_pretty_article_url:
            link = make_pretty_article_url(law_name, art_label)

    return {
        "type":"article","law":law_name,"article":art_label,
        "mst":mst,"jo":jo,"efYd":efYd,
        "text":(text or "").strip(),
        "link":link or "",
    }
